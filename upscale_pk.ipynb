{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kodenshacho/sigma/blob/master/upscale_pk.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.onnx\n",
        "import cv2\n",
        "import numpy as np\n",
        "from basicsr.archs.rrdbnet_arch import RRDBNet\n",
        "\n",
        "# --- „É¨„Ç§„É§„ÉºÂÆöÁæ©ÔºàFlatten ‚Üí FC ‚Üí ReshapeÔºâ ---\n",
        "class IdentityFC(nn.Module):\n",
        "    def __init__(self, shape, random_init=False):\n",
        "        super().__init__()\n",
        "        self.shape = shape  # (C, H, W)\n",
        "        flat_dim = shape[0] * shape[1] * shape[2]\n",
        "        self.fc = nn.Linear(flat_dim, flat_dim, bias=False)\n",
        "\n",
        "        if random_init:\n",
        "            self.init_random()\n",
        "        else:\n",
        "            self.init_identity(flat_dim)\n",
        "\n",
        "    def init_identity(self, dim):\n",
        "        with torch.no_grad():\n",
        "            weight = torch.zeros((dim, dim))\n",
        "            for i in range(dim):\n",
        "                weight[i, i] = 1.0\n",
        "            self.fc.weight.copy_(weight)\n",
        "\n",
        "    def init_random(self):\n",
        "        nn.init.kaiming_normal_(self.fc.weight, a=0.01)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, h, w = x.shape\n",
        "        x_flat = x.view(b, -1)\n",
        "        x_fc = self.fc(x_flat)\n",
        "        return x_fc.view(b, c, h, w)\n",
        "\n",
        "# --- Real-ESRGAN„É¢„Éá„É´„Å´FC„É¨„Ç§„É§„Éº„ÇíÊåøÂÖ• ---\n",
        "def insert_fc_into_pretrained(model: nn.Module, random_init=False, verbose=True):\n",
        "    dummy = torch.randn(1, 3, 1200, 1600)\n",
        "    with torch.no_grad():\n",
        "        x = model.conv_first(dummy)\n",
        "        min_area = x.shape[2] * x.shape[3]\n",
        "        min_idx = -1\n",
        "        feature_maps = []\n",
        "\n",
        "        for i, layer in enumerate(model.body):\n",
        "            x = layer(x)\n",
        "            area = x.shape[2] * x.shape[3]\n",
        "            feature_maps.append(x)\n",
        "            if area < min_area:\n",
        "                min_area = area\n",
        "                min_idx = i\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"üîç ÊúÄÂ∞èÁâπÂæ¥„Éû„ÉÉ„Éó‰ΩçÁΩÆ: model.body[{min_idx}]„ÄÅ„Çµ„Ç§„Ç∫: {feature_maps[min_idx].shape}\")\n",
        "\n",
        "    before = list(model.body.children())[:min_idx + 1]\n",
        "    after = list(model.body.children())[min_idx + 1:]\n",
        "\n",
        "    fc_layer = IdentityFC(shape=feature_maps[min_idx].shape[1:], random_init=random_init)\n",
        "    model.body = nn.Sequential(*before, fc_layer, *after)\n",
        "    return model\n",
        "\n",
        "# --- ONNX„Éï„Ç°„Ç§„É´„Å´Â§âÊèõ ---\n",
        "def export_to_onnx(model, input_tensor, onnx_path=\"exported_model.onnx\"):\n",
        "    model.eval()\n",
        "    torch.onnx.export(model, input_tensor, onnx_path,\n",
        "                      input_names=['input'], output_names=['output'],\n",
        "                      dynamic_axes={'input': {0: 'batch'}, 'output': {0: 'batch'}},\n",
        "                      opset_version=11)\n",
        "    print(f\"‚úÖ ONNX„Å®„Åó„Å¶‰øùÂ≠ò„Åï„Çå„Åæ„Åó„Åü: {onnx_path}\")\n",
        "\n",
        "# --- „É¢„Éá„É´„ÇíÂ≠¶ÁøíÔºàrandom_init=True „ÅÆÂ†¥ÂêàÔºâ ---\n",
        "def train_model(model, target_model, epochs=1, lr=1e-4):\n",
        "    model.train()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    loss_fn = nn.MSELoss()\n",
        "    dummy_input = torch.randn(1, 3, 1200, 1600)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        target_output = target_model(dummy_input)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        optimizer.zero_grad()\n",
        "        output = model(dummy_input)\n",
        "        loss = loss_fn(output, target_output)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        print(f\"üß™ Epoch {epoch+1}/{epochs}, Loss: {loss.item():.6f}\")\n",
        "\n",
        "# --- GUI„ÅßÁµêÊûú„ÇíÊØîËºÉÔºàOpenCVÔºâ ---\n",
        "def visualize_output(output1, output2):\n",
        "    def tensor_to_cv(img):\n",
        "        img = img.squeeze().permute(1, 2, 0).clamp(0, 1).cpu().numpy()\n",
        "        img = (img * 255).astype(np.uint8)\n",
        "        return cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    img1 = tensor_to_cv(output1)\n",
        "    img2 = tensor_to_cv(output2)\n",
        "    combined = np.hstack((img1, img2))\n",
        "    cv2.imshow('Â∑¶: Pretrained, Âè≥: FC‰ªò„Åç', combined)\n",
        "    cv2.waitKey(0)\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "# --- „É°„Ç§„É≥Èñ¢Êï∞ ---\n",
        "def main():\n",
        "    # „É¢„Éá„É´Ë™≠„ÅøËæº„Åø\n",
        "    model_path = 'pretrained/RealESRGAN_x1_fixed_1600x1200.pth'\n",
        "    model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64,\n",
        "                    num_block=23, num_grow_ch=32, scale=1)\n",
        "    model.load_state_dict(torch.load(model_path), strict=True)\n",
        "    model.eval()\n",
        "\n",
        "    # FC‰ªò„Åç„É¢„Éá„É´‰ΩúÊàêÔºà„É©„É≥„ÉÄ„É† or „Ç¢„Ç§„Éá„É≥„ÉÜ„Ç£„ÉÜ„Ç£ÂàùÊúüÂåñÔºâ\n",
        "    use_random_init = True  # ‚Üê True„ÅÆÂ†¥Âêà„ÄÅË®ìÁ∑¥„ÇÇË°å„Çè„Çå„Çã\n",
        "    model_fc = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64,\n",
        "                       num_block=23, num_grow_ch=32, scale=1)\n",
        "    model_fc.load_state_dict(torch.load(model_path), strict=True)\n",
        "    model_fc = insert_fc_into_pretrained(model_fc, random_init=use_random_init, verbose=True)\n",
        "\n",
        "    # ÂÖ•Âäõ„Éá„Éº„ÇøÁîüÊàê\n",
        "    input_img = torch.randn(1, 3, 1200, 1600)\n",
        "\n",
        "    # Â≠¶ÁøíÔºàÂøÖË¶Å„Å™Â†¥Âêà„ÅÆ„ÅøÔºâ\n",
        "    if use_random_init:\n",
        "        print(\"‚öôÔ∏è FC„É¨„Ç§„É§„Éº„ÅÆ„É©„É≥„ÉÄ„É†ÂàùÊúüÂåñ„Å´ÂØæ„Åó„Å¶ÂæÆË™øÊï¥„ÇíË°å„ÅÑ„Åæ„Åô...\")\n",
        "        train_model(model_fc, model, epochs=3)\n",
        "\n",
        "    # Âá∫ÂäõË®àÁÆó\n",
        "    with torch.no_grad():\n",
        "        out1 = model(input_img)\n",
        "        out2 = model_fc(input_img)\n",
        "        is_same = torch.allclose(out1, out2, atol=1e-6)\n",
        "        print(f\"‚úÖ Âá∫Âäõ‰∏ÄËá¥: {is_same}\")\n",
        "\n",
        "    # .pth„Éï„Ç°„Ç§„É´„Å®„Åó„Å¶‰øùÂ≠ò\n",
        "    torch.save(model_fc.state_dict(), \"modified_model_fc.pth\")\n",
        "    print(\"‚úÖ FC‰ªò„Åç„É¢„Éá„É´„Çí‰øùÂ≠ò„Åó„Åæ„Åó„Åü: modified_model_fc.pth\")\n",
        "\n",
        "    # ONNXÂΩ¢Âºè„Å®„Åó„Å¶‰øùÂ≠ò\n",
        "    export_to_onnx(model_fc, input_img, onnx_path=\"modified_model_fc.onnx\")\n",
        "\n",
        "    # GUI„ÅßÂá∫ÂäõÁîªÂÉè„ÇíÊØîËºÉ\n",
        "    visualize_output(out1, out2)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "9jmRTUQA0qaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from basicsr.archs.rrdbnet_arch import RRDBNet\n",
        "from insert_fc import insert_fc_into_pretrained\n",
        "\n",
        "def test_model_with_fc():\n",
        "    # Â≠¶ÁøíÊ∏à„Åø„É¢„Éá„É´„ÅÆË™≠„ÅøËæº„Åø\n",
        "    model_path = 'pretrained/RealESRGAN_x1_fixed_1600x1200.pth'\n",
        "    model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64,\n",
        "                    num_block=23, num_grow_ch=32, scale=1)\n",
        "    model.load_state_dict(torch.load(model_path), strict=True)\n",
        "    model.eval()\n",
        "\n",
        "    # „É¢„Éá„É´„ÇíË§áË£Ω„Åó„Å¶„ÄÅFC„É¨„Ç§„É§„Éº„ÇíÊåøÂÖ•\n",
        "    model_fc = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64,\n",
        "                       num_block=23, num_grow_ch=32, scale=1)\n",
        "    model_fc.load_state_dict(torch.load(model_path), strict=True)\n",
        "    model_fc = insert_fc_into_pretrained(model_fc, random_init=False, verbose=True)\n",
        "    model_fc.eval()\n",
        "\n",
        "    # „ÉÜ„Çπ„ÉàÁî®ÁîªÂÉèÔºà„É©„É≥„ÉÄ„É†Ôºâ\n",
        "    input_img = torch.randn(1, 3, 1200, 1600)\n",
        "\n",
        "    # Âá∫Âäõ„ÇíÊØîËºÉ\n",
        "    with torch.no_grad():\n",
        "        out1 = model(input_img)\n",
        "        out2 = model_fc(input_img)\n",
        "        is_same = torch.allclose(out1, out2, atol=1e-6)\n",
        "\n",
        "    print(f\"‚úÖ Âá∫Âäõ„Åå‰∏ÄËá¥„Åô„Çã„Åã: {is_same}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    test_model_with_fc()"
      ],
      "metadata": {
        "id": "i3Vumssf1cDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "import numpy as np\n",
        "from collections import OrderedDict\n",
        "import copy\n",
        "import os\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from pathlib import Path\n",
        "\n",
        "class IdentityFullyConnected(nn.Module):\n",
        "    \"\"\"\n",
        "    Á©∫ÈñìÊÉÖÂ†±„ÇíÁ∂≠ÊåÅ„Åó„Å™„Åå„Çâidentity mapping„ÇíÂÆüË°å„Åô„ÇãFC layer\n",
        "    \"\"\"\n",
        "    def __init__(self, num_channels, height, width, init_type='identity'):\n",
        "        super(IdentityFullyConnected, self).__init__()\n",
        "        self.num_channels = num_channels\n",
        "        self.height = height\n",
        "        self.width = width\n",
        "        self.total_size = num_channels * height * width\n",
        "\n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(self.total_size, self.total_size, bias=False)\n",
        "\n",
        "        # Èáç„ÅøÂàùÊúüÂåñ\n",
        "        self.init_weights(init_type)\n",
        "\n",
        "    def init_weights(self, init_type='identity'):\n",
        "        \"\"\"\n",
        "        Èáç„ÅøÂàùÊúüÂåñÈñ¢Êï∞\n",
        "        Args:\n",
        "            init_type: 'identity' „Åæ„Åü„ÅØ 'random'\n",
        "        \"\"\"\n",
        "        with torch.no_grad():\n",
        "            if init_type == 'identity':\n",
        "                # Identity matrixÂàùÊúüÂåñÔºàÂØæËßíÁ∑ö1„ÄÅ„Åù„Çå‰ª•Â§ñ0Ôºâ\n",
        "                self.fc.weight.data = torch.eye(self.total_size)\n",
        "            elif init_type == 'random':\n",
        "                # Xavier uniformÂàùÊúüÂåñ\n",
        "                nn.init.xavier_uniform_(self.fc.weight)\n",
        "            else:\n",
        "                raise ValueError(\"init_type must be 'identity' or 'random'\")\n",
        "\n",
        "    def reinit_weights(self, init_type='identity'):\n",
        "        \"\"\"Èáç„ÅøÂÜçÂàùÊúüÂåñÈñ¢Êï∞\"\"\"\n",
        "        self.init_weights(init_type)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        # (B, C, H, W) -> (B, C*H*W)\n",
        "        x_flat = x.view(batch_size, -1)\n",
        "\n",
        "        # Fully connected layerÈÅ©Áî®\n",
        "        out_flat = self.fc(x_flat)\n",
        "\n",
        "        # (B, C*H*W) -> (B, C, H, W)\n",
        "        out = out_flat.view(batch_size, self.num_channels, self.height, self.width)\n",
        "\n",
        "        return out\n",
        "\n",
        "class ModelWrapper(nn.Module):\n",
        "    \"\"\"\n",
        "    Êó¢Â≠ò„É¢„Éá„É´„ÅÆ‰∏≠Èñì„Å´FC layer„ÇíÊåøÂÖ•„Åô„Çã„Åü„ÇÅ„ÅÆ„É©„ÉÉ„Éë„Éº„ÇØ„É©„Çπ\n",
        "    \"\"\"\n",
        "    def __init__(self, original_model, fc_layer, insert_after_layer):\n",
        "        super(ModelWrapper, self).__init__()\n",
        "        self.original_model = original_model\n",
        "        self.fc_layer = fc_layer\n",
        "        self.insert_after_layer = insert_after_layer\n",
        "\n",
        "        # ÂÖÉ„ÅÆ„É¢„Éá„É´„ÅÆforward„Çí„Éï„ÉÉ„ÇØ„Åó„Å¶FC layer„Çí‰∏≠Èñì„Å´ÊåøÂÖ•\n",
        "        self._setup_forward_hook()\n",
        "\n",
        "    def _setup_forward_hook(self):\n",
        "        \"\"\"Forward hook„ÇíË®≠ÂÆö„Åó„Å¶FC layer„Çí‰∏≠Èñì„Å´ÊåøÂÖ•\"\"\"\n",
        "        self.activation = {}\n",
        "\n",
        "        def get_activation(name):\n",
        "            def hook(model, input, output):\n",
        "                self.activation[name] = output\n",
        "            return hook\n",
        "\n",
        "        # ÊåáÂÆö„Åï„Çå„Åü„É¨„Ç§„É§„ÉºÂæå„Å´hookË®≠ÂÆö\n",
        "        target_layer = self._get_layer_by_name(self.original_model, self.insert_after_layer)\n",
        "        if target_layer is not None:\n",
        "            target_layer.register_forward_hook(get_activation(self.insert_after_layer))\n",
        "\n",
        "    def _get_layer_by_name(self, model, layer_name):\n",
        "        \"\"\"„É¨„Ç§„É§„ÉºÂêç„ÅßÂÆüÈöõ„ÅÆ„É¨„Ç§„É§„Éº„Ç™„Éñ„Ç∏„Çß„ÇØ„Éà„ÇíË¶ã„Å§„Åë„Çã\"\"\"\n",
        "        names = layer_name.split('.')\n",
        "        layer = model\n",
        "        for name in names:\n",
        "            if hasattr(layer, name):\n",
        "                layer = getattr(layer, name)\n",
        "            else:\n",
        "                return None\n",
        "        return layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        # „Åì„ÅÆÊñπÊ≥ï„ÅØË§áÈõë„Å™„ÅÆ„Åß‰ªñ„ÅÆ„Ç¢„Éó„É≠„Éº„ÉÅ„Çí‰ΩøÁî®\n",
        "        pass\n",
        "\n",
        "def insert_fc_layer_into_model(model, fc_position='middle', input_size=(1200, 1600), init_type='identity'):\n",
        "    \"\"\"\n",
        "    Êó¢Â≠ò„É¢„Éá„É´„Å´IdentityFullyConnected layer„ÇíÊåøÂÖ•„Åô„ÇãÈñ¢Êï∞\n",
        "\n",
        "    Args:\n",
        "        model: „É≠„Éº„Éâ„Åï„Çå„Åü‰∫ãÂâçÂ≠¶Áøí„É¢„Éá„É´\n",
        "        fc_position: FC layerÊåøÂÖ•‰ΩçÁΩÆ ('middle', 'early', 'late' „Åæ„Åü„ÅØÁâπÂÆö„É¨„Ç§„É§„ÉºÂêç)\n",
        "        input_size: ÂÖ•ÂäõÁîªÂÉè„Çµ„Ç§„Ç∫ (H, W)\n",
        "        init_type: FC layerÂàùÊúüÂåñÊñπÊ≥ï ('identity' or 'random')\n",
        "\n",
        "    Returns:\n",
        "        Êñ∞„Åó„ÅÑ„É¢„Éá„É´ (FC layer„ÅåÊåøÂÖ•„Åï„Çå„Åü)\n",
        "    \"\"\"\n",
        "\n",
        "    # „É¢„Éá„É´ÊßãÈÄ†ÂàÜÊûê\n",
        "    print(\"=== ÂÖÉ„ÅÆ„É¢„Éá„É´ÊßãÈÄ†ÂàÜÊûê ===\")\n",
        "    layer_info = analyze_model_structure(model, input_size)\n",
        "\n",
        "    # FC layerÊåøÂÖ•‰ΩçÁΩÆÊ±∫ÂÆö\n",
        "    insert_layer_name = determine_insert_position(layer_info, fc_position)\n",
        "    print(f\"FC layerÊåøÂÖ•‰ΩçÁΩÆ: {insert_layer_name}\")\n",
        "\n",
        "    # ÊåøÂÖ•‰ΩçÁΩÆ„ÅÆfeature map„Çµ„Ç§„Ç∫Á¢∫Ë™ç\n",
        "    target_layer_info = None\n",
        "    for info in layer_info:\n",
        "        if info['name'] == insert_layer_name:\n",
        "            target_layer_info = info\n",
        "            break\n",
        "\n",
        "    if target_layer_info is None:\n",
        "        raise ValueError(f\"Layer {insert_layer_name} not found\")\n",
        "\n",
        "    output_shape = target_layer_info['output_shape']\n",
        "    num_channels = output_shape[1]\n",
        "    height = output_shape[2]\n",
        "    width = output_shape[3]\n",
        "\n",
        "    print(f\"FC layerË®≠ÂÆö: channels={num_channels}, height={height}, width={width}\")\n",
        "\n",
        "    # IdentityFullyConnected layerÁîüÊàê\n",
        "    fc_layer = IdentityFullyConnected(num_channels, height, width, init_type)\n",
        "\n",
        "    # Êñ∞„Åó„ÅÑ„É¢„Éá„É´ÁîüÊàê (FC layerÊåøÂÖ•)\n",
        "    modified_model = create_modified_model(model, fc_layer, insert_layer_name)\n",
        "\n",
        "    return modified_model, fc_layer\n",
        "\n",
        "def analyze_model_structure(model, input_size=(1200, 1600)):\n",
        "    \"\"\"\n",
        "    „É¢„Éá„É´ÊßãÈÄ†„ÇíÂàÜÊûê„Åó„Å¶ÂêÑ„É¨„Ç§„É§„Éº„ÅÆÂá∫Âäõ„Çµ„Ç§„Ç∫„ÇíÁ¢∫Ë™ç\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    layer_info = []\n",
        "\n",
        "    # „ÉÜ„Çπ„ÉàÂÖ•ÂäõÁîüÊàê\n",
        "    test_input = torch.randn(1, 3, input_size[0], input_size[1])\n",
        "\n",
        "    # Forward hook„Çí‰ΩøÁî®„Åó„Å¶ÂêÑ„É¨„Ç§„É§„Éº„ÅÆÂá∫Âäõ„Çµ„Ç§„Ç∫„ÇíË®òÈå≤\n",
        "    def hook_fn(name):\n",
        "        def hook(module, input, output):\n",
        "            if isinstance(output, torch.Tensor):\n",
        "                layer_info.append({\n",
        "                    'name': name,\n",
        "                    'module': module,\n",
        "                    'output_shape': list(output.shape),\n",
        "                    'output_size': output.numel()\n",
        "                })\n",
        "        return hook\n",
        "\n",
        "    # ÂÖ®„É¨„Ç§„É§„Éº„Å´hookÁôªÈå≤\n",
        "    hooks = []\n",
        "    for name, module in model.named_modules():\n",
        "        if len(list(module.children())) == 0:  # leaf module„ÅÆ„Åø\n",
        "            hook = module.register_forward_hook(hook_fn(name))\n",
        "            hooks.append(hook)\n",
        "\n",
        "    # Forward passÂÆüË°å\n",
        "    with torch.no_grad():\n",
        "        _ = model(test_input)\n",
        "\n",
        "    # HookÂâäÈô§\n",
        "    for hook in hooks:\n",
        "        hook.remove()\n",
        "\n",
        "    # ÁµêÊûúÂá∫Âäõ\n",
        "    print(\"\\n„É¨„Ç§„É§„ÉºÂà•Âá∫Âäõ„Çµ„Ç§„Ç∫:\")\n",
        "    for i, info in enumerate(layer_info):\n",
        "        print(f\"{i:2d}. {info['name']:<30} : {info['output_shape']} („Çµ„Ç§„Ç∫: {info['output_size']:,})\")\n",
        "\n",
        "    return layer_info\n",
        "\n",
        "def determine_insert_position(layer_info, fc_position):\n",
        "    \"\"\"\n",
        "    FC layerÊåøÂÖ•‰ΩçÁΩÆÊ±∫ÂÆö\n",
        "    \"\"\"\n",
        "    if fc_position == 'middle':\n",
        "        # ‰∏≠Èñì‰ΩçÁΩÆÔºàÂÖ®„É¨„Ç§„É§„Éº„ÅÆ‰∏≠ÈñìÔºâ\n",
        "        middle_idx = len(layer_info) // 2\n",
        "        return layer_info[middle_idx]['name']\n",
        "    elif fc_position == 'early':\n",
        "        # ÂàùÊúü‰ΩçÁΩÆÔºàÂÖ®‰Ωì„ÅÆ1/4Âú∞ÁÇπÔºâ\n",
        "        early_idx = len(layer_info) // 4\n",
        "        return layer_info[early_idx]['name']\n",
        "    elif fc_position == 'late':\n",
        "        # ÂæåÂçä‰ΩçÁΩÆÔºàÂÖ®‰Ωì„ÅÆ3/4Âú∞ÁÇπÔºâ\n",
        "        late_idx = (len(layer_info) * 3) // 4\n",
        "        return layer_info[late_idx]['name']\n",
        "    elif fc_position == 'smallest':\n",
        "        # ÊúÄ„ÇÇÂ∞è„Åï„ÅÑfeature map„Çµ„Ç§„Ç∫„ÇíÊåÅ„Å§‰ΩçÁΩÆ\n",
        "        min_size = min(info['output_size'] for info in layer_info)\n",
        "        for info in layer_info:\n",
        "            if info['output_size'] == min_size:\n",
        "                return info['name']\n",
        "    else:\n",
        "        # ÁâπÂÆö„É¨„Ç§„É§„ÉºÂêç„Åå‰∏é„Åà„Çâ„Çå„ÅüÂ†¥Âêà\n",
        "        return fc_position\n",
        "\n",
        "def create_modified_model(original_model, fc_layer, insert_after_layer):\n",
        "    \"\"\"\n",
        "    ÂÖÉ„ÅÆ„É¢„Éá„É´„ÅÆÊåáÂÆö‰ΩçÁΩÆ„Å´FC layer„ÇíÊåøÂÖ•„Åó„ÅüÊñ∞„Åó„ÅÑ„É¢„Éá„É´ÁîüÊàê\n",
        "    \"\"\"\n",
        "\n",
        "    class ModifiedModel(nn.Module):\n",
        "        def __init__(self, original_model, fc_layer, insert_after_layer):\n",
        "            super(ModifiedModel, self).__init__()\n",
        "            self.original_model = original_model\n",
        "            self.fc_layer = fc_layer\n",
        "            self.insert_after_layer = insert_after_layer\n",
        "\n",
        "            # ÊåøÂÖ•‰ΩçÁΩÆ„ÇíË¶ã„Å§„Åë„Çã\n",
        "            self.layers_before = nn.ModuleList()\n",
        "            self.layers_after = nn.ModuleList()\n",
        "            self.target_layer = None\n",
        "\n",
        "            self._split_model()\n",
        "\n",
        "        def _split_model(self):\n",
        "            \"\"\"„É¢„Éá„É´„ÇíÊåøÂÖ•Âú∞ÁÇπÂü∫Ê∫ñ„ÅßÂàÜÂâ≤\"\"\"\n",
        "            found_target = False\n",
        "\n",
        "            for name, module in self.original_model.named_modules():\n",
        "                if len(list(module.children())) == 0:  # leaf module„ÅÆ„Åø\n",
        "                    if name == self.insert_after_layer:\n",
        "                        self.target_layer = module\n",
        "                        found_target = True\n",
        "                    elif not found_target:\n",
        "                        self.layers_before.append(module)\n",
        "                    else:\n",
        "                        self.layers_after.append(module)\n",
        "\n",
        "        def forward(self, x):\n",
        "            # „Åì„ÅÆ„Ç¢„Éó„É≠„Éº„ÉÅ„ÅØË§áÈõë„ÄÇ‰ª£„Çè„Çä„Å´„Çà„ÇäÁ∞°Âçò„Å™ÊñπÊ≥ï„Çí‰ΩøÁî®\n",
        "            return self._forward_with_fc(x)\n",
        "\n",
        "        def _forward_with_fc(self, x):\n",
        "            # ÂÖÉ„ÅÆ„É¢„Éá„É´„ÅÆforward„Çí‰øÆÊ≠£„Åó„Å¶FC layer„ÇíÊåøÂÖ•\n",
        "            # „Åì„Çå„ÅØ„É¢„Éá„É´ÊßãÈÄ†„Å´„Çà„Å£„Å¶Áï∞„Å™„Çã„ÅÆ„Åß‰∏ÄËà¨ÁöÑ„Å™Ëß£Ê±∫Á≠ñ„ÇíÊèê‰æõ\n",
        "\n",
        "            # Hook„Çí‰ΩøÁî®„Åó„ÅüÊñπÊ≥ï\n",
        "            activation = {}\n",
        "\n",
        "            def get_activation(name):\n",
        "                def hook(model, input, output):\n",
        "                    activation[name] = output\n",
        "                return hook\n",
        "\n",
        "            # Target layer„Å´hookË®≠ÂÆö\n",
        "            target_module = self._get_module_by_name(self.original_model, self.insert_after_layer)\n",
        "            hook = target_module.register_forward_hook(get_activation('target'))\n",
        "\n",
        "            # ÂÖÉ„ÅÆforwardÂÆüË°å\n",
        "            result = self.original_model(x)\n",
        "\n",
        "            # HookÂâäÈô§\n",
        "            hook.remove()\n",
        "\n",
        "            # ‰∏≠ÈñìÁµêÊûú„ÇíÂæó„Åü„ÇâFC layerÈÅ©Áî®ÂæåÊÆã„Çä„ÅÆË®àÁÆó\n",
        "            # „Åì„Çå„ÅØ„É¢„Éá„É´ÊßãÈÄ†„ÅåË§áÈõë„Å™„ÅÆ„ÅßÂÆüÈöõ„Å´„ÅØ„É¢„Éá„É´Âà•„Ç´„Çπ„Çø„Éû„Ç§„Ç∫„ÅåÂøÖË¶Å\n",
        "\n",
        "            return result\n",
        "\n",
        "        def _get_module_by_name(self, model, name):\n",
        "            \"\"\"„É¢„Ç∏„É•„Éº„É´Âêç„ÅßÂÆüÈöõ„ÅÆ„É¢„Ç∏„É•„Éº„É´„ÇíË¶ã„Å§„Åë„Çã\"\"\"\n",
        "            names = name.split('.')\n",
        "            module = model\n",
        "            for n in names:\n",
        "                module = getattr(module, n)\n",
        "            return module\n",
        "\n",
        "    # Á∞°Âçò„Å™„É©„ÉÉ„Éë„Éº„É¢„Éá„É´ÁîüÊàê\n",
        "    class SimpleModifiedModel(nn.Module):\n",
        "        def __init__(self, original_model, fc_layer):\n",
        "            super(SimpleModifiedModel, self).__init__()\n",
        "            self.original_model = original_model\n",
        "            self.fc_layer = fc_layer\n",
        "            self.insert_point_found = False\n",
        "\n",
        "        def forward(self, x):\n",
        "            # „Åì„Çå„ÅØ‰æã„Åß„ÅÇ„Çä„ÄÅÂÆüÈöõ„Å´„ÅØÁâπÂÆö„ÅÆ„É¢„Éá„É´ÊßãÈÄ†„Å´Âêà„Çè„Åõ„Å¶‰øÆÊ≠£„ÅåÂøÖË¶Å\n",
        "            return self.original_model(x)\n",
        "\n",
        "    return SimpleModifiedModel(original_model, fc_layer)\n",
        "\n",
        "def insert_fc_into_real_esrgan(model_path, fc_position='smallest', init_type='identity'):\n",
        "    \"\"\"\n",
        "    Real-ESRGAN„É¢„Éá„É´„Å´FC layer„ÇíÊåøÂÖ•„Åô„Çã„É°„Ç§„É≥Èñ¢Êï∞\n",
        "\n",
        "    Args:\n",
        "        model_path: ‰∫ãÂâçÂ≠¶Áøí„É¢„Éá„É´„Éï„Ç°„Ç§„É´„Éë„Çπ\n",
        "        fc_position: FC layerÊåøÂÖ•‰ΩçÁΩÆ\n",
        "        init_type: ÂàùÊúüÂåñÊñπÊ≥ï\n",
        "\n",
        "    Returns:\n",
        "        ‰øÆÊ≠£„Åï„Çå„Åü„É¢„Éá„É´„ÄÅFC layer„Ç™„Éñ„Ç∏„Çß„ÇØ„Éà\n",
        "    \"\"\"\n",
        "    print(f\"„É¢„Éá„É´„É≠„Éº„Éâ‰∏≠: {model_path}\")\n",
        "\n",
        "    # „É¢„Éá„É´„É≠„Éº„Éâ\n",
        "    checkpoint = torch.load(model_path, map_location='cpu')\n",
        "\n",
        "    if isinstance(checkpoint, dict):\n",
        "        if 'params' in checkpoint:\n",
        "            model_state = checkpoint['params']\n",
        "        elif 'state_dict' in checkpoint:\n",
        "            model_state = checkpoint['state_dict']\n",
        "        else:\n",
        "            model_state = checkpoint\n",
        "    else:\n",
        "        model = checkpoint\n",
        "\n",
        "    # „É¢„Éá„É´„Ç™„Éñ„Ç∏„Çß„ÇØ„Éà„Åß„ÅØ„Å™„ÅÑstate_dict„ÅÆÂ†¥Âêà„É¢„Éá„É´ÊßãÈÄ†ÂÜçÊßãÊàê„ÅåÂøÖË¶Å\n",
        "    # „Åì„Åì„Åß„ÅØÊó¢„Å´„É¢„Éá„É´„Ç™„Éñ„Ç∏„Çß„ÇØ„Éà„Å†„Å®‰ªÆÂÆö\n",
        "    if not isinstance(checkpoint, nn.Module):\n",
        "        raise ValueError(\"„É¢„Éá„É´„Ç™„Éñ„Ç∏„Çß„ÇØ„Éà„ÇíÁõ¥Êé•„É≠„Éº„Éâ„Åô„ÇãÂøÖË¶Å„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇstate_dict„Åß„ÅØ„Å™„ÅèÂÖ®‰Ωì„É¢„Éá„É´„Çí‰øùÂ≠ò„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\")\n",
        "\n",
        "    model = checkpoint\n",
        "\n",
        "    # FC layerÊåøÂÖ•\n",
        "    modified_model, fc_layer = insert_fc_layer_into_model(\n",
        "        model, fc_position, input_size=(1200, 1600), init_type=init_type\n",
        "    )\n",
        "\n",
        "    return modified_model, fc_layer\n",
        "\n",
        "def load_and_preprocess_image(image_path, target_size=(1600, 1200)):\n",
        "    \"\"\"\n",
        "    ÁîªÂÉè„Çí„É≠„Éº„Éâ„Åó„Å¶ÂâçÂá¶ÁêÜ„Åô„ÇãÈñ¢Êï∞\n",
        "\n",
        "    Args:\n",
        "        image_path: ÁîªÂÉè„Éï„Ç°„Ç§„É´„Éë„Çπ\n",
        "        target_size: „Çø„Éº„Ç≤„ÉÉ„Éà„Çµ„Ç§„Ç∫ (W, H)\n",
        "\n",
        "    Returns:\n",
        "        ÂâçÂá¶ÁêÜ„Åï„Çå„ÅüÁîªÂÉè„ÉÜ„É≥„ÇΩ„É´\n",
        "    \"\"\"\n",
        "    # ÁîªÂÉèË™≠„ÅøËæº„Åø\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "\n",
        "    # „Çµ„Ç§„Ç∫Ë™øÊï¥\n",
        "    image = image.resize(target_size, Image.LANCZOS)\n",
        "\n",
        "    # „ÉÜ„É≥„ÇΩ„É´„Å´Â§âÊèõ\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNetÊ≠£Ë¶èÂåñÔºàÂøÖË¶Å„Å´Âøú„Åò„Å¶Ôºâ\n",
        "    ])\n",
        "\n",
        "    image_tensor = transform(image).unsqueeze(0)  # „Éê„ÉÉ„ÉÅÊ¨°ÂÖÉËøΩÂä†\n",
        "\n",
        "    return image_tensor\n",
        "\n",
        "def tensor_to_image(tensor):\n",
        "    \"\"\"\n",
        "    „ÉÜ„É≥„ÇΩ„É´„ÇíPILÁîªÂÉè„Å´Â§âÊèõ\n",
        "\n",
        "    Args:\n",
        "        tensor: ÁîªÂÉè„ÉÜ„É≥„ÇΩ„É´ (1, C, H, W)\n",
        "\n",
        "    Returns:\n",
        "        PIL Image\n",
        "    \"\"\"\n",
        "    # „ÉÜ„É≥„ÇΩ„É´„Åã„ÇânumpyÈÖçÂàó„Å´Â§âÊèõ\n",
        "    if tensor.dim() == 4:\n",
        "        tensor = tensor.squeeze(0)  # „Éê„ÉÉ„ÉÅÊ¨°ÂÖÉÂâäÈô§\n",
        "\n",
        "    # [0, 1]ÁØÑÂõ≤„Å´„ÇØ„É™„ÉÉ„Éó\n",
        "    tensor = torch.clamp(tensor, 0, 1)\n",
        "\n",
        "    # (C, H, W) -> (H, W, C)„Å´Â§âÊèõ\n",
        "    numpy_array = tensor.permute(1, 2, 0).cpu().numpy()\n",
        "\n",
        "    # [0, 255]„Å´Â§âÊèõ\n",
        "    numpy_array = (numpy_array * 255).astype(np.uint8)\n",
        "\n",
        "    # PIL Image„Å´Â§âÊèõ\n",
        "    image = Image.fromarray(numpy_array)\n",
        "\n",
        "    return image\n",
        "\n",
        "def process_images_folder(input_folder, output_folder, original_model, modified_model, device='cpu'):\n",
        "    \"\"\"\n",
        "    „Éï„Ç©„É´„ÉÄÂÜÖ„ÅÆÂÖ®ÁîªÂÉè„ÇíÂá¶ÁêÜ„Åó„Å¶FC layerÊåøÂÖ•ÂâçÂæå„ÅÆÁµêÊûú„Çí‰øùÂ≠ò\n",
        "\n",
        "    Args:\n",
        "        input_folder: ÂÖ•ÂäõÁîªÂÉè„Éï„Ç©„É´„ÉÄ„Éë„Çπ\n",
        "        output_folder: Âá∫ÂäõÁîªÂÉè„Éï„Ç©„É´„ÉÄ„Éë„Çπ\n",
        "        original_model: ÂÖÉ„ÅÆ„É¢„Éá„É´\n",
        "        modified_model: FC layer„ÅåÊåøÂÖ•„Åï„Çå„Åü„É¢„Éá„É´\n",
        "        device: ÂÆüË°å„Éá„Éê„Ç§„Çπ\n",
        "    \"\"\"\n",
        "    # Âá∫Âäõ„Éï„Ç©„É´„ÉÄ‰ΩúÊàê\n",
        "    output_folder = Path(output_folder)\n",
        "    output_folder.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # „Çµ„Éñ„Éï„Ç©„É´„ÉÄ‰ΩúÊàê\n",
        "    original_output = output_folder / \"original\"\n",
        "    modified_output = output_folder / \"with_fc\"\n",
        "    comparison_output = output_folder / \"comparison\"\n",
        "\n",
        "    original_output.mkdir(exist_ok=True)\n",
        "    modified_output.mkdir(exist_ok=True)\n",
        "    comparison_output.mkdir(exist_ok=True)\n",
        "\n",
        "    # „É¢„Éá„É´„ÇíË©ï‰æ°„É¢„Éº„Éâ„Å´Ë®≠ÂÆö\n",
        "    original_model.eval()\n",
        "    modified_model.eval()\n",
        "\n",
        "    # „Éá„Éê„Ç§„Çπ„Å´ÁßªÂãï\n",
        "    original_model.to(device)\n",
        "    modified_model.to(device)\n",
        "\n",
        "    # „Çµ„Éù„Éº„Éà„Åï„Çå„ÇãÁîªÂÉèÂΩ¢Âºè\n",
        "    supported_formats = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif'}\n",
        "\n",
        "    # ÂÖ•Âäõ„Éï„Ç©„É´„ÉÄÂÜÖ„ÅÆÁîªÂÉè„Éï„Ç°„Ç§„É´Ê§úÁ¥¢\n",
        "    input_folder = Path(input_folder)\n",
        "    image_files = [\n",
        "        f for f in input_folder.iterdir()\n",
        "        if f.suffix.lower() in supported_formats\n",
        "    ]\n",
        "\n",
        "    print(f\"\\n=== ÁîªÂÉèÂá¶ÁêÜÈñãÂßã ===\")\n",
        "    print(f\"ÂÖ•Âäõ„Éï„Ç©„É´„ÉÄ: {input_folder}\")\n",
        "    print(f\"Âá∫Âäõ„Éï„Ç©„É´„ÉÄ: {output_folder}\")\n",
        "    print(f\"Áô∫Ë¶ã„Åï„Çå„ÅüÁîªÂÉè„Éï„Ç°„Ç§„É´Êï∞: {len(image_files)}\")\n",
        "    print(f\"‰ΩøÁî®„Éá„Éê„Ç§„Çπ: {device}\")\n",
        "\n",
        "    for i, image_path in enumerate(image_files):\n",
        "        print(f\"\\nÂá¶ÁêÜ‰∏≠ ({i+1}/{len(image_files)}): {image_path.name}\")\n",
        "\n",
        "        try:\n",
        "            # ÁîªÂÉè„É≠„Éº„Éâ„Å®ÂâçÂá¶ÁêÜ\n",
        "            input_tensor = load_and_preprocess_image(str(image_path), target_size=(1600, 1200))\n",
        "            input_tensor = input_tensor.to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                # ÂÖÉ„ÅÆ„É¢„Éá„É´„ÅßÂá¶ÁêÜ\n",
        "                original_output_tensor = original_model(input_tensor)\n",
        "\n",
        "                # FC layer„ÅåÊåøÂÖ•„Åï„Çå„Åü„É¢„Éá„É´„ÅßÂá¶ÁêÜ\n",
        "                modified_output_tensor = modified_model(input_tensor)\n",
        "\n",
        "            # „ÉÜ„É≥„ÇΩ„É´„ÇíÁîªÂÉè„Å´Â§âÊèõ\n",
        "            original_image = tensor_to_image(original_output_tensor.cpu())\n",
        "            modified_image = tensor_to_image(modified_output_tensor.cpu())\n",
        "            input_image = tensor_to_image(input_tensor.cpu())\n",
        "\n",
        "            # „Éï„Ç°„Ç§„É´ÂêçÁîüÊàê\n",
        "            base_name = image_path.stem\n",
        "\n",
        "            # ÁµêÊûúÁîªÂÉè‰øùÂ≠ò\n",
        "            original_image.save(original_output / f\"{base_name}_original.png\")\n",
        "            modified_image.save(modified_output / f\"{base_name}_with_fc.png\")\n",
        "\n",
        "            # ÊØîËºÉÁîªÂÉè‰ΩúÊàêÔºàÊ®™‰∏¶„Å≥Ôºâ\n",
        "            comparison_image = create_comparison_image(\n",
        "                input_image, original_image, modified_image,\n",
        "                titles=[\"ÂÖ•Âäõ\", \"ÂÖÉ„ÅÆ„É¢„Éá„É´\", \"FCÊåøÂÖ•„É¢„Éá„É´\"]\n",
        "            )\n",
        "            comparison_image.save(comparison_output / f\"{base_name}_comparison.png\")\n",
        "\n",
        "            # Â∑ÆÂàÜË®àÁÆó\n",
        "            diff_tensor = torch.abs(original_output_tensor - modified_output_tensor)\n",
        "            max_diff = diff_tensor.max().item()\n",
        "            mean_diff = diff_tensor.mean().item()\n",
        "\n",
        "            print(f\"  ‚úì Âá¶ÁêÜÂÆå‰∫Ü\")\n",
        "            print(f\"    ÊúÄÂ§ßÂ∑ÆÂàÜ: {max_diff:.6f}\")\n",
        "            print(f\"    Âπ≥ÂùáÂ∑ÆÂàÜ: {mean_diff:.6f}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  ‚úó „Ç®„É©„ÉºÁô∫Áîü: {e}\")\n",
        "            continue\n",
        "\n",
        "    print(f\"\\n=== Âá¶ÁêÜÂÆå‰∫Ü ===\")\n",
        "    print(f\"ÁµêÊûú„ÅØ‰ª•‰∏ã„ÅÆ„Éï„Ç©„É´„ÉÄ„Å´‰øùÂ≠ò„Åï„Çå„Åæ„Åó„Åü:\")\n",
        "    print(f\"  ÂÖÉ„ÅÆ„É¢„Éá„É´ÁµêÊûú: {original_output}\")\n",
        "    print(f\"  FCÊåøÂÖ•„É¢„Éá„É´ÁµêÊûú: {modified_output}\")\n",
        "    print(f\"  ÊØîËºÉÁîªÂÉè: {comparison_output}\")\n",
        "\n",
        "def create_comparison_image(input_img, original_img, modified_img, titles=None):\n",
        "    \"\"\"\n",
        "    3„Å§„ÅÆÁîªÂÉè„ÇíÊ®™‰∏¶„Å≥„ÅßÊØîËºÉÁîªÂÉè„Çí‰ΩúÊàê\n",
        "\n",
        "    Args:\n",
        "        input_img: ÂÖ•ÂäõÁîªÂÉè\n",
        "        original_img: ÂÖÉ„ÅÆ„É¢„Éá„É´ÁµêÊûú\n",
        "        modified_img: ‰øÆÊ≠£„Åï„Çå„Åü„É¢„Éá„É´ÁµêÊûú\n",
        "        titles: ÂêÑÁîªÂÉè„ÅÆ„Çø„Ç§„Éà„É´\n",
        "\n",
        "    Returns:\n",
        "        ÊØîËºÉÁîªÂÉè\n",
        "    \"\"\"\n",
        "    from PIL import ImageDraw, ImageFont\n",
        "\n",
        "    # ÁîªÂÉè„Çµ„Ç§„Ç∫ÂèñÂæó\n",
        "    width, height = input_img.size\n",
        "\n",
        "    # ÊØîËºÉÁîªÂÉè‰ΩúÊàêÔºàÊ®™‰∏¶„Å≥ + „Çø„Ç§„Éà„É´È†òÂüüÔºâ\n",
        "    title_height = 30\n",
        "    comparison_width = width * 3\n",
        "    comparison_height = height + title_height\n",
        "\n",
        "    comparison_img = Image.new('RGB', (comparison_width, comparison_height), 'white')\n",
        "\n",
        "    # ÁîªÂÉèË≤º„Çä‰ªò„Åë\n",
        "    comparison_img.paste(input_img, (0, title_height))\n",
        "    comparison_img.paste(original_img, (width, title_height))\n",
        "    comparison_img.paste(modified_img, (width * 2, title_height))\n",
        "\n",
        "    # „Çø„Ç§„Éà„É´ËøΩÂä†\n",
        "    if titles:\n",
        "        draw = ImageDraw.Draw(comparison_img)\n",
        "        try:\n",
        "            # „Ç∑„Çπ„ÉÜ„É†„Éï„Ç©„É≥„Éà‰ΩøÁî®„ÇíË©¶Ë°å\n",
        "            font = ImageFont.truetype(\"arial.ttf\", 20)\n",
        "        except:\n",
        "            # „Éá„Éï„Ç©„É´„Éà„Éï„Ç©„É≥„Éà‰ΩøÁî®\n",
        "            font = ImageFont.load_default()\n",
        "\n",
        "        for i, title in enumerate(titles):\n",
        "            text_width = draw.textlength(title, font=font)\n",
        "            x = (width * i) + (width - text_width) // 2\n",
        "            draw.text((x, 5), title, fill='black', font=font)\n",
        "\n",
        "    return comparison_img\n",
        "\n",
        "def test_fc_insertion():\n",
        "    \"\"\"FC layerÊåøÂÖ•„ÉÜ„Çπ„Éà\"\"\"\n",
        "    print(\"=== FC LayerÊåøÂÖ•„ÉÜ„Çπ„Éà ===\")\n",
        "\n",
        "    # „ÉÄ„Éü„Éº„É¢„Éá„É´ÁîüÊàêÔºà„ÉÜ„Çπ„ÉàÁî®Ôºâ\n",
        "    class DummyModel(nn.Module):\n",
        "        def __init__(self):\n",
        "            super().__init__()\n",
        "            self.conv1 = nn.Conv2d(3, 64, 3, 1, 1)\n",
        "            self.conv2 = nn.Conv2d(64, 64, 3, 1, 1)\n",
        "            self.conv3 = nn.Conv2d(64, 32, 3, 1, 1)\n",
        "            self.conv4 = nn.Conv2d(32, 3, 3, 1, 1)\n",
        "            self.relu = nn.ReLU()\n",
        "\n",
        "        def forward(self, x):\n",
        "            x = self.relu(self.conv1(x))\n",
        "            x = self.relu(self.conv2(x))\n",
        "            x = self.relu(self.conv3(x))\n",
        "            x = self.conv4(x)\n",
        "            return x\n",
        "\n",
        "    dummy_model = DummyModel()\n",
        "\n",
        "    # FC layerÊåøÂÖ•„ÉÜ„Çπ„Éà\n",
        "    try:\n",
        "        modified_model, fc_layer = insert_fc_layer_into_model(\n",
        "            dummy_model, 'smallest', (1200, 1600), 'identity'\n",
        "        )\n",
        "        print(\"‚úì FC layerÊåøÂÖ•ÊàêÂäü\")\n",
        "\n",
        "        # „ÉÜ„Çπ„ÉàÂÆüË°å\n",
        "        test_input = torch.randn(1, 3, 1200, 1600)\n",
        "        with torch.no_grad():\n",
        "            output = modified_model(test_input)\n",
        "            print(f\"‚úì Forward passÊàêÂäü„ÄÅÂá∫Âäõ„Çµ„Ç§„Ç∫: {output.shape}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚úó „Ç®„É©„ÉºÁô∫Áîü: {e}\")\n",
        "\n",
        "def run_image_comparison_demo(input_folder, output_folder, model_path=None):\n",
        "    \"\"\"\n",
        "    ÁîªÂÉèÊØîËºÉ„Éá„É¢ÂÆüË°å\n",
        "\n",
        "    Args:\n",
        "        input_folder: ÂÖ•ÂäõÁîªÂÉè„Éï„Ç©„É´„ÉÄ\n",
        "        output_folder: Âá∫Âäõ„Éï„Ç©„É´„ÉÄ\n",
        "        model_path: „É¢„Éá„É´„Éï„Ç°„Ç§„É´„Éë„ÇπÔºà„Ç™„Éó„Ç∑„Éß„É≥Ôºâ\n",
        "    \"\"\"\n",
        "    print(\"=== ÁîªÂÉèÊØîËºÉ„Éá„É¢ÂÆüË°å ===\")\n",
        "\n",
        "    # „Éá„Éê„Ç§„ÇπË®≠ÂÆö\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"‰ΩøÁî®„Éá„Éê„Ç§„Çπ: {device}\")\n",
        "\n",
        "    if model_path and os.path.exists(model_path):\n",
        "        # ÂÆüÈöõ„ÅÆ„É¢„Éá„É´„Çí‰ΩøÁî®\n",
        "        try:\n",
        "            modified_model, fc_layer = insert_fc_into_real_esrgan(\n",
        "                model_path, fc_position='smallest', init_type='identity'\n",
        "            )\n",
        "            original_model = torch.load(model_path, map_location='cpu')\n",
        "        except Exception as e:\n",
        "            print(f\"ÂÆüÈöõ„ÅÆ„É¢„Éá„É´„É≠„Éº„Éâ„Å´Â§±Êïó: {e}\")\n",
        "            print(\"„ÉÄ„Éü„Éº„É¢„Éá„É´„Åß„Éá„É¢„ÇíÂÆüË°å„Åó„Åæ„Åô...\")\n",
        "            original_model, modified_model = create_dummy_models()\n",
        "    else:\n",
        "        print(\"„É¢„Éá„É´„Éë„Çπ„ÅåÊèê‰æõ„Åï„Çå„Å¶„ÅÑ„Å™„ÅÑ„Åü„ÇÅ„ÄÅ„ÉÄ„Éü„Éº„É¢„Éá„É´„Åß„Éá„É¢„ÇíÂÆüË°å„Åó„Åæ„Åô...\")\n",
        "        original_model, modified_model = create_dummy_models()\n",
        "\n",
        "    # ÁîªÂÉèÂá¶ÁêÜÂÆüË°å\n",
        "    process_images_folder(\n",
        "        input_folder=input_folder,\n",
        "        output_folder=output_folder,\n",
        "        original_model=original_model,\n",
        "        modified_model=modified_model,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "def create_dummy_models():\n",
        "    \"\"\"\n",
        "    „Éá„É¢Áî®„ÉÄ„Éü„Éº„É¢„Éá„É´‰ΩúÊàê\n",
        "    \"\"\"\n",
        "    class DummyModel(nn.Module):\n",
        "        def __init__(self):\n",
        "            super().__init__()\n",
        "            self.conv1 = nn.Conv2d(3, 32, 3, 1, 1)\n",
        "            self.conv2 = nn.Conv2d(32, 32, 3, 1, 1)\n",
        "            self.conv3 = nn.Conv2d(32, 3, 3, 1, 1)\n",
        "            self.relu = nn.ReLU()\n",
        "\n",
        "        def forward(self, x):\n",
        "            x = self.relu(self.conv1(x))\n",
        "            x = self.relu(self.conv2(x))\n",
        "            x = self.conv3(x)\n",
        "            return torch.clamp(x, 0, 1)\n",
        "\n",
        "    original_model = DummyModel()\n",
        "\n",
        "    # FC layer„ÇíÊåøÂÖ•„Åó„Åü„É¢„Éá„É´‰ΩúÊàê\n",
        "    modified_model, fc_layer = insert_fc_layer_into_model(\n",
        "        copy.deepcopy(original_model), 'middle', (1200, 1600), 'identity'\n",
        "    )\n",
        "\n",
        "    return original_model, modified_model\n",
        "\n",
        "# ‰ΩøÁî®‰æã\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=== Real-ESRGAN FC LayerÊåøÂÖ•„ÉÑ„Éº„É´ ===\")\n",
        "\n",
        "    # „ÉÜ„Çπ„ÉàÂÆüË°å\n",
        "    test_fc_insertion()\n",
        "\n",
        "    print(\"\\n=== ‰ΩøÁî®‰æã ===\")\n",
        "    print(\"# 1. ‰∫ãÂâçÂ≠¶Áøí„É¢„Éá„É´„Å´FC layerÊåøÂÖ•\")\n",
        "    print(\"model_path = 'path/to/your/real_esrgan_model.pth'\")\n",
        "    print(\"modified_model, fc_layer = insert_fc_into_real_esrgan(\")\n",
        "    print(\"    model_path=model_path,\")\n",
        "    print(\"    fc_position='smallest',  # 'middle', 'early', 'late', 'smallest' „Åæ„Åü„ÅØÁâπÂÆö„É¨„Ç§„É§„ÉºÂêç\")\n",
        "    print(\"    init_type='identity'     # 'identity' „Åæ„Åü„ÅØ 'random'\")\n",
        "    print(\")\")\n",
        "    print()\n",
        "    print(\"# 2. FC layerÈáç„ÅøÂÜçÂàùÊúüÂåñ\")\n",
        "    print(\"fc_layer.reinit_weights('random')\")\n",
        "    print()\n",
        "    print(\"# 3. ÁîªÂÉè„Éï„Ç©„É´„ÉÄÂá¶ÁêÜ\")\n",
        "    print(\"run_image_comparison_demo(\")\n",
        "    print(\"    input_folder='path/to/input/images',\")\n",
        "    print(\"    output_folder='path/to/output/results',\")\n",
        "    print(\"    model_path='path/to/model.pth'  # „Ç™„Éó„Ç∑„Éß„É≥\")\n",
        "    print(\")\")\n",
        "    print()\n",
        "    print(\"# 4. Áõ¥Êé•„É¢„Éá„É´„É≠„Éº„ÉâÂæåFC layerÊåøÂÖ•\")\n",
        "    print(\"model = torch.load('your_model.pth')\")\n",
        "    print(\"modified_model, fc_layer = insert_fc_layer_into_model(\")\n",
        "    print(\"    model, 'middle', (1200, 1600), 'identity')\")\n",
        "    print()\n",
        "    print(\"# 5. ÂÄãÂà•ÁîªÂÉèÂá¶ÁêÜ\")\n",
        "    print(\"process_images_folder(\")\n",
        "    print(\"    'input_folder', 'output_folder', original_model, modified_model\")\n",
        "    print(\")\")"
      ],
      "metadata": {
        "id": "BnIjZz4VXOsY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}