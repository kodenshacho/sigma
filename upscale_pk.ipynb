{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kodenshacho/sigma/blob/master/upscale_pk.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.onnx\n",
        "import cv2\n",
        "import numpy as np\n",
        "from basicsr.archs.rrdbnet_arch import RRDBNet\n",
        "\n",
        "# --- ãƒ¬ã‚¤ãƒ¤ãƒ¼å®šç¾©ï¼ˆFlatten â†’ FC â†’ Reshapeï¼‰ ---\n",
        "class IdentityFC(nn.Module):\n",
        "    def __init__(self, shape, random_init=False):\n",
        "        super().__init__()\n",
        "        self.shape = shape  # (C, H, W)\n",
        "        flat_dim = shape[0] * shape[1] * shape[2]\n",
        "        self.fc = nn.Linear(flat_dim, flat_dim, bias=False)\n",
        "\n",
        "        if random_init:\n",
        "            self.init_random()\n",
        "        else:\n",
        "            self.init_identity(flat_dim)\n",
        "\n",
        "    def init_identity(self, dim):\n",
        "        with torch.no_grad():\n",
        "            weight = torch.zeros((dim, dim))\n",
        "            for i in range(dim):\n",
        "                weight[i, i] = 1.0\n",
        "            self.fc.weight.copy_(weight)\n",
        "\n",
        "    def init_random(self):\n",
        "        nn.init.kaiming_normal_(self.fc.weight, a=0.01)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, h, w = x.shape\n",
        "        x_flat = x.view(b, -1)\n",
        "        x_fc = self.fc(x_flat)\n",
        "        return x_fc.view(b, c, h, w)\n",
        "\n",
        "# --- Real-ESRGANãƒ¢ãƒ‡ãƒ«ã«FCãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’æŒ¿å…¥ ---\n",
        "def insert_fc_into_pretrained(model: nn.Module, random_init=False, verbose=True):\n",
        "    dummy = torch.randn(1, 3, 1200, 1600)\n",
        "    with torch.no_grad():\n",
        "        x = model.conv_first(dummy)\n",
        "        min_area = x.shape[2] * x.shape[3]\n",
        "        min_idx = -1\n",
        "        feature_maps = []\n",
        "\n",
        "        for i, layer in enumerate(model.body):\n",
        "            x = layer(x)\n",
        "            area = x.shape[2] * x.shape[3]\n",
        "            feature_maps.append(x)\n",
        "            if area < min_area:\n",
        "                min_area = area\n",
        "                min_idx = i\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"ğŸ” æœ€å°ç‰¹å¾´ãƒãƒƒãƒ—ä½ç½®: model.body[{min_idx}]ã€ã‚µã‚¤ã‚º: {feature_maps[min_idx].shape}\")\n",
        "\n",
        "    before = list(model.body.children())[:min_idx + 1]\n",
        "    after = list(model.body.children())[min_idx + 1:]\n",
        "\n",
        "    fc_layer = IdentityFC(shape=feature_maps[min_idx].shape[1:], random_init=random_init)\n",
        "    model.body = nn.Sequential(*before, fc_layer, *after)\n",
        "    return model\n",
        "\n",
        "# --- ONNXãƒ•ã‚¡ã‚¤ãƒ«ã«å¤‰æ› ---\n",
        "def export_to_onnx(model, input_tensor, onnx_path=\"exported_model.onnx\"):\n",
        "    model.eval()\n",
        "    torch.onnx.export(model, input_tensor, onnx_path,\n",
        "                      input_names=['input'], output_names=['output'],\n",
        "                      dynamic_axes={'input': {0: 'batch'}, 'output': {0: 'batch'}},\n",
        "                      opset_version=11)\n",
        "    print(f\"âœ… ONNXã¨ã—ã¦ä¿å­˜ã•ã‚Œã¾ã—ãŸ: {onnx_path}\")\n",
        "\n",
        "# --- ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ï¼ˆrandom_init=True ã®å ´åˆï¼‰ ---\n",
        "def train_model(model, target_model, epochs=1, lr=1e-4):\n",
        "    model.train()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    loss_fn = nn.MSELoss()\n",
        "    dummy_input = torch.randn(1, 3, 1200, 1600)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        target_output = target_model(dummy_input)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        optimizer.zero_grad()\n",
        "        output = model(dummy_input)\n",
        "        loss = loss_fn(output, target_output)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        print(f\"ğŸ§ª Epoch {epoch+1}/{epochs}, Loss: {loss.item():.6f}\")\n",
        "\n",
        "# --- GUIã§çµæœã‚’æ¯”è¼ƒï¼ˆOpenCVï¼‰ ---\n",
        "def visualize_output(output1, output2):\n",
        "    def tensor_to_cv(img):\n",
        "        img = img.squeeze().permute(1, 2, 0).clamp(0, 1).cpu().numpy()\n",
        "        img = (img * 255).astype(np.uint8)\n",
        "        return cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    img1 = tensor_to_cv(output1)\n",
        "    img2 = tensor_to_cv(output2)\n",
        "    combined = np.hstack((img1, img2))\n",
        "    cv2.imshow('å·¦: Pretrained, å³: FCä»˜ã', combined)\n",
        "    cv2.waitKey(0)\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "# --- ãƒ¡ã‚¤ãƒ³é–¢æ•° ---\n",
        "def main():\n",
        "    # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿\n",
        "    model_path = 'pretrained/RealESRGAN_x1_fixed_1600x1200.pth'\n",
        "    model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64,\n",
        "                    num_block=23, num_grow_ch=32, scale=1)\n",
        "    model.load_state_dict(torch.load(model_path), strict=True)\n",
        "    model.eval()\n",
        "\n",
        "    # FCä»˜ããƒ¢ãƒ‡ãƒ«ä½œæˆï¼ˆãƒ©ãƒ³ãƒ€ãƒ  or ã‚¢ã‚¤ãƒ‡ãƒ³ãƒ†ã‚£ãƒ†ã‚£åˆæœŸåŒ–ï¼‰\n",
        "    use_random_init = True  # â† Trueã®å ´åˆã€è¨“ç·´ã‚‚è¡Œã‚ã‚Œã‚‹\n",
        "    model_fc = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64,\n",
        "                       num_block=23, num_grow_ch=32, scale=1)\n",
        "    model_fc.load_state_dict(torch.load(model_path), strict=True)\n",
        "    model_fc = insert_fc_into_pretrained(model_fc, random_init=use_random_init, verbose=True)\n",
        "\n",
        "    # å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ\n",
        "    input_img = torch.randn(1, 3, 1200, 1600)\n",
        "\n",
        "    # å­¦ç¿’ï¼ˆå¿…è¦ãªå ´åˆã®ã¿ï¼‰\n",
        "    if use_random_init:\n",
        "        print(\"âš™ï¸ FCãƒ¬ã‚¤ãƒ¤ãƒ¼ã®ãƒ©ãƒ³ãƒ€ãƒ åˆæœŸåŒ–ã«å¯¾ã—ã¦å¾®èª¿æ•´ã‚’è¡Œã„ã¾ã™...\")\n",
        "        train_model(model_fc, model, epochs=3)\n",
        "\n",
        "    # å‡ºåŠ›è¨ˆç®—\n",
        "    with torch.no_grad():\n",
        "        out1 = model(input_img)\n",
        "        out2 = model_fc(input_img)\n",
        "        is_same = torch.allclose(out1, out2, atol=1e-6)\n",
        "        print(f\"âœ… å‡ºåŠ›ä¸€è‡´: {is_same}\")\n",
        "\n",
        "    # .pthãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜\n",
        "    torch.save(model_fc.state_dict(), \"modified_model_fc.pth\")\n",
        "    print(\"âœ… FCä»˜ããƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: modified_model_fc.pth\")\n",
        "\n",
        "    # ONNXå½¢å¼ã¨ã—ã¦ä¿å­˜\n",
        "    export_to_onnx(model_fc, input_img, onnx_path=\"modified_model_fc.onnx\")\n",
        "\n",
        "    # GUIã§å‡ºåŠ›ç”»åƒã‚’æ¯”è¼ƒ\n",
        "    visualize_output(out1, out2)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "9jmRTUQA0qaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from basicsr.archs.rrdbnet_arch import RRDBNet\n",
        "from insert_fc import insert_fc_into_pretrained\n",
        "\n",
        "def test_model_with_fc():\n",
        "    # å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿\n",
        "    model_path = 'pretrained/RealESRGAN_x1_fixed_1600x1200.pth'\n",
        "    model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64,\n",
        "                    num_block=23, num_grow_ch=32, scale=1)\n",
        "    model.load_state_dict(torch.load(model_path), strict=True)\n",
        "    model.eval()\n",
        "\n",
        "    # ãƒ¢ãƒ‡ãƒ«ã‚’è¤‡è£½ã—ã¦ã€FCãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’æŒ¿å…¥\n",
        "    model_fc = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64,\n",
        "                       num_block=23, num_grow_ch=32, scale=1)\n",
        "    model_fc.load_state_dict(torch.load(model_path), strict=True)\n",
        "    model_fc = insert_fc_into_pretrained(model_fc, random_init=False, verbose=True)\n",
        "    model_fc.eval()\n",
        "\n",
        "    # ãƒ†ã‚¹ãƒˆç”¨ç”»åƒï¼ˆãƒ©ãƒ³ãƒ€ãƒ ï¼‰\n",
        "    input_img = torch.randn(1, 3, 1200, 1600)\n",
        "\n",
        "    # å‡ºåŠ›ã‚’æ¯”è¼ƒ\n",
        "    with torch.no_grad():\n",
        "        out1 = model(input_img)\n",
        "        out2 = model_fc(input_img)\n",
        "        is_same = torch.allclose(out1, out2, atol=1e-6)\n",
        "\n",
        "    print(f\"âœ… å‡ºåŠ›ãŒä¸€è‡´ã™ã‚‹ã‹: {is_same}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    test_model_with_fc()"
      ],
      "metadata": {
        "id": "i3Vumssf1cDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "import numpy as np\n",
        "from collections import OrderedDict\n",
        "import copy\n",
        "import os\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from pathlib import Path\n",
        "\n",
        "class IdentityFullyConnected(nn.Module):\n",
        "    \"\"\"\n",
        "    ç©ºé–“æƒ…å ±ã‚’ç¶­æŒã—ãªãŒã‚‰identity mappingã‚’å®Ÿè¡Œã™ã‚‹FC layer\n",
        "    \"\"\"\n",
        "    def __init__(self, num_channels, height, width, init_type='identity'):\n",
        "        super(IdentityFullyConnected, self).__init__()\n",
        "        self.num_channels = num_channels\n",
        "        self.height = height\n",
        "        self.width = width\n",
        "        self.total_size = num_channels * height * width\n",
        "\n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(self.total_size, self.total_size, bias=False)\n",
        "\n",
        "        # é‡ã¿åˆæœŸåŒ–\n",
        "        self.init_weights(init_type)\n",
        "\n",
        "    def init_weights(self, init_type='identity'):\n",
        "        \"\"\"\n",
        "        é‡ã¿åˆæœŸåŒ–é–¢æ•°\n",
        "        Args:\n",
        "            init_type: 'identity' ã¾ãŸã¯ 'random'\n",
        "        \"\"\"\n",
        "        with torch.no_grad():\n",
        "            if init_type == 'identity':\n",
        "                # Identity matrixåˆæœŸåŒ–ï¼ˆå¯¾è§’ç·š1ã€ãã‚Œä»¥å¤–0ï¼‰\n",
        "                self.fc.weight.data = torch.eye(self.total_size)\n",
        "            elif init_type == 'random':\n",
        "                # Xavier uniformåˆæœŸåŒ–\n",
        "                nn.init.xavier_uniform_(self.fc.weight)\n",
        "            else:\n",
        "                raise ValueError(\"init_type must be 'identity' or 'random'\")\n",
        "\n",
        "    def reinit_weights(self, init_type='identity'):\n",
        "        \"\"\"é‡ã¿å†åˆæœŸåŒ–é–¢æ•°\"\"\"\n",
        "        self.init_weights(init_type)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        # (B, C, H, W) -> (B, C*H*W)\n",
        "        x_flat = x.view(batch_size, -1)\n",
        "\n",
        "        # Fully connected layeré©ç”¨\n",
        "        out_flat = self.fc(x_flat)\n",
        "\n",
        "        # (B, C*H*W) -> (B, C, H, W)\n",
        "        out = out_flat.view(batch_size, self.num_channels, self.height, self.width)\n",
        "\n",
        "        return out\n",
        "\n",
        "class ModelWrapper(nn.Module):\n",
        "    \"\"\"\n",
        "    æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã®ä¸­é–“ã«FC layerã‚’æŒ¿å…¥ã™ã‚‹ãŸã‚ã®ãƒ©ãƒƒãƒ‘ãƒ¼ã‚¯ãƒ©ã‚¹\n",
        "    \"\"\"\n",
        "    def __init__(self, original_model, fc_layer, insert_after_layer):\n",
        "        super(ModelWrapper, self).__init__()\n",
        "        self.original_model = original_model\n",
        "        self.fc_layer = fc_layer\n",
        "        self.insert_after_layer = insert_after_layer\n",
        "\n",
        "        # å…ƒã®ãƒ¢ãƒ‡ãƒ«ã®forwardã‚’ãƒ•ãƒƒã‚¯ã—ã¦FC layerã‚’ä¸­é–“ã«æŒ¿å…¥\n",
        "        self._setup_forward_hook()\n",
        "\n",
        "    def _setup_forward_hook(self):\n",
        "        \"\"\"Forward hookã‚’è¨­å®šã—ã¦FC layerã‚’ä¸­é–“ã«æŒ¿å…¥\"\"\"\n",
        "        self.activation = {}\n",
        "\n",
        "        def get_activation(name):\n",
        "            def hook(model, input, output):\n",
        "                self.activation[name] = output\n",
        "            return hook\n",
        "\n",
        "        # æŒ‡å®šã•ã‚ŒãŸãƒ¬ã‚¤ãƒ¤ãƒ¼å¾Œã«hookè¨­å®š\n",
        "        target_layer = self._get_layer_by_name(self.original_model, self.insert_after_layer)\n",
        "        if target_layer is not None:\n",
        "            target_layer.register_forward_hook(get_activation(self.insert_after_layer))\n",
        "\n",
        "    def _get_layer_by_name(self, model, layer_name):\n",
        "        \"\"\"ãƒ¬ã‚¤ãƒ¤ãƒ¼åã§å®Ÿéš›ã®ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’è¦‹ã¤ã‘ã‚‹\"\"\"\n",
        "        names = layer_name.split('.')\n",
        "        layer = model\n",
        "        for name in names:\n",
        "            if hasattr(layer, name):\n",
        "                layer = getattr(layer, name)\n",
        "            else:\n",
        "                return None\n",
        "        return layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        # ã“ã®æ–¹æ³•ã¯è¤‡é›‘ãªã®ã§ä»–ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ä½¿ç”¨\n",
        "        pass\n",
        "\n",
        "def insert_fc_layer_into_model(model, fc_position='middle', input_size=(1200, 1600), init_type='identity'):\n",
        "    \"\"\"\n",
        "    æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ã«IdentityFullyConnected layerã‚’æŒ¿å…¥ã™ã‚‹é–¢æ•°\n",
        "\n",
        "    Args:\n",
        "        model: ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸäº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«\n",
        "        fc_position: FC layeræŒ¿å…¥ä½ç½® ('middle', 'early', 'late' ã¾ãŸã¯ç‰¹å®šãƒ¬ã‚¤ãƒ¤ãƒ¼å)\n",
        "        input_size: å…¥åŠ›ç”»åƒã‚µã‚¤ã‚º (H, W)\n",
        "        init_type: FC layeråˆæœŸåŒ–æ–¹æ³• ('identity' or 'random')\n",
        "\n",
        "    Returns:\n",
        "        æ–°ã—ã„ãƒ¢ãƒ‡ãƒ« (FC layerãŒæŒ¿å…¥ã•ã‚ŒãŸ)\n",
        "    \"\"\"\n",
        "\n",
        "    # ãƒ¢ãƒ‡ãƒ«æ§‹é€ åˆ†æ\n",
        "    print(\"=== å…ƒã®ãƒ¢ãƒ‡ãƒ«æ§‹é€ åˆ†æ ===\")\n",
        "    layer_info = analyze_model_structure(model, input_size)\n",
        "\n",
        "    # FC layeræŒ¿å…¥ä½ç½®æ±ºå®š\n",
        "    insert_layer_name = determine_insert_position(layer_info, fc_position)\n",
        "    print(f\"FC layeræŒ¿å…¥ä½ç½®: {insert_layer_name}\")\n",
        "\n",
        "    # æŒ¿å…¥ä½ç½®ã®feature mapã‚µã‚¤ã‚ºç¢ºèª\n",
        "    target_layer_info = None\n",
        "    for info in layer_info:\n",
        "        if info['name'] == insert_layer_name:\n",
        "            target_layer_info = info\n",
        "            break\n",
        "\n",
        "    if target_layer_info is None:\n",
        "        raise ValueError(f\"Layer {insert_layer_name} not found\")\n",
        "\n",
        "    output_shape = target_layer_info['output_shape']\n",
        "    num_channels = output_shape[1]\n",
        "    height = output_shape[2]\n",
        "    width = output_shape[3]\n",
        "\n",
        "    print(f\"FC layerè¨­å®š: channels={num_channels}, height={height}, width={width}\")\n",
        "\n",
        "    # IdentityFullyConnected layerç”Ÿæˆ\n",
        "    fc_layer = IdentityFullyConnected(num_channels, height, width, init_type)\n",
        "\n",
        "    # æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ç”Ÿæˆ (FC layeræŒ¿å…¥)\n",
        "    modified_model = create_modified_model(model, fc_layer, insert_layer_name)\n",
        "\n",
        "    return modified_model, fc_layer\n",
        "\n",
        "def analyze_model_structure(model, input_size=(1200, 1600)):\n",
        "    \"\"\"\n",
        "    ãƒ¢ãƒ‡ãƒ«æ§‹é€ ã‚’åˆ†æã—ã¦å„ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®å‡ºåŠ›ã‚µã‚¤ã‚ºã‚’ç¢ºèª\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    layer_info = []\n",
        "\n",
        "    # ãƒ†ã‚¹ãƒˆå…¥åŠ›ç”Ÿæˆ\n",
        "    test_input = torch.randn(1, 3, input_size[0], input_size[1])\n",
        "\n",
        "    # Forward hookã‚’ä½¿ç”¨ã—ã¦å„ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®å‡ºåŠ›ã‚µã‚¤ã‚ºã‚’è¨˜éŒ²\n",
        "    def hook_fn(name):\n",
        "        def hook(module, input, output):\n",
        "            if isinstance(output, torch.Tensor):\n",
        "                layer_info.append({\n",
        "                    'name': name,\n",
        "                    'module': module,\n",
        "                    'output_shape': list(output.shape),\n",
        "                    'output_size': output.numel()\n",
        "                })\n",
        "        return hook\n",
        "\n",
        "    # å…¨ãƒ¬ã‚¤ãƒ¤ãƒ¼ã«hookç™»éŒ²\n",
        "    hooks = []\n",
        "    for name, module in model.named_modules():\n",
        "        if len(list(module.children())) == 0:  # leaf moduleã®ã¿\n",
        "            hook = module.register_forward_hook(hook_fn(name))\n",
        "            hooks.append(hook)\n",
        "\n",
        "    # Forward passå®Ÿè¡Œ\n",
        "    with torch.no_grad():\n",
        "        _ = model(test_input)\n",
        "\n",
        "    # Hookå‰Šé™¤\n",
        "    for hook in hooks:\n",
        "        hook.remove()\n",
        "\n",
        "    # çµæœå‡ºåŠ›\n",
        "    print(\"\\nãƒ¬ã‚¤ãƒ¤ãƒ¼åˆ¥å‡ºåŠ›ã‚µã‚¤ã‚º:\")\n",
        "    for i, info in enumerate(layer_info):\n",
        "        print(f\"{i:2d}. {info['name']:<30} : {info['output_shape']} (ã‚µã‚¤ã‚º: {info['output_size']:,})\")\n",
        "\n",
        "    return layer_info\n",
        "\n",
        "def determine_insert_position(layer_info, fc_position):\n",
        "    \"\"\"\n",
        "    FC layeræŒ¿å…¥ä½ç½®æ±ºå®š\n",
        "    \"\"\"\n",
        "    if fc_position == 'middle':\n",
        "        # ä¸­é–“ä½ç½®ï¼ˆå…¨ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®ä¸­é–“ï¼‰\n",
        "        middle_idx = len(layer_info) // 2\n",
        "        return layer_info[middle_idx]['name']\n",
        "    elif fc_position == 'early':\n",
        "        # åˆæœŸä½ç½®ï¼ˆå…¨ä½“ã®1/4åœ°ç‚¹ï¼‰\n",
        "        early_idx = len(layer_info) // 4\n",
        "        return layer_info[early_idx]['name']\n",
        "    elif fc_position == 'late':\n",
        "        # å¾ŒåŠä½ç½®ï¼ˆå…¨ä½“ã®3/4åœ°ç‚¹ï¼‰\n",
        "        late_idx = (len(layer_info) * 3) // 4\n",
        "        return layer_info[late_idx]['name']\n",
        "    elif fc_position == 'smallest':\n",
        "        # æœ€ã‚‚å°ã•ã„feature mapã‚µã‚¤ã‚ºã‚’æŒã¤ä½ç½®\n",
        "        min_size = min(info['output_size'] for info in layer_info)\n",
        "        for info in layer_info:\n",
        "            if info['output_size'] == min_size:\n",
        "                return info['name']\n",
        "    else:\n",
        "        # ç‰¹å®šãƒ¬ã‚¤ãƒ¤ãƒ¼åãŒä¸ãˆã‚‰ã‚ŒãŸå ´åˆ\n",
        "        return fc_position\n",
        "\n",
        "def create_modified_model(original_model, fc_layer, insert_after_layer):\n",
        "    \"\"\"\n",
        "    å…ƒã®ãƒ¢ãƒ‡ãƒ«ã®æŒ‡å®šä½ç½®ã«FC layerã‚’æŒ¿å…¥ã—ãŸæ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ç”Ÿæˆ\n",
        "    \"\"\"\n",
        "\n",
        "    class ModifiedModel(nn.Module):\n",
        "        def __init__(self, original_model, fc_layer, insert_after_layer):\n",
        "            super(ModifiedModel, self).__init__()\n",
        "            self.original_model = original_model\n",
        "            self.fc_layer = fc_layer\n",
        "            self.insert_after_layer = insert_after_layer\n",
        "\n",
        "            # æŒ¿å…¥ä½ç½®ã‚’è¦‹ã¤ã‘ã‚‹\n",
        "            self.layers_before = nn.ModuleList()\n",
        "            self.layers_after = nn.ModuleList()\n",
        "            self.target_layer = None\n",
        "\n",
        "            self._split_model()\n",
        "\n",
        "        def _split_model(self):\n",
        "            \"\"\"ãƒ¢ãƒ‡ãƒ«ã‚’æŒ¿å…¥åœ°ç‚¹åŸºæº–ã§åˆ†å‰²\"\"\"\n",
        "            found_target = False\n",
        "\n",
        "            for name, module in self.original_model.named_modules():\n",
        "                if len(list(module.children())) == 0:  # leaf moduleã®ã¿\n",
        "                    if name == self.insert_after_layer:\n",
        "                        self.target_layer = module\n",
        "                        found_target = True\n",
        "                    elif not found_target:\n",
        "                        self.layers_before.append(module)\n",
        "                    else:\n",
        "                        self.layers_after.append(module)\n",
        "\n",
        "        def forward(self, x):\n",
        "            # ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯è¤‡é›‘ã€‚ä»£ã‚ã‚Šã«ã‚ˆã‚Šç°¡å˜ãªæ–¹æ³•ã‚’ä½¿ç”¨\n",
        "            return self._forward_with_fc(x)\n",
        "\n",
        "        def _forward_with_fc(self, x):\n",
        "            # å…ƒã®ãƒ¢ãƒ‡ãƒ«ã®forwardã‚’ä¿®æ­£ã—ã¦FC layerã‚’æŒ¿å…¥\n",
        "            # ã“ã‚Œã¯ãƒ¢ãƒ‡ãƒ«æ§‹é€ ã«ã‚ˆã£ã¦ç•°ãªã‚‹ã®ã§ä¸€èˆ¬çš„ãªè§£æ±ºç­–ã‚’æä¾›\n",
        "\n",
        "            # Hookã‚’ä½¿ç”¨ã—ãŸæ–¹æ³•\n",
        "            activation = {}\n",
        "\n",
        "            def get_activation(name):\n",
        "                def hook(model, input, output):\n",
        "                    activation[name] = output\n",
        "                return hook\n",
        "\n",
        "            # Target layerã«hookè¨­å®š\n",
        "            target_module = self._get_module_by_name(self.original_model, self.insert_after_layer)\n",
        "            hook = target_module.register_forward_hook(get_activation('target'))\n",
        "\n",
        "            # å…ƒã®forwardå®Ÿè¡Œ\n",
        "            result = self.original_model(x)\n",
        "\n",
        "            # Hookå‰Šé™¤\n",
        "            hook.remove()\n",
        "\n",
        "            # ä¸­é–“çµæœã‚’å¾—ãŸã‚‰FC layeré©ç”¨å¾Œæ®‹ã‚Šã®è¨ˆç®—\n",
        "            # ã“ã‚Œã¯ãƒ¢ãƒ‡ãƒ«æ§‹é€ ãŒè¤‡é›‘ãªã®ã§å®Ÿéš›ã«ã¯ãƒ¢ãƒ‡ãƒ«åˆ¥ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºãŒå¿…è¦\n",
        "\n",
        "            return result\n",
        "\n",
        "        def _get_module_by_name(self, model, name):\n",
        "            \"\"\"ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åã§å®Ÿéš›ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’è¦‹ã¤ã‘ã‚‹\"\"\"\n",
        "            names = name.split('.')\n",
        "            module = model\n",
        "            for n in names:\n",
        "                module = getattr(module, n)\n",
        "            return module\n",
        "\n",
        "    # ç°¡å˜ãªãƒ©ãƒƒãƒ‘ãƒ¼ãƒ¢ãƒ‡ãƒ«ç”Ÿæˆ\n",
        "    class SimpleModifiedModel(nn.Module):\n",
        "        def __init__(self, original_model, fc_layer):\n",
        "            super(SimpleModifiedModel, self).__init__()\n",
        "            self.original_model = original_model\n",
        "            self.fc_layer = fc_layer\n",
        "            self.insert_point_found = False\n",
        "\n",
        "        def forward(self, x):\n",
        "            # ã“ã‚Œã¯ä¾‹ã§ã‚ã‚Šã€å®Ÿéš›ã«ã¯ç‰¹å®šã®ãƒ¢ãƒ‡ãƒ«æ§‹é€ ã«åˆã‚ã›ã¦ä¿®æ­£ãŒå¿…è¦\n",
        "            return self.original_model(x)\n",
        "\n",
        "    return SimpleModifiedModel(original_model, fc_layer)\n",
        "\n",
        "def insert_fc_into_real_esrgan(model_path, fc_position='smallest', init_type='identity'):\n",
        "    \"\"\"\n",
        "    Real-ESRGANãƒ¢ãƒ‡ãƒ«ã«FC layerã‚’æŒ¿å…¥ã™ã‚‹ãƒ¡ã‚¤ãƒ³é–¢æ•°\n",
        "\n",
        "    Args:\n",
        "        model_path: äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹\n",
        "        fc_position: FC layeræŒ¿å…¥ä½ç½®\n",
        "        init_type: åˆæœŸåŒ–æ–¹æ³•\n",
        "\n",
        "    Returns:\n",
        "        ä¿®æ­£ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã€FC layerã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ\n",
        "    \"\"\"\n",
        "    print(f\"ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ä¸­: {model_path}\")\n",
        "\n",
        "    # ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰\n",
        "    checkpoint = torch.load(model_path, map_location='cpu')\n",
        "\n",
        "    if isinstance(checkpoint, dict):\n",
        "        if 'params' in checkpoint:\n",
        "            model_state = checkpoint['params']\n",
        "        elif 'state_dict' in checkpoint:\n",
        "            model_state = checkpoint['state_dict']\n",
        "        else:\n",
        "            model_state = checkpoint\n",
        "    else:\n",
        "        model = checkpoint\n",
        "\n",
        "    # ãƒ¢ãƒ‡ãƒ«ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã§ã¯ãªã„state_dictã®å ´åˆãƒ¢ãƒ‡ãƒ«æ§‹é€ å†æ§‹æˆãŒå¿…è¦\n",
        "    # ã“ã“ã§ã¯æ—¢ã«ãƒ¢ãƒ‡ãƒ«ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã ã¨ä»®å®š\n",
        "    if not isinstance(checkpoint, nn.Module):\n",
        "        raise ValueError(\"ãƒ¢ãƒ‡ãƒ«ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ç›´æ¥ãƒ­ãƒ¼ãƒ‰ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚state_dictã§ã¯ãªãå…¨ä½“ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¦ãã ã•ã„ã€‚\")\n",
        "\n",
        "    model = checkpoint\n",
        "\n",
        "    # FC layeræŒ¿å…¥\n",
        "    modified_model, fc_layer = insert_fc_layer_into_model(\n",
        "        model, fc_position, input_size=(1200, 1600), init_type=init_type\n",
        "    )\n",
        "\n",
        "    return modified_model, fc_layer\n",
        "\n",
        "def load_and_preprocess_image(image_path, target_size=(1600, 1200)):\n",
        "    \"\"\"\n",
        "    ç”»åƒã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦å‰å‡¦ç†ã™ã‚‹é–¢æ•°\n",
        "\n",
        "    Args:\n",
        "        image_path: ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹\n",
        "        target_size: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚µã‚¤ã‚º (W, H)\n",
        "\n",
        "    Returns:\n",
        "        å‰å‡¦ç†ã•ã‚ŒãŸç”»åƒãƒ†ãƒ³ã‚½ãƒ«\n",
        "    \"\"\"\n",
        "    # ç”»åƒèª­ã¿è¾¼ã¿\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "\n",
        "    # ã‚µã‚¤ã‚ºèª¿æ•´\n",
        "    image = image.resize(target_size, Image.LANCZOS)\n",
        "\n",
        "    # ãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNetæ­£è¦åŒ–ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰\n",
        "    ])\n",
        "\n",
        "    image_tensor = transform(image).unsqueeze(0)  # ãƒãƒƒãƒæ¬¡å…ƒè¿½åŠ \n",
        "\n",
        "    return image_tensor\n",
        "\n",
        "def tensor_to_image(tensor):\n",
        "    \"\"\"\n",
        "    ãƒ†ãƒ³ã‚½ãƒ«ã‚’PILç”»åƒã«å¤‰æ›\n",
        "\n",
        "    Args:\n",
        "        tensor: ç”»åƒãƒ†ãƒ³ã‚½ãƒ« (1, C, H, W)\n",
        "\n",
        "    Returns:\n",
        "        PIL Image\n",
        "    \"\"\"\n",
        "    # ãƒ†ãƒ³ã‚½ãƒ«ã‹ã‚‰numpyé…åˆ—ã«å¤‰æ›\n",
        "    if tensor.dim() == 4:\n",
        "        tensor = tensor.squeeze(0)  # ãƒãƒƒãƒæ¬¡å…ƒå‰Šé™¤\n",
        "\n",
        "    # [0, 1]ç¯„å›²ã«ã‚¯ãƒªãƒƒãƒ—\n",
        "    tensor = torch.clamp(tensor, 0, 1)\n",
        "\n",
        "    # (C, H, W) -> (H, W, C)ã«å¤‰æ›\n",
        "    numpy_array = tensor.permute(1, 2, 0).cpu().numpy()\n",
        "\n",
        "    # [0, 255]ã«å¤‰æ›\n",
        "    numpy_array = (numpy_array * 255).astype(np.uint8)\n",
        "\n",
        "    # PIL Imageã«å¤‰æ›\n",
        "    image = Image.fromarray(numpy_array)\n",
        "\n",
        "    return image\n",
        "\n",
        "def process_images_folder(input_folder, output_folder, original_model, modified_model, device='cpu'):\n",
        "    \"\"\"\n",
        "    ãƒ•ã‚©ãƒ«ãƒ€å†…ã®å…¨ç”»åƒã‚’å‡¦ç†ã—ã¦FC layeræŒ¿å…¥å‰å¾Œã®çµæœã‚’ä¿å­˜\n",
        "\n",
        "    Args:\n",
        "        input_folder: å…¥åŠ›ç”»åƒãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹\n",
        "        output_folder: å‡ºåŠ›ç”»åƒãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹\n",
        "        original_model: å…ƒã®ãƒ¢ãƒ‡ãƒ«\n",
        "        modified_model: FC layerãŒæŒ¿å…¥ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«\n",
        "        device: å®Ÿè¡Œãƒ‡ãƒã‚¤ã‚¹\n",
        "    \"\"\"\n",
        "    # å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€ä½œæˆ\n",
        "    output_folder = Path(output_folder)\n",
        "    output_folder.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€ä½œæˆ\n",
        "    original_output = output_folder / \"original\"\n",
        "    modified_output = output_folder / \"with_fc\"\n",
        "    comparison_output = output_folder / \"comparison\"\n",
        "\n",
        "    original_output.mkdir(exist_ok=True)\n",
        "    modified_output.mkdir(exist_ok=True)\n",
        "    comparison_output.mkdir(exist_ok=True)\n",
        "\n",
        "    # ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰ã«è¨­å®š\n",
        "    original_model.eval()\n",
        "    modified_model.eval()\n",
        "\n",
        "    # ãƒ‡ãƒã‚¤ã‚¹ã«ç§»å‹•\n",
        "    original_model.to(device)\n",
        "    modified_model.to(device)\n",
        "\n",
        "    # ã‚µãƒãƒ¼ãƒˆã•ã‚Œã‚‹ç”»åƒå½¢å¼\n",
        "    supported_formats = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif'}\n",
        "\n",
        "    # å…¥åŠ›ãƒ•ã‚©ãƒ«ãƒ€å†…ã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢\n",
        "    input_folder = Path(input_folder)\n",
        "    image_files = [\n",
        "        f for f in input_folder.iterdir()\n",
        "        if f.suffix.lower() in supported_formats\n",
        "    ]\n",
        "\n",
        "    print(f\"\\n=== ç”»åƒå‡¦ç†é–‹å§‹ ===\")\n",
        "    print(f\"å…¥åŠ›ãƒ•ã‚©ãƒ«ãƒ€: {input_folder}\")\n",
        "    print(f\"å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€: {output_folder}\")\n",
        "    print(f\"ç™ºè¦‹ã•ã‚ŒãŸç”»åƒãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(image_files)}\")\n",
        "    print(f\"ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {device}\")\n",
        "\n",
        "    for i, image_path in enumerate(image_files):\n",
        "        print(f\"\\nå‡¦ç†ä¸­ ({i+1}/{len(image_files)}): {image_path.name}\")\n",
        "\n",
        "        try:\n",
        "            # ç”»åƒãƒ­ãƒ¼ãƒ‰ã¨å‰å‡¦ç†\n",
        "            input_tensor = load_and_preprocess_image(str(image_path), target_size=(1600, 1200))\n",
        "            input_tensor = input_tensor.to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                # å…ƒã®ãƒ¢ãƒ‡ãƒ«ã§å‡¦ç†\n",
        "                original_output_tensor = original_model(input_tensor)\n",
        "\n",
        "                # FC layerãŒæŒ¿å…¥ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã§å‡¦ç†\n",
        "                modified_output_tensor = modified_model(input_tensor)\n",
        "\n",
        "            # ãƒ†ãƒ³ã‚½ãƒ«ã‚’ç”»åƒã«å¤‰æ›\n",
        "            original_image = tensor_to_image(original_output_tensor.cpu())\n",
        "            modified_image = tensor_to_image(modified_output_tensor.cpu())\n",
        "            input_image = tensor_to_image(input_tensor.cpu())\n",
        "\n",
        "            # ãƒ•ã‚¡ã‚¤ãƒ«åç”Ÿæˆ\n",
        "            base_name = image_path.stem\n",
        "\n",
        "            # çµæœç”»åƒä¿å­˜\n",
        "            original_image.save(original_output / f\"{base_name}_original.png\")\n",
        "            modified_image.save(modified_output / f\"{base_name}_with_fc.png\")\n",
        "\n",
        "            # æ¯”è¼ƒç”»åƒä½œæˆï¼ˆæ¨ªä¸¦ã³ï¼‰\n",
        "            comparison_image = create_comparison_image(\n",
        "                input_image, original_image, modified_image,\n",
        "                titles=[\"å…¥åŠ›\", \"å…ƒã®ãƒ¢ãƒ‡ãƒ«\", \"FCæŒ¿å…¥ãƒ¢ãƒ‡ãƒ«\"]\n",
        "            )\n",
        "            comparison_image.save(comparison_output / f\"{base_name}_comparison.png\")\n",
        "\n",
        "            # å·®åˆ†è¨ˆç®—\n",
        "            diff_tensor = torch.abs(original_output_tensor - modified_output_tensor)\n",
        "            max_diff = diff_tensor.max().item()\n",
        "            mean_diff = diff_tensor.mean().item()\n",
        "\n",
        "            print(f\"  âœ“ å‡¦ç†å®Œäº†\")\n",
        "            print(f\"    æœ€å¤§å·®åˆ†: {max_diff:.6f}\")\n",
        "            print(f\"    å¹³å‡å·®åˆ†: {mean_diff:.6f}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  âœ— ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}\")\n",
        "            continue\n",
        "\n",
        "    print(f\"\\n=== å‡¦ç†å®Œäº† ===\")\n",
        "    print(f\"çµæœã¯ä»¥ä¸‹ã®ãƒ•ã‚©ãƒ«ãƒ€ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ:\")\n",
        "    print(f\"  å…ƒã®ãƒ¢ãƒ‡ãƒ«çµæœ: {original_output}\")\n",
        "    print(f\"  FCæŒ¿å…¥ãƒ¢ãƒ‡ãƒ«çµæœ: {modified_output}\")\n",
        "    print(f\"  æ¯”è¼ƒç”»åƒ: {comparison_output}\")\n",
        "\n",
        "def create_comparison_image(input_img, original_img, modified_img, titles=None):\n",
        "    \"\"\"\n",
        "    3ã¤ã®ç”»åƒã‚’æ¨ªä¸¦ã³ã§æ¯”è¼ƒç”»åƒã‚’ä½œæˆ\n",
        "\n",
        "    Args:\n",
        "        input_img: å…¥åŠ›ç”»åƒ\n",
        "        original_img: å…ƒã®ãƒ¢ãƒ‡ãƒ«çµæœ\n",
        "        modified_img: ä¿®æ­£ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«çµæœ\n",
        "        titles: å„ç”»åƒã®ã‚¿ã‚¤ãƒˆãƒ«\n",
        "\n",
        "    Returns:\n",
        "        æ¯”è¼ƒç”»åƒ\n",
        "    \"\"\"\n",
        "    from PIL import ImageDraw, ImageFont\n",
        "\n",
        "    # ç”»åƒã‚µã‚¤ã‚ºå–å¾—\n",
        "    width, height = input_img.size\n",
        "\n",
        "    # æ¯”è¼ƒç”»åƒä½œæˆï¼ˆæ¨ªä¸¦ã³ + ã‚¿ã‚¤ãƒˆãƒ«é ˜åŸŸï¼‰\n",
        "    title_height = 30\n",
        "    comparison_width = width * 3\n",
        "    comparison_height = height + title_height\n",
        "\n",
        "    comparison_img = Image.new('RGB', (comparison_width, comparison_height), 'white')\n",
        "\n",
        "    # ç”»åƒè²¼ã‚Šä»˜ã‘\n",
        "    comparison_img.paste(input_img, (0, title_height))\n",
        "    comparison_img.paste(original_img, (width, title_height))\n",
        "    comparison_img.paste(modified_img, (width * 2, title_height))\n",
        "\n",
        "    # ã‚¿ã‚¤ãƒˆãƒ«è¿½åŠ \n",
        "    if titles:\n",
        "        draw = ImageDraw.Draw(comparison_img)\n",
        "        try:\n",
        "            # ã‚·ã‚¹ãƒ†ãƒ ãƒ•ã‚©ãƒ³ãƒˆä½¿ç”¨ã‚’è©¦è¡Œ\n",
        "            font = ImageFont.truetype(\"arial.ttf\", 20)\n",
        "        except:\n",
        "            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ•ã‚©ãƒ³ãƒˆä½¿ç”¨\n",
        "            font = ImageFont.load_default()\n",
        "\n",
        "        for i, title in enumerate(titles):\n",
        "            text_width = draw.textlength(title, font=font)\n",
        "            x = (width * i) + (width - text_width) // 2\n",
        "            draw.text((x, 5), title, fill='black', font=font)\n",
        "\n",
        "    return comparison_img\n",
        "\n",
        "def test_fc_insertion():\n",
        "    \"\"\"FC layeræŒ¿å…¥ãƒ†ã‚¹ãƒˆ\"\"\"\n",
        "    print(\"=== FC LayeræŒ¿å…¥ãƒ†ã‚¹ãƒˆ ===\")\n",
        "\n",
        "    # ãƒ€ãƒŸãƒ¼ãƒ¢ãƒ‡ãƒ«ç”Ÿæˆï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰\n",
        "    class DummyModel(nn.Module):\n",
        "        def __init__(self):\n",
        "            super().__init__()\n",
        "            self.conv1 = nn.Conv2d(3, 64, 3, 1, 1)\n",
        "            self.conv2 = nn.Conv2d(64, 64, 3, 1, 1)\n",
        "            self.conv3 = nn.Conv2d(64, 32, 3, 1, 1)\n",
        "            self.conv4 = nn.Conv2d(32, 3, 3, 1, 1)\n",
        "            self.relu = nn.ReLU()\n",
        "\n",
        "        def forward(self, x):\n",
        "            x = self.relu(self.conv1(x))\n",
        "            x = self.relu(self.conv2(x))\n",
        "            x = self.relu(self.conv3(x))\n",
        "            x = self.conv4(x)\n",
        "            return x\n",
        "\n",
        "    dummy_model = DummyModel()\n",
        "\n",
        "    # FC layeræŒ¿å…¥ãƒ†ã‚¹ãƒˆ\n",
        "    try:\n",
        "        modified_model, fc_layer = insert_fc_layer_into_model(\n",
        "            dummy_model, 'smallest', (1200, 1600), 'identity'\n",
        "        )\n",
        "        print(\"âœ“ FC layeræŒ¿å…¥æˆåŠŸ\")\n",
        "\n",
        "        # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ\n",
        "        test_input = torch.randn(1, 3, 1200, 1600)\n",
        "        with torch.no_grad():\n",
        "            output = modified_model(test_input)\n",
        "            print(f\"âœ“ Forward passæˆåŠŸã€å‡ºåŠ›ã‚µã‚¤ã‚º: {output.shape}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âœ— ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}\")\n",
        "\n",
        "def run_image_comparison_demo(input_folder, output_folder, model_path=None):\n",
        "    \"\"\"\n",
        "    ç”»åƒæ¯”è¼ƒãƒ‡ãƒ¢å®Ÿè¡Œ\n",
        "\n",
        "    Args:\n",
        "        input_folder: å…¥åŠ›ç”»åƒãƒ•ã‚©ãƒ«ãƒ€\n",
        "        output_folder: å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€\n",
        "        model_path: ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰\n",
        "    \"\"\"\n",
        "    print(\"=== ç”»åƒæ¯”è¼ƒãƒ‡ãƒ¢å®Ÿè¡Œ ===\")\n",
        "\n",
        "    # ãƒ‡ãƒã‚¤ã‚¹è¨­å®š\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {device}\")\n",
        "\n",
        "    if model_path and os.path.exists(model_path):\n",
        "        # å®Ÿéš›ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨\n",
        "        try:\n",
        "            modified_model, fc_layer = insert_fc_into_real_esrgan(\n",
        "                model_path, fc_position='smallest', init_type='identity'\n",
        "            )\n",
        "            original_model = torch.load(model_path, map_location='cpu')\n",
        "        except Exception as e:\n",
        "            print(f\"å®Ÿéš›ã®ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—: {e}\")\n",
        "            print(\"ãƒ€ãƒŸãƒ¼ãƒ¢ãƒ‡ãƒ«ã§ãƒ‡ãƒ¢ã‚’å®Ÿè¡Œã—ã¾ã™...\")\n",
        "            original_model, modified_model = create_dummy_models()\n",
        "    else:\n",
        "        print(\"ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ãŒæä¾›ã•ã‚Œã¦ã„ãªã„ãŸã‚ã€ãƒ€ãƒŸãƒ¼ãƒ¢ãƒ‡ãƒ«ã§ãƒ‡ãƒ¢ã‚’å®Ÿè¡Œã—ã¾ã™...\")\n",
        "        original_model, modified_model = create_dummy_models()\n",
        "\n",
        "    # ç”»åƒå‡¦ç†å®Ÿè¡Œ\n",
        "    process_images_folder(\n",
        "        input_folder=input_folder,\n",
        "        output_folder=output_folder,\n",
        "        original_model=original_model,\n",
        "        modified_model=modified_model,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "def create_dummy_models():\n",
        "    \"\"\"\n",
        "    ãƒ‡ãƒ¢ç”¨ãƒ€ãƒŸãƒ¼ãƒ¢ãƒ‡ãƒ«ä½œæˆ\n",
        "    \"\"\"\n",
        "    class DummyModel(nn.Module):\n",
        "        def __init__(self):\n",
        "            super().__init__()\n",
        "            self.conv1 = nn.Conv2d(3, 32, 3, 1, 1)\n",
        "            self.conv2 = nn.Conv2d(32, 32, 3, 1, 1)\n",
        "            self.conv3 = nn.Conv2d(32, 3, 3, 1, 1)\n",
        "            self.relu = nn.ReLU()\n",
        "\n",
        "        def forward(self, x):\n",
        "            x = self.relu(self.conv1(x))\n",
        "            x = self.relu(self.conv2(x))\n",
        "            x = self.conv3(x)\n",
        "            return torch.clamp(x, 0, 1)\n",
        "\n",
        "    original_model = DummyModel()\n",
        "\n",
        "    # FC layerã‚’æŒ¿å…¥ã—ãŸãƒ¢ãƒ‡ãƒ«ä½œæˆ\n",
        "    modified_model, fc_layer = insert_fc_layer_into_model(\n",
        "        copy.deepcopy(original_model), 'middle', (1200, 1600), 'identity'\n",
        "    )\n",
        "\n",
        "    return original_model, modified_model\n",
        "\n",
        "# ä½¿ç”¨ä¾‹\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=== Real-ESRGAN FC LayeræŒ¿å…¥ãƒ„ãƒ¼ãƒ« ===\")\n",
        "\n",
        "    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ\n",
        "    test_fc_insertion()\n",
        "\n",
        "    print(\"\\n=== ä½¿ç”¨ä¾‹ ===\")\n",
        "    print(\"# 1. äº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã«FC layeræŒ¿å…¥\")\n",
        "    print(\"model_path = 'path/to/your/real_esrgan_model.pth'\")\n",
        "    print(\"modified_model, fc_layer = insert_fc_into_real_esrgan(\")\n",
        "    print(\"    model_path=model_path,\")\n",
        "    print(\"    fc_position='smallest',  # 'middle', 'early', 'late', 'smallest' ã¾ãŸã¯ç‰¹å®šãƒ¬ã‚¤ãƒ¤ãƒ¼å\")\n",
        "    print(\"    init_type='identity'     # 'identity' ã¾ãŸã¯ 'random'\")\n",
        "    print(\")\")\n",
        "    print()\n",
        "    print(\"# 2. FC layeré‡ã¿å†åˆæœŸåŒ–\")\n",
        "    print(\"fc_layer.reinit_weights('random')\")\n",
        "    print()\n",
        "    print(\"# 3. ç”»åƒãƒ•ã‚©ãƒ«ãƒ€å‡¦ç†\")\n",
        "    print(\"run_image_comparison_demo(\")\n",
        "    print(\"    input_folder='path/to/input/images',\")\n",
        "    print(\"    output_folder='path/to/output/results',\")\n",
        "    print(\"    model_path='path/to/model.pth'  # ã‚ªãƒ—ã‚·ãƒ§ãƒ³\")\n",
        "    print(\")\")\n",
        "    print()\n",
        "    print(\"# 4. ç›´æ¥ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å¾ŒFC layeræŒ¿å…¥\")\n",
        "    print(\"model = torch.load('your_model.pth')\")\n",
        "    print(\"modified_model, fc_layer = insert_fc_layer_into_model(\")\n",
        "    print(\"    model, 'middle', (1200, 1600), 'identity')\")\n",
        "    print()\n",
        "    print(\"# 5. å€‹åˆ¥ç”»åƒå‡¦ç†\")\n",
        "    print(\"process_images_folder(\")\n",
        "    print(\"    'input_folder', 'output_folder', original_model, modified_model\")\n",
        "    print(\")\")"
      ],
      "metadata": {
        "id": "BnIjZz4VXOsY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}