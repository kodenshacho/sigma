{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kodenshacho/sigma/blob/master/glfragment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.onnx\n",
        "from openvino.runtime import Core\n",
        "from openvino.tools import mo\n",
        "import os\n",
        "\n",
        "class FFDNet(nn.Module):\n",
        "    def __init__(self, num_channels=1, num_features=64):\n",
        "        super(FFDNet, self).__init__()\n",
        "        self.num_channels = num_channels\n",
        "        self.num_features = num_features\n",
        "\n",
        "        # 다운샘플링\n",
        "        self.downscale = nn.PixelUnshuffle(2)\n",
        "\n",
        "        # 특징 추출 레이어\n",
        "        layers = []\n",
        "        # 첫 번째 컨볼루션 레이어\n",
        "        layers.append(nn.Conv2d(num_channels * 4 + 1, num_features, kernel_size=3, padding=1))\n",
        "        layers.append(nn.ReLU(inplace=True))\n",
        "\n",
        "        # 중간 레이어\n",
        "        for _ in range(12):  # 12개의 중간 레이어\n",
        "            layers.append(nn.Conv2d(num_features, num_features, kernel_size=3, padding=1))\n",
        "            layers.append(nn.BatchNorm2d(num_features))\n",
        "            layers.append(nn.ReLU(inplace=True))\n",
        "\n",
        "        # 마지막 컨볼루션 레이어\n",
        "        layers.append(nn.Conv2d(num_features, num_channels * 4, kernel_size=3, padding=1))\n",
        "\n",
        "        self.features = nn.Sequential(*layers)\n",
        "\n",
        "        # 업샘플링\n",
        "        self.upscale = nn.PixelShuffle(2)\n",
        "\n",
        "    def forward(self, x, noise_level):\n",
        "        # 다운샘플링\n",
        "        x_down = self.downscale(x)\n",
        "\n",
        "        # 노이즈 레벨 맵 생성 및 확장\n",
        "        noise_level = noise_level.expand(-1, -1, x_down.shape[2], x_down.shape[3])\n",
        "\n",
        "        # 입력과 노이즈 레벨 맵 결합\n",
        "        x_in = torch.cat([x_down, noise_level], dim=1)\n",
        "\n",
        "        # 특징 추출\n",
        "        features = self.features(x_in)\n",
        "\n",
        "        # 업샘플링\n",
        "        out = self.upscale(features)\n",
        "\n",
        "        return out\n",
        "\n",
        "def create_noise_level_map(noise_sigma, shape):\n",
        "    \"\"\"노이즈 레벨 맵 생성 함수\"\"\"\n",
        "    return torch.full((1, 1, shape[2], shape[3]), noise_sigma)\n",
        "\n",
        "def convert_to_openvino(model_path, output_dir):\n",
        "    \"\"\"PyTorch 모델을 OpenVINO 모델로 변환하는 함수\"\"\"\n",
        "    try:\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "        # 모델 로드\n",
        "        model = FFDNet(num_channels=1)\n",
        "        model.load_state_dict(torch.load(model_path))\n",
        "        model.eval()\n",
        "\n",
        "        # ONNX 모델 경로\n",
        "        onnx_path = os.path.join(output_dir, \"ffdnet.onnx\")\n",
        "\n",
        "        # 입력 샘플 생성\n",
        "        sample_image = torch.randn(1, 1, 256, 256)\n",
        "        sample_noise = torch.full((1, 1, 1, 1), 0.1)\n",
        "\n",
        "        # 추가된 레이어의 중간 출력을 추적하기 위한 설정\n",
        "        class ModelWrapper(nn.Module):\n",
        "            def __init__(self, model):\n",
        "                super(ModelWrapper, self).__init__()\n",
        "                self.model = model\n",
        "\n",
        "            def forward(self, x, noise):\n",
        "                # 중간 출력을 저장할 딕셔너리\n",
        "                intermediate = {}\n",
        "\n",
        "                # 다운샘플링\n",
        "                x_down = self.model.downscale(x)\n",
        "                intermediate['downscale'] = x_down\n",
        "\n",
        "                # 노이즈 레벨 맵\n",
        "                noise_map = noise.expand(-1, -1, x_down.shape[2], x_down.shape[3])\n",
        "                x_in = torch.cat([x_down, noise_map], dim=1)\n",
        "\n",
        "                # 특징 추출\n",
        "                features = self.model.features(x_in)\n",
        "                intermediate['features'] = features\n",
        "\n",
        "                # 업샘플링\n",
        "                out = self.model.upscale(features)\n",
        "                intermediate['upscale'] = out\n",
        "\n",
        "                return out, intermediate\n",
        "\n",
        "        # 모델 래핑\n",
        "        wrapped_model = ModelWrapper(model)\n",
        "\n",
        "        # PyTorch -> ONNX 변환\n",
        "        print(\"PyTorch 모델을 ONNX로 변환 중...\")\n",
        "        torch.onnx.export(wrapped_model,\n",
        "                         (sample_image, sample_noise),\n",
        "                         onnx_path,\n",
        "                         input_names=['input_image', 'noise_level'],\n",
        "                         output_names=['denoised_image', 'intermediate_outputs'],\n",
        "                         dynamic_axes={\n",
        "                             'input_image': {0: 'batch_size', 2: 'height', 3: 'width'},\n",
        "                             'noise_level': {0: 'batch_size'},\n",
        "                             'denoised_image': {0: 'batch_size', 2: 'height', 3: 'width'}\n",
        "                         },\n",
        "                         do_constant_folding=True,\n",
        "                         opset_version=11)\n",
        "\n",
        "        print(\"ONNX 모델 저장됨:\", onnx_path)\n",
        "\n",
        "        # ONNX -> OpenVINO IR 변환\n",
        "        print(\"ONNX 모델을 OpenVINO로 변환 중...\")\n",
        "        ov_model = mo.convert_model(\n",
        "            onnx_path,\n",
        "            model_name=\"ffdnet\",\n",
        "            framework=\"onnx\",\n",
        "            input=['input_image', 'noise_level'],\n",
        "            input_shape=[[1, 1, 256, 256], [1, 1, 1, 1]],\n",
        "            output=['denoised_image', 'intermediate_outputs'],\n",
        "            data_type='FP32'\n",
        "        )\n",
        "\n",
        "        # OpenVINO 모델 저장\n",
        "        serialize_path = os.path.join(output_dir, \"ffdnet.xml\")\n",
        "        ov_model.serialize(serialize_path)\n",
        "\n",
        "        print(\"변환 완료\")\n",
        "\n",
        "        # 변환된 모델 테스트\n",
        "        print(\"변환된 모델 테스트 중...\")\n",
        "        ie = Core()\n",
        "        model = ie.read_model(serialize_path)\n",
        "        compiled_model = ie.compile_model(model=model, device_name=\"CPU\")\n",
        "\n",
        "        # 입력 레이어 정보 출력\n",
        "        print(\"\\n입력 레이어 정보:\")\n",
        "        for input_layer in model.inputs:\n",
        "            print(f\"이름: {input_layer.get_any_name()}\")\n",
        "            print(f\"형상: {input_layer.shape}\")\n",
        "            print(f\"타입: {input_layer.element_type}\")\n",
        "            print(\"---\")\n",
        "\n",
        "        # 출력 레이어 정보 출력\n",
        "        print(\"\\n출력 레이어 정보:\")\n",
        "        for output_layer in model.outputs:\n",
        "            print(f\"이름: {output_layer.get_any_name()}\")\n",
        "            print(f\"형상: {output_layer.shape}\")\n",
        "            print(f\"타입: {output_layer.element_type}\")\n",
        "            print(\"---\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"오류 발생: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    model_path = \"path/to/ffdnet.pth\"\n",
        "    output_dir = \"openvino_model\"\n",
        "    convert_to_openvino(model_path, output_dir)"
      ],
      "metadata": {
        "id": "PL1heTwcReak"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}