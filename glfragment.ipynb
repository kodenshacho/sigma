{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kodenshacho/sigma/blob/master/glfragment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn as nn\n",
        "from torch.nn import functional as F\n",
        "import math\n",
        "\n",
        "from basicsr.utils.registry import ARCH_REGISTRY\n",
        "from .arch_util import default_init_weights, make_layer, pixel_unshuffle\n",
        "\n",
        "\n",
        "class ResidualDenseBlock(nn.Module):\n",
        "    def __init__(self, num_feat=64, num_grow_ch=32):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(num_feat, num_grow_ch, 3, 1, 1)\n",
        "        self.conv2 = nn.Conv2d(num_feat + num_grow_ch, num_grow_ch, 3, 1, 1)\n",
        "        self.conv3 = nn.Conv2d(num_feat + 2 * num_grow_ch, num_grow_ch, 3, 1, 1)\n",
        "        self.conv4 = nn.Conv2d(num_feat + 3 * num_grow_ch, num_grow_ch, 3, 1, 1)\n",
        "        self.conv5 = nn.Conv2d(num_feat + 4 * num_grow_ch, num_feat, 3, 1, 1)\n",
        "        self.lrelu = nn.LeakyReLU(0.2, inplace=True)\n",
        "        default_init_weights([self.conv1, self.conv2, self.conv3, self.conv4, self.conv5], 0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.lrelu(self.conv1(x))\n",
        "        x2 = self.lrelu(self.conv2(torch.cat((x, x1), 1)))\n",
        "        x3 = self.lrelu(self.conv3(torch.cat((x, x1, x2), 1)))\n",
        "        x4 = self.lrelu(self.conv4(torch.cat((x, x1, x2, x3), 1)))\n",
        "        x5 = self.conv5(torch.cat((x, x1, x2, x3, x4), 1))\n",
        "        return x5 * 0.2 + x\n",
        "\n",
        "\n",
        "class RRDB(nn.Module):\n",
        "    def __init__(self, num_feat, num_grow_ch=32):\n",
        "        super().__init__()\n",
        "        self.rdb1 = ResidualDenseBlock(num_feat, num_grow_ch)\n",
        "        self.rdb2 = ResidualDenseBlock(num_feat, num_grow_ch)\n",
        "        self.rdb3 = ResidualDenseBlock(num_feat, num_grow_ch)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.rdb1(x)\n",
        "        out = self.rdb2(out)\n",
        "        out = self.rdb3(out)\n",
        "        return out * 0.2 + x\n",
        "\n",
        "\n",
        "@ARCH_REGISTRY.register()\n",
        "class RRDBNet(nn.Module):\n",
        "    def __init__(self, num_in_ch, num_out_ch, scale=1, num_feat=64, num_block=23, num_grow_ch=32):\n",
        "        super().__init__()\n",
        "        self.scale = scale\n",
        "        if scale == 2:\n",
        "            num_in_ch *= 4\n",
        "        elif scale == 1:\n",
        "            num_in_ch *= 16\n",
        "\n",
        "        self.conv_first = nn.Conv2d(num_in_ch, num_feat, 3, 1, 1)\n",
        "        self.body = make_layer(RRDB, num_block, num_feat=num_feat, num_grow_ch=num_grow_ch)\n",
        "        self.conv_body = nn.Conv2d(num_feat, num_feat, 3, 1, 1)\n",
        "\n",
        "        # FC layer at smallest node\n",
        "        self.fc_smallest = nn.Linear(num_feat, num_feat, bias=False)\n",
        "        self.init_fc_identity()\n",
        "\n",
        "        # upsampling layers\n",
        "        self.conv_up1 = nn.Conv2d(num_feat, num_feat, 3, 1, 1)\n",
        "        self.conv_up2 = nn.Conv2d(num_feat, num_feat, 3, 1, 1)\n",
        "        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)\n",
        "        self.conv_last = nn.Conv2d(num_feat, num_out_ch, 3, 1, 1)\n",
        "        self.lrelu = nn.LeakyReLU(0.2, inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.scale == 2:\n",
        "            feat = pixel_unshuffle(x, scale=2)\n",
        "        elif self.scale == 1:\n",
        "            feat = pixel_unshuffle(x, scale=4)\n",
        "        else:\n",
        "            feat = x\n",
        "        feat = self.conv_first(feat)\n",
        "        body_feat = self.conv_body(self.body(feat))\n",
        "        feat = feat + body_feat\n",
        "\n",
        "        # Store feat before FC for comparison\n",
        "        feat_before_fc = feat.clone()\n",
        "\n",
        "        # apply FC without altering spatial dims\n",
        "        b, c, h, w = feat.shape\n",
        "        feat_flat = feat.permute(0,2,3,1).reshape(-1, c)\n",
        "        with torch.no_grad():\n",
        "            feat_fc = F.linear(feat_flat, self.fc_smallest.weight)\n",
        "        feat = feat_fc.reshape(b, h, w, c).permute(0,3,1,2)\n",
        "\n",
        "\n",
        "        # apply FC without altering spatial dims\n",
        "        # b, c, h, w = feat.shape\n",
        "        # feat_flat = feat.permute(0,2,3,1).reshape(-1, c)\n",
        "        # feat_fc = self.fc_smallest(feat_flat)\n",
        "        # feat = feat_fc.reshape(b, h, w, c).permute(0,3,1,2)\n",
        "\n",
        "        # Compare feat before and after FC\n",
        "        print('Feat before FC shape:', feat_before_fc.shape)\n",
        "        print('Feat after FC shape:', feat.shape)\n",
        "        print('Feat max abs diff before and after FC:', torch.max(torch.abs(feat_before_fc - feat)).item())\n",
        "        # Add more detailed comparison\n",
        "        print('Feat mean abs diff before and after FC:', torch.mean(torch.abs(feat_before_fc - feat)).item())\n",
        "        print('Are feats close? (allclose):', torch.allclose(feat_before_fc, feat))\n",
        "\n",
        "\n",
        "        feat = self.lrelu(self.conv_up1(F.interpolate(feat, scale_factor=2, mode='nearest')))\n",
        "        feat = self.lrelu(self.conv_up2(F.interpolate(feat, scale_factor=2, mode='nearest')))\n",
        "        out = self.conv_last(self.lrelu(self.conv_hr(feat)))\n",
        "        return out\n",
        "\n",
        "    def init_fc_identity(self):\n",
        "        # Identity 초기화 후 학습되지 않도록 weight 고정\n",
        "        with torch.no_grad():\n",
        "            eye = torch.eye(self.fc_smallest.weight.size(0), device=self.fc_smallest.weight.device)\n",
        "            self.fc_smallest.weight.copy_(eye)\n",
        "        self.fc_smallest.weight.requires_grad_(False)\n",
        "\n",
        "    def init_fc_random(self):\n",
        "        # 랜덤 초기화 (optional, weight 고정 해제하지 않음)\n",
        "        nn.init.kaiming_uniform_(self.fc_smallest.weight, a=math.sqrt(5))\n",
        "\n",
        "    def print_fc_weights(self, prefix='FC Weights'):\n",
        "        print(f'{prefix}:')\n",
        "        print(self.fc_smallest.weight.data)\n",
        "\n",
        "# 해당 수정으로 identity 가중치가 고정되므로 반복 Iteration마다 동일 출력을 보장합니다.\n"
      ],
      "metadata": {
        "id": "6PkSt2lN_tnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 테스트 스크립트 예시\n",
        "if __name__ == '__main__':\n",
        "    model = RRDBNet(3, 3, scale=1)\n",
        "    pretrained = RRDBNet(3, 3, scale=1)\n",
        "    # Create a dummy pretrained model file for demonstration\n",
        "    dummy_pretrained_path = 'pretrained_1600x1200.pth'\n",
        "    if not os.path.exists(dummy_pretrained_path):\n",
        "        print(f\"Creating dummy pretrained model file at {dummy_pretrained_path}\")\n",
        "        torch.save(pretrained.state_dict(), dummy_pretrained_path)\n",
        "\n",
        "    pretrained.load_state_dict(torch.load(dummy_pretrained_path))\n",
        "\n",
        "    # 사전학습 모델 FC 가중치 출력\n",
        "    pretrained.print_fc_weights(prefix='Pretrained FC Weights')\n",
        "\n",
        "    # 훈련 모델에 사전학습 가중치 복사\n",
        "    model.load_state_dict(pretrained.state_dict())\n",
        "    # 훈련 모델 FC 가중치 출력\n",
        "    model.print_fc_weights(prefix='Loaded Model FC Weights')\n",
        "\n",
        "    # 차이 비교\n",
        "    diff = pretrained.fc_smallest.weight.data - model.fc_smallest.weight.data\n",
        "    print('FC Weight Max abs diff:', diff.abs().max().item())\n",
        "\n",
        "    # 동일한 입력 비교\n",
        "    x = torch.randn(1,3,1600,1200)\n",
        "    out_pre = pretrained(x)\n",
        "    out_model = model(x)\n",
        "    print('Output Max abs diff:', torch.max(torch.abs(out_pre - out_model)).item())"
      ],
      "metadata": {
        "id": "mefZEtg2_3rL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/boomb0om/Real-ESRGAN-colab\n",
        "!git clone https://github.com/XPixelGroup/BasicSR.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StPZN-o_bn0e",
        "outputId": "80770d78-477b-43a0-bd55-f0cab9c1e106"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'BasicSR'...\n",
            "remote: Enumerating objects: 5924, done.\u001b[K\n",
            "remote: Total 5924 (delta 0), reused 0 (delta 0), pack-reused 5924 (from 1)\u001b[K\n",
            "Receiving objects: 100% (5924/5924), 4.14 MiB | 20.77 MiB/s, done.\n",
            "Resolving deltas: 100% (3758/3758), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Googleドライブのマウントと作業フォルダへの移動\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd '/content/drive/My Drive/work'"
      ],
      "metadata": {
        "id": "O3cM9xvcYpql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/xinntao/Real-ESRGAN.git\n",
        "%cd Real-ESRGAN\n",
        "# upload with fc rrdbnet..."
      ],
      "metadata": {
        "id": "FfzqV4PzaAb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# パッケージのインストール\n",
        "!pip install basicsr facexlib gfpgan\n",
        "!pip install -r requirements.txt\n",
        "!python setup.py develop\n"
      ],
      "metadata": {
        "id": "oQ_hpjVcamuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! python tests/test_model.py\n",
        "# ! pip install --upgrade torchvision"
      ],
      "metadata": {
        "id": "ugVV1WCJcjDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6636b26"
      },
      "source": [
        "# Task\n",
        "Analyze the Real-ESRGAN model architecture in \"/content/Real-ESRGAN/BasicSR/basicsr/archs/rrdbnet_arch.py\" to identify the convolution layer with the smallest number of nodes. Modify the architecture by inserting a fully connected layer after this identified convolution layer, ensuring the fully connected layer's input size matches the preceding layer's output size. Prepare the model for training with 1600x1200 input and output, aiming to achieve results similar to the original pre-trained Real-ESRGAN model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "942aea52"
      },
      "source": [
        "## 모델 아키텍처 분석\n",
        "\n",
        "### Subtask:\n",
        "Real-ESRGAN 모델의 아키텍처, 특히 `RRDBNet`의 구조를 분석하여 fully connected layer를 삽입할 위치를 결정합니다. 노드 수가 가장 작은 콘볼루션 레이어의 출력 크기를 확인합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a303ede"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires analyzing the `RRDBNet` architecture defined in a Python file to identify the convolution layer with the smallest number of output nodes and its output size. This involves reading the file content and examining the class definition, which can be done by reading the file and printing its content.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5546bd38",
        "outputId": "a9355516-7350-46b2-8cd4-daaf1d025f66"
      },
      "source": [
        "file_path = '/content/Real-ESRGAN/basicsr/archs/rrdbnet_arch.py'\n",
        "try:\n",
        "    with open(file_path, 'r') as f:\n",
        "        file_content = f.read()\n",
        "    print(file_content)\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: File not found at {file_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: File not found at /content/Real-ESRGAN/basicsr/archs/rrdbnet_arch.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0e52565"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous command failed because the file path was incorrect. The `BasicSR` repository was cloned, and the `Real-ESRGAN` repository was also cloned and the working directory was changed to `Real-ESRGAN`. The `rrdbnet_arch.py` file is located within the `basicsr` directory inside the cloned `BasicSR` repository, not within the `Real-ESRGAN` directory. The correct path should be within the cloned `BasicSR` directory. I need to adjust the file path and try reading the file again.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0c5a867",
        "outputId": "9bd10be9-4768-4174-aebc-d2eec6998164"
      },
      "source": [
        "file_path = '/content/BasicSR/basicsr/archs/rrdbnet_arch.py'\n",
        "try:\n",
        "    with open(file_path, 'r') as f:\n",
        "        file_content = f.read()\n",
        "    print(file_content)\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: File not found at {file_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: File not found at /content/BasicSR/basicsr/archs/rrdbnet_arch.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cc0759c7"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous command also failed because the file path is still incorrect. The `BasicSR` repository was cloned into `/content/BasicSR`. The file should be located inside the `BasicSR` directory. I will check the directory structure and try reading the file again with the correct path.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "278b05db",
        "outputId": "4baaae32-e356-4b25-87fb-eb29d7bf78dc"
      },
      "source": [
        "import os\n",
        "print(os.listdir('/content/BasicSR/basicsr/archs'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/BasicSR/basicsr/archs'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-12-2330357166.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/BasicSR/basicsr/archs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/BasicSR/basicsr/archs'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a473070d"
      },
      "source": [
        "**Reasoning**:\n",
        "The error indicates that the directory `/content/BasicSR/basicsr/archs` does not exist. This suggests that the cloning of the `BasicSR` repository might not have placed the files in the expected location or the path is still incorrect. I will list the contents of the `/content` directory and then the `/content/BasicSR` directory to understand the file structure after cloning.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "aJCmYAptgNbF",
        "outputId": "2b8d5f7f-baab-4e21-f4d1-c2a603d55022"
      },
      "source": [
        "import os\n",
        "print(os.listdir('/content'))\n",
        "print(os.listdir('/content/BasicSR'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['.config', 'Real-ESRGAN', 'sample_data']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/BasicSR'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-13-2072100820.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/BasicSR'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/BasicSR'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31c19fd0"
      },
      "source": [
        "**Reasoning**:\n",
        "The error indicates that the `/content/BasicSR` directory does not exist, even though the previous output showed that the `BasicSR` repository was cloned. This is unexpected. It seems the cloning step might have failed or the output from the first cell was misleading. Given the goal is to analyze the `RRDBNet` architecture which is part of the `BasicSR` library, and `BasicSR` was supposedly installed in a later step (`!pip install basicsr`), the source code for `RRDBNet` should be available within the Python site-packages. I will try to locate the `rrdbnet_arch.py` file within the site-packages directory and read its content.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tvAwh3PgQEp",
        "outputId": "7782be52-bf5d-425f-eaf3-a5a17a56b004"
      },
      "source": [
        "import site\n",
        "import os\n",
        "\n",
        "site_packages = site.getsitepackages()\n",
        "file_path = None\n",
        "for site_package in site_packages:\n",
        "    possible_path = os.path.join(site_package, 'basicsr', 'archs', 'rrdbnet_arch.py')\n",
        "    if os.path.exists(possible_path):\n",
        "        file_path = possible_path\n",
        "        break\n",
        "\n",
        "if file_path:\n",
        "    print(f\"Found rrdbnet_arch.py at: {file_path}\")\n",
        "    try:\n",
        "        with open(file_path, 'r') as f:\n",
        "            file_content = f.read()\n",
        "        print(file_content)\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while reading the file: {e}\")\n",
        "else:\n",
        "    print(\"Could not find rrdbnet_arch.py in site-packages.\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found rrdbnet_arch.py at: /usr/local/lib/python3.11/dist-packages/basicsr/archs/rrdbnet_arch.py\n",
            "import torch\n",
            "from torch import nn as nn\n",
            "from torch.nn import functional as F\n",
            "\n",
            "from basicsr.utils.registry import ARCH_REGISTRY\n",
            "from .arch_util import default_init_weights, make_layer, pixel_unshuffle\n",
            "\n",
            "\n",
            "class ResidualDenseBlock(nn.Module):\n",
            "    \"\"\"Residual Dense Block.\n",
            "\n",
            "    Used in RRDB block in ESRGAN.\n",
            "\n",
            "    Args:\n",
            "        num_feat (int): Channel number of intermediate features.\n",
            "        num_grow_ch (int): Channels for each growth.\n",
            "    \"\"\"\n",
            "\n",
            "    def __init__(self, num_feat=64, num_grow_ch=32):\n",
            "        super(ResidualDenseBlock, self).__init__()\n",
            "        self.conv1 = nn.Conv2d(num_feat, num_grow_ch, 3, 1, 1)\n",
            "        self.conv2 = nn.Conv2d(num_feat + num_grow_ch, num_grow_ch, 3, 1, 1)\n",
            "        self.conv3 = nn.Conv2d(num_feat + 2 * num_grow_ch, num_grow_ch, 3, 1, 1)\n",
            "        self.conv4 = nn.Conv2d(num_feat + 3 * num_grow_ch, num_grow_ch, 3, 1, 1)\n",
            "        self.conv5 = nn.Conv2d(num_feat + 4 * num_grow_ch, num_feat, 3, 1, 1)\n",
            "\n",
            "        self.lrelu = nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "\n",
            "        # initialization\n",
            "        default_init_weights([self.conv1, self.conv2, self.conv3, self.conv4, self.conv5], 0.1)\n",
            "\n",
            "    def forward(self, x):\n",
            "        x1 = self.lrelu(self.conv1(x))\n",
            "        x2 = self.lrelu(self.conv2(torch.cat((x, x1), 1)))\n",
            "        x3 = self.lrelu(self.conv3(torch.cat((x, x1, x2), 1)))\n",
            "        x4 = self.lrelu(self.conv4(torch.cat((x, x1, x2, x3), 1)))\n",
            "        x5 = self.conv5(torch.cat((x, x1, x2, x3, x4), 1))\n",
            "        # Empirically, we use 0.2 to scale the residual for better performance\n",
            "        return x5 * 0.2 + x\n",
            "\n",
            "\n",
            "class RRDB(nn.Module):\n",
            "    \"\"\"Residual in Residual Dense Block.\n",
            "\n",
            "    Used in RRDB-Net in ESRGAN.\n",
            "\n",
            "    Args:\n",
            "        num_feat (int): Channel number of intermediate features.\n",
            "        num_grow_ch (int): Channels for each growth.\n",
            "    \"\"\"\n",
            "\n",
            "    def __init__(self, num_feat, num_grow_ch=32):\n",
            "        super(RRDB, self).__init__()\n",
            "        self.rdb1 = ResidualDenseBlock(num_feat, num_grow_ch)\n",
            "        self.rdb2 = ResidualDenseBlock(num_feat, num_grow_ch)\n",
            "        self.rdb3 = ResidualDenseBlock(num_feat, num_grow_ch)\n",
            "\n",
            "    def forward(self, x):\n",
            "        out = self.rdb1(x)\n",
            "        out = self.rdb2(out)\n",
            "        out = self.rdb3(out)\n",
            "        # Empirically, we use 0.2 to scale the residual for better performance\n",
            "        return out * 0.2 + x\n",
            "\n",
            "\n",
            "@ARCH_REGISTRY.register()\n",
            "class RRDBNet(nn.Module):\n",
            "    \"\"\"Networks consisting of Residual in Residual Dense Block, which is used\n",
            "    in ESRGAN.\n",
            "\n",
            "    ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks.\n",
            "\n",
            "    We extend ESRGAN for scale x2 and scale x1.\n",
            "    Note: This is one option for scale 1, scale 2 in RRDBNet.\n",
            "    We first employ the pixel-unshuffle (an inverse operation of pixelshuffle to reduce the spatial size\n",
            "    and enlarge the channel size before feeding inputs into the main ESRGAN architecture.\n",
            "\n",
            "    Args:\n",
            "        num_in_ch (int): Channel number of inputs.\n",
            "        num_out_ch (int): Channel number of outputs.\n",
            "        num_feat (int): Channel number of intermediate features.\n",
            "            Default: 64\n",
            "        num_block (int): Block number in the trunk network. Defaults: 23\n",
            "        num_grow_ch (int): Channels for each growth. Default: 32.\n",
            "    \"\"\"\n",
            "\n",
            "    def __init__(self, num_in_ch, num_out_ch, scale=4, num_feat=64, num_block=23, num_grow_ch=32):\n",
            "        super(RRDBNet, self).__init__()\n",
            "        self.scale = scale\n",
            "        if scale == 2:\n",
            "            num_in_ch = num_in_ch * 4\n",
            "        elif scale == 1:\n",
            "            num_in_ch = num_in_ch * 16\n",
            "        self.conv_first = nn.Conv2d(num_in_ch, num_feat, 3, 1, 1)\n",
            "        self.body = make_layer(RRDB, num_block, num_feat=num_feat, num_grow_ch=num_grow_ch)\n",
            "        self.conv_body = nn.Conv2d(num_feat, num_feat, 3, 1, 1)\n",
            "        # upsample\n",
            "        self.conv_up1 = nn.Conv2d(num_feat, num_feat, 3, 1, 1)\n",
            "        self.conv_up2 = nn.Conv2d(num_feat, num_feat, 3, 1, 1)\n",
            "        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)\n",
            "        self.conv_last = nn.Conv2d(num_feat, num_out_ch, 3, 1, 1)\n",
            "\n",
            "        self.lrelu = nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "\n",
            "    def forward(self, x):\n",
            "        if self.scale == 2:\n",
            "            feat = pixel_unshuffle(x, scale=2)\n",
            "        elif self.scale == 1:\n",
            "            feat = pixel_unshuffle(x, scale=4)\n",
            "        else:\n",
            "            feat = x\n",
            "        feat = self.conv_first(feat)\n",
            "        body_feat = self.conv_body(self.body(feat))\n",
            "        feat = feat + body_feat\n",
            "        # upsample\n",
            "        feat = self.lrelu(self.conv_up1(F.interpolate(feat, scale_factor=2, mode='nearest')))\n",
            "        feat = self.lrelu(self.conv_up2(F.interpolate(feat, scale_factor=2, mode='nearest')))\n",
            "        out = self.conv_last(self.lrelu(self.conv_hr(feat)))\n",
            "        return out\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45bdb18a"
      },
      "source": [
        "## 모델 아키텍처 수정\n",
        "\n",
        "### Subtask:\n",
        "분석 결과를 바탕으로 `RRDBNet` 아키텍처에 fully connected layer를 삽입하는 코드를 작성합니다. fully connected layer의 입력 크기는 이전 레이어의 출력 크기와 일치하도록 설정합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fee2540"
      },
      "source": [
        "**Reasoning**:\n",
        "To modify the `RRDBNet` architecture, I need to read the original `rrdbnet_arch.py` file, insert the fully connected layer and the logic to handle it, and then write the modified code back to the file. I will add the fully connected layer after the `conv1` layer inside the `ResidualDenseBlock` as it has the smallest number of nodes (`num_grow_ch`).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "ed2cc58e",
        "outputId": "9b0630bd-76f3-4cf5-b83c-50352605f5a4"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "from basicsr.utils.registry import ARCH_REGISTRY\n",
        "\n",
        "\n",
        "class ResidualDenseBlock(nn.Module):\n",
        "    \"\"\"Residual Dense Block.\n",
        "\n",
        "    Used in RRDB block in ESRGAN.\n",
        "\n",
        "    Args:\n",
        "        num_feat (int): Channel number of intermediate features.\n",
        "        num_grow_ch (int): Channels for growth.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_feat=64, num_grow_ch=32):\n",
        "        super(ResidualDenseBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(num_feat, num_grow_ch, 3, 1, 1)\n",
        "        self.conv2 = nn.Conv2d(num_feat + num_grow_ch, num_grow_ch, 3, 1, 1)\n",
        "        self.conv3 = nn.Conv2d(num_feat + 2 * num_grow_ch, num_grow_ch, 3, 1, 1)\n",
        "        self.conv4 = nn.Conv2d(num_feat + 3 * num_grow_ch, num_grow_ch, 3, 1, 1)\n",
        "        self.conv5 = nn.Conv2d(num_feat + 4 * num_grow_ch, num_feat, 3, 1, 1)\n",
        "\n",
        "        self.lrelu = nn.LakyReLU(negative_slope=0.2, inplace=True)\n",
        "\n",
        "        # New fully connected layer\n",
        "        # The input size is num_grow_ch * H * W. We will determine H and W in the forward pass.\n",
        "        # For now, we initialize it without a specific size, and will re-initialize it in the forward pass\n",
        "        # This is a common practice when the input size is dynamic.\n",
        "        self.fc = None\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Forward function.\n",
        "\n",
        "        Args:\n",
        "            x (Tensor): Input tensor with shape (n, c, h, w).\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Forward results.\n",
        "        \"\"\"\n",
        "        x1 = self.lrelu(self.conv1(x))\n",
        "\n",
        "        # Flatten the output of conv1 and pass it through the fully connected layer\n",
        "        n, c, h, w = x1.size()\n",
        "        if self.fc is None:\n",
        "            self.fc = nn.Linear(c * h * w, c * h * w).to(x.device)\n",
        "\n",
        "        x1_flat = x1.view(n, -1)\n",
        "        x1_fc = self.fc(x1_flat)\n",
        "        x1 = x1_fc.view(n, c, h, w)\n",
        "\n",
        "\n",
        "        x2 = self.lrelu(self.conv2(torch.cat((x, x1), 1)))\n",
        "        x3 = self.lrelu(self.conv3(torch.cat((x, x1, x2), 1)))\n",
        "        x4 = self.lrelu(self.conv4(torch.cat((x, x1, x2, x3), 1)))\n",
        "        x5 = self.conv5(torch.cat((x, x1, x2, x3, x4), 1))\n",
        "        # Empirically, we find that scaling the residual block by a small\n",
        "        # constant improves training stability.\n",
        "        return x5 * 0.2 + x\n",
        "\n",
        "\n",
        "class RRDB(nn.Module):\n",
        "    \"\"\"Residual in Residual Dense Block.\n",
        "\n",
        "    Args:\n",
        "        num_feat (int): Channel number of intermediate features.\n",
        "        num_grow_ch (int): Channels for growth.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_feat, num_grow_ch=32):\n",
        "        super(RRDB, self).__init__()\n",
        "        self.rdb1 = ResidualDenseBlock(num_feat, num_grow_ch)\n",
        "        self.rdb2 = ResidualDenseBlock(num_feat, num_grow_ch)\n",
        "        self.rdb3 = ResidualDenseBlock(num_feat, num_grow_ch)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Forward function.\n",
        "\n",
        "        Args:\n",
        "            x (Tensor): Input tensor with shape (n, c, h, w).\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Forward results.\n",
        "        \"\"\"\n",
        "        out = self.rdb1(x)\n",
        "        out = self.rdb2(out)\n",
        "        out = self.rdb3(out)\n",
        "        # Empirically, we find that scaling the residual block by a small\n",
        "        # constant improves training stability.\n",
        "        return out * 0.2 + x\n",
        "\n",
        "\n",
        "@ARCH_REGISTRY.register()\n",
        "class RRDBNet(nn.Module):\n",
        "    \"\"\"Networks consisting of Residual in Residual Dense Block, which is used\n",
        "    in ESRGAN.\n",
        "\n",
        "    ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks.\n",
        "\n",
        "    Args:\n",
        "        num_in_ch (int): Channel number of inputs.\n",
        "        num_out_ch (int): Channel number of outputs.\n",
        "        num_feat (int): Channel number of intermediate features.\n",
        "            Default: 64\n",
        "        num_block (int): Block number in the trunk network. Default: 23\n",
        "        num_grow_ch (int): Channels for growth. Default: 32\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_in_ch, num_out_ch, num_feat=64, num_block=23, num_grow_ch=32):\n",
        "        super(RRDBNet, self).__init__()\n",
        "        self.conv_first = nn.Conv2d(num_in_ch, num_feat, 3, 1, 1)\n",
        "        self.body = nn.Sequential(*[RRDB(num_feat, num_grow_ch) for _ in range(num_block)])\n",
        "        self.conv_body = nn.Conv2d(num_feat, num_feat, 3, 1, 1)\n",
        "        # upsampling\n",
        "        self.conv_up1 = nn.Conv2d(num_feat, num_feat, 3, 1, 1)\n",
        "        self.conv_up2 = nn.Conv2d(num_feat, num_feat, 3, 1, 1)\n",
        "        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)\n",
        "        self.conv_last = nn.Conv2d(num_feat, num_out_ch, 3, 1, 1)\n",
        "\n",
        "        self.lrelu = nn.LakyReLU(negative_slope=0.2, inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Forward function.\n",
        "\n",
        "        Args:\n",
        "            x (Tensor): Input tensor with shape (n, c, h, w).\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Forward results.\n",
        "        \"\"\"\n",
        "        feat = self.conv_first(x)\n",
        "        body_feat = self.conv_body(self.body(feat))\n",
        "        feat = feat + body_feat\n",
        "        # upsampling\n",
        "        feat = self.lrelu(self.conv_up1(F.interpolate(feat, scale_factor=2, mode='nearest')))\n",
        "        feat = self.lrelu(self.conv_up2(F.interpolate(feat, scale_factor=2, mode='nearest')))\n",
        "        out = self.conv_last(self.lrelu(self.conv_hr(feat)))\n",
        "        return out\n",
        "\n",
        "\n",
        "file_path = '/usr/local/lib/python3.11/dist-packages/basicsr/archs/rrdbnet_arch.py'\n",
        "\n",
        "with open(file_path, 'w') as f:\n",
        "    # We need to write the imports and the classes to the file.\n",
        "    # We will reconstruct the file content with the modified ResidualDenseBlock.\n",
        "\n",
        "    # Imports\n",
        "    f.write(\"import torch\\n\")\n",
        "    f.write(\"from torch import nn\\n\")\n",
        "    f.write(\"from torch.nn import functional as F\\n\\n\")\n",
        "    f.write(\"from basicsr.utils.registry import ARCH_REGISTRY\\n\\n\\n\")\n",
        "\n",
        "    # ResidualDenseBlock\n",
        "    f.write(\"class ResidualDenseBlock(nn.Module):\\n\")\n",
        "    f.write(\"    \\\"\\\"\\\"Residual Dense Block.\\n\\n\")\n",
        "    f.write(\"    Used in RRDB block in ESRGAN.\\n\\n\")\n",
        "    f.write(\"    Args:\\n\")\n",
        "    f.write(\"        num_feat (int): Channel number of intermediate features.\\n\")\n",
        "    f.write(\"        num_grow_ch (int): Channels for growth.\\n\")\n",
        "    f.write(\"    \\\"\\\"\\\"\\n\\n\")\n",
        "    f.write(\"    def __init__(self, num_feat=64, num_grow_ch=32):\\n\")\n",
        "    f.write(\"        super(ResidualDenseBlock, self).__init__()\\n\")\n",
        "    f.write(\"        self.conv1 = nn.Conv2d(num_feat, num_grow_ch, 3, 1, 1)\\n\")\n",
        "    f.write(\"        self.conv2 = nn.Conv2d(num_feat + num_grow_ch, num_grow_ch, 3, 1, 1)\\n\")\n",
        "    f.write(\"        self.conv3 = nn.Conv2d(num_feat + 2 * num_grow_ch, num_grow_ch, 3, 1, 1)\\n\")\n",
        "    f.write(\"        self.conv4 = nn.Conv2d(num_feat + 3 * num_grow_ch, num_grow_ch, 3, 1, 1)\\n\")\n",
        "    f.write(\"        self.conv5 = nn.Conv2d(num_feat + 4 * num_grow_ch, num_feat, 3, 1, 1)\\n\\n\")\n",
        "    f.write(\"        self.lrelu = nn.LakyReLU(negative_slope=0.2, inplace=True)\\n\\n\")\n",
        "    f.write(\"        self.fc = None\\n\\n\")\n",
        "    f.write(\"    def forward(self, x):\\n\")\n",
        "    f.write(\"        \\\"\\\"\\\"Forward function.\\n\\n\")\n",
        "    f.write(\"        Args:\\n\")\n",
        "    f.write(\"            x (Tensor): Input tensor with shape (n, c, h, w).\\n\\n\")\n",
        "    f.write(\"        Returns:\\n\")\n",
        "    f.write(\"            Tensor: Forward results.\\n\")\n",
        "    f.write(\"        \\\"\\\"\\\"\\n\")\n",
        "    f.write(\"        x1 = self.lrelu(self.conv1(x))\\n\\n\")\n",
        "    f.write(\"        n, c, h, w = x1.size()\\n\")\n",
        "    f.write(\"        if self.fc is None:\\n\")\n",
        "    f.write(\"            self.fc = nn.Linear(c * h * w, c * h * w).to(x.device)\\n\\n\")\n",
        "    f.write(\"        x1_flat = x1.view(n, -1)\\n\")\n",
        "    f.write(\"        x1_fc = self.fc(x1_flat)\\n\")\n",
        "    f.write(\"        x1 = x1_fc.view(n, c, h, w)\\n\\n\")\n",
        "    f.write(\"        x2 = self.lrelu(self.conv2(torch.cat((x, x1), 1)))\\n\")\n",
        "    f.write(\"        x3 = self.lrelu(self.conv3(torch.cat((x, x1, x2), 1)))\\n\")\n",
        "    f.write(\"        x4 = self.lrelu(self.conv4(torch.cat((x, x1, x2, x3), 1)))\\n\")\n",
        "    f.write(\"        x5 = self.conv5(torch.cat((x, x1, x2, x3, x4), 1))\\n\")\n",
        "    f.write(\"        return x5 * 0.2 + x\\n\\n\\n\")\n",
        "\n",
        "    # RRDB\n",
        "    f.write(\"class RRDB(nn.Module):\\n\")\n",
        "    f.write(\"    \\\"\\\"\\\"Residual in Residual Dense Block.\\n\\n\")\n",
        "    f.write(\"    Args:\\n\")\n",
        "    f.write(\"        num_feat (int): Channel number of intermediate features.\\n\")\n",
        "    f.write(\"        num_grow_ch (int): Channels for growth.\\n\")\n",
        "    f.write(\"    \\\"\\\"\\\"\\n\\n\")\n",
        "    f.write(\"    def __init__(self, num_feat, num_grow_ch=32):\\n\")\n",
        "    f.write(\"        super(RRDB, self).__init__()\\n\")\n",
        "    f.write(\"        self.rdb1 = ResidualDenseBlock(num_feat, num_grow_ch)\\n\")\n",
        "    f.write(\"        self.rdb2 = ResidualDenseBlock(num_feat, num_grow_ch)\\n\")\n",
        "    f.write(\"        self.rdb3 = ResidualDenseBlock(num_feat, num_grow_ch)\\n\\n\")\n",
        "    f.write(\"    def forward(self, x):\\n\")\n",
        "    f.write(\"        \\\"\\\"\\\"Forward function.\\n\\n\")\n",
        "    f.write(\"        Args:\\n\")\n",
        "    f.write(\"            x (Tensor): Input tensor with shape (n, c, h, w).\\n\\n\")\n",
        "    f.write(\"        Returns:\\n\")\n",
        "    f.write(\"            Tensor: Forward results.\\n\")\n",
        "    f.write(\"        \\\"\\\"\\\"\\n\")\n",
        "    f.write(\"        out = self.rdb1(x)\\n\")\n",
        "    f.write(\"        out = self.rdb2(out)\\n\")\n",
        "    f.write(\"        out = self.rdb3(out)\\n\")\n",
        "    f.write(\"        return out * 0.2 + x\\n\\n\\n\")\n",
        "\n",
        "    # RRDBNet\n",
        "    f.write(\"@ARCH_REGISTRY.register()\\n\")\n",
        "    f.write(\"class RRDBNet(nn.Module):\\n\")\n",
        "    f.write(\"    \\\"\\\"\\\"Networks consisting of Residual in Residual Dense Block, which is used\\n\")\n",
        "    f.write(\"    in ESRGAN.\\n\\n\")\n",
        "    f.write(\"    ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks.\\n\\n\")\n",
        "    f.write(\"    Args:\\n\")\n",
        "    f.write(\"        num_in_ch (int): Channel number of inputs.\\n\")\n",
        "    f.write(\"        num_out_ch (int): Channel number of outputs.\\n\")\n",
        "    f.write(\"        num_feat (int): Channel number of intermediate features.\\n\")\n",
        "    f.write(\"            Default: 64\\n\")\n",
        "    f.write(\"        num_block (int): Block number in the trunk network. Default: 23\\n\")\n",
        "    f.write(\"        num_grow_ch (int): Channels for growth. Default: 32\\n\")\n",
        "    f.write(\"    \\\"\\\"\\\"\\n\\n\")\n",
        "    f.write(\"    def __init__(self, num_in_ch, num_out_ch, num_feat=64, num_block=23, num_grow_ch=32):\\n\")\n",
        "    f.write(\"        super(RRDBNet, self).__init__()\\n\")\n",
        "    f.write(\"        self.conv_first = nn.Conv2d(num_in_ch, num_feat, 3, 1, 1)\\n\")\n",
        "    f.write(\"        self.body = nn.Sequential(*[RRDB(num_feat, num_grow_ch) for _ in range(num_block)])\\n\")\n",
        "    f.write(\"        self.conv_body = nn.Conv2d(num_feat, num_feat, 3, 1, 1)\\n\")\n",
        "    f.write(\"        # upsampling\\n\")\n",
        "    f.write(\"        self.conv_up1 = nn.Conv2d(num_feat, num_feat, 3, 1, 1)\\n\")\n",
        "    f.write(\"        self.conv_up2 = nn.Conv2d(num_feat, num_feat, 3, 1, 1)\\n\")\n",
        "    f.write(\"        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)\\n\")\n",
        "    f.write(\"        self.conv_last = nn.Conv2d(num_feat, num_out_ch, 3, 1, 1)\\n\\n\")\n",
        "    f.write(\"        self.lrelu = nn.LakyReLU(negative_slope=0.2, inplace=True)\\n\\n\")\n",
        "    f.write(\"    def forward(self, x):\\n\")\n",
        "    f.write(\"        \\\"\\\"\\\"Forward function.\\n\\n\")\n",
        "    f.write(\"        Args:\\n\")\n",
        "    f.write(\"            x (Tensor): Input tensor with shape (n, c, h, w).\\n\\n\")\n",
        "    f.write(\"        Returns:\\n\")\n",
        "    f.write(\"            Tensor: Forward results.\\n\")\n",
        "    f.write(\"        \\\"\\\"\\\"\\n\")\n",
        "    f.write(\"        feat = self.conv_first(x)\\n\")\n",
        "    f.write(\"        body_feat = self.conv_body(self.body(feat))\\n\")\n",
        "    f.write(\"        feat = feat + body_feat\\n\")\n",
        "    f.write(\"        # upsampling\\n\")\n",
        "    f.write(\"        feat = self.lrelu(self.conv_up1(F.interpolate(feat, scale_factor=2, mode='nearest')))\\n\")\n",
        "    f.write(\"        feat = self.lrelu(self.conv_up2(F.interpolate(feat, scale_factor=2, mode='nearest')))\\n\")\n",
        "    f.write(\"        out = self.conv_last(self.lrelu(self.conv_hr(feat)))\\n\")\n",
        "    f.write(\"        return out\\n\")\n",
        "\n",
        "print(f\"Successfully modified and saved {file_path}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torchvision.transforms.functional_tensor'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-15-4202178244.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbasicsr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregistry\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mARCH_REGISTRY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/basicsr/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# flake8: noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0marchs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/basicsr/data/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mdataset_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_folder\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_dataset.py'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# import all the dataset modules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0m_dataset_modules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'basicsr.data.{file_name}'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset_filenames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/basicsr/data/__init__.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mdataset_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_folder\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_dataset.py'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# import all the dataset modules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0m_dataset_modules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'basicsr.data.{file_name}'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset_filenames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/basicsr/data/realesrgan_dataset.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbasicsr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegradations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcircular_lowpass_kernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_mixed_kernels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbasicsr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbasicsr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFileClient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_root_logger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimfrombytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg2tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/basicsr/data/degradations.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspecial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmultivariate_normal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional_tensor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrgb_to_grayscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# -------------------------------------------------------------------- #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchvision.transforms.functional_tensor'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61676669"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code block failed because the `basicsr` library, which was installed, has a dependency issue with `torchvision`. The error `ModuleNotFoundError: No module named 'torchvision.transforms.functional_tensor'` indicates that the installed version of `torchvision` is not compatible with the `basicsr` code that was executed during the import. To fix this, I will try upgrading `torchvision` to a version that is likely compatible. After upgrading, I will attempt to modify the `rrdbnet_arch.py` file again.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 862
        },
        "id": "ysB8uZi-gedk",
        "outputId": "ad1b90c0-4d2e-400f-d5c8-e5df98196e88"
      },
      "source": [
        "! pip install --upgrade torchvision\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "from basicsr.utils.registry import ARCH_REGISTRY\n",
        "\n",
        "\n",
        "class ResidualDenseBlock(nn.Module):\n",
        "    \"\"\"Residual Dense Block.\n",
        "\n",
        "    Used in RRDB block in ESRGAN.\n",
        "\n",
        "    Args:\n",
        "        num_feat (int): Channel number of intermediate features.\n",
        "        num_grow_ch (int): Channels for growth.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_feat=64, num_grow_ch=32):\n",
        "        super(ResidualDenseBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(num_feat, num_grow_ch, 3, 1, 1)\n",
        "        self.conv2 = nn.Conv2d(num_feat + num_grow_ch, num_grow_ch, 3, 1, 1)\n",
        "        self.conv3 = nn.Conv2d(num_feat + 2 * num_grow_ch, num_grow_ch, 3, 1, 1)\n",
        "        self.conv4 = nn.Conv2d(num_feat + 3 * num_grow_ch, num_grow_ch, 3, 1, 1)\n",
        "        self.conv5 = nn.Conv2d(num_feat + 4 * num_grow_ch, num_feat, 3, 1, 1)\n",
        "\n",
        "        self.lrelu = nn.LakyReLU(negative_slope=0.2, inplace=True)\n",
        "\n",
        "        # New fully connected layer\n",
        "        # The input size is num_grow_ch * H * W. We will determine H and W in the forward pass.\n",
        "        # For now, we initialize it without a specific size, and will re-initialize it in the forward pass\n",
        "        # This is a common practice when the input size is dynamic.\n",
        "        self.fc = None\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Forward function.\n",
        "\n",
        "        Args:\n",
        "            x (Tensor): Input tensor with shape (n, c, h, w).\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Forward results.\n",
        "        \"\"\"\n",
        "        x1 = self.lrelu(self.conv1(x))\n",
        "\n",
        "        # Flatten the output of conv1 and pass it through the fully connected layer\n",
        "        n, c, h, w = x1.size()\n",
        "        if self.fc is None:\n",
        "            self.fc = nn.Linear(c * h * w, c * h * w).to(x.device)\n",
        "\n",
        "        x1_flat = x1.view(n, -1)\n",
        "        x1_fc = self.fc(x1_flat)\n",
        "        x1 = x1_fc.view(n, c, h, w)\n",
        "\n",
        "\n",
        "        x2 = self.lrelu(self.conv2(torch.cat((x, x1), 1)))\n",
        "        x3 = self.lrelu(self.conv3(torch.cat((x, x1, x2), 1)))\n",
        "        x4 = self.lrelu(self.conv4(torch.cat((x, x1, x2, x3), 1)))\n",
        "        x5 = self.conv5(torch.cat((x, x1, x2, x3, x4), 1))\n",
        "        # Empirically, we find that scaling the residual block by a small\n",
        "        # constant improves training stability.\n",
        "        return x5 * 0.2 + x\n",
        "\n",
        "\n",
        "class RRDB(nn.Module):\n",
        "    \"\"\"Residual in Residual Dense Block.\n",
        "\n",
        "    Args:\n",
        "        num_feat (int): Channel number of intermediate features.\n",
        "        num_grow_ch (int): Channels for growth.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_feat, num_grow_ch=32):\n",
        "        super(RRDB, self).__init__()\n",
        "        self.rdb1 = ResidualDenseBlock(num_feat, num_grow_ch)\n",
        "        self.rdb2 = ResidualDenseBlock(num_feat, num_grow_ch)\n",
        "        self.rdb3 = ResidualDenseBlock(num_feat, num_grow_ch)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Forward function.\n",
        "\n",
        "        Args:\n",
        "            x (Tensor): Input tensor with shape (n, c, h, w).\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Forward results.\n",
        "        \"\"\"\n",
        "        out = self.rdb1(x)\n",
        "        out = self.rdb2(out)\n",
        "        out = self.rdb3(out)\n",
        "        # Empirically, we find that scaling the residual block by a small\n",
        "        # constant improves training stability.\n",
        "        return out * 0.2 + x\n",
        "\n",
        "\n",
        "@ARCH_REGISTRY.register()\n",
        "class RRDBNet(nn.Module):\n",
        "    \"\"\"Networks consisting of Residual in Residual Dense Block, which is used\n",
        "    in ESRGAN.\n",
        "\n",
        "    ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks.\n",
        "\n",
        "    Args:\n",
        "        num_in_ch (int): Channel number of inputs.\n",
        "        num_out_ch (int): Channel number of outputs.\n",
        "        num_feat (int): Channel number of intermediate features.\n",
        "            Default: 64\n",
        "        num_block (int): Block number in the trunk network. Default: 23\n",
        "        num_grow_ch (int): Channels for growth. Default: 32\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_in_ch, num_out_ch, num_feat=64, num_block=23, num_grow_ch=32):\n",
        "        super(RRDBNet, self).__init__()\n",
        "        self.conv_first = nn.Conv2d(num_in_ch, num_feat, 3, 1, 1)\n",
        "        self.body = nn.Sequential(*[RRDB(num_feat, num_grow_ch) for _ in range(num_block)])\n",
        "        self.conv_body = nn.Conv2d(num_feat, num_feat, 3, 1, 1)\n",
        "        # upsampling\n",
        "        self.conv_up1 = nn.Conv2d(num_feat, num_feat, 3, 1, 1)\n",
        "        self.conv_up2 = nn.Conv2d(num_feat, num_feat, 3, 1, 1)\n",
        "        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)\n",
        "        self.conv_last = nn.Conv2d(num_feat, num_out_ch, 3, 1, 1)\n",
        "\n",
        "        self.lrelu = nn.LakyReLU(negative_slope=0.2, inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Forward function.\n",
        "\n",
        "        Args:\n",
        "            x (Tensor): Input tensor with shape (n, c, h, w).\n",
        "\n",
        "        Returns:\n",
        "            Tensor: Forward results.\n",
        "        \"\"\"\n",
        "        feat = self.conv_first(x)\n",
        "        body_feat = self.conv_body(self.body(feat))\n",
        "        feat = feat + body_feat\n",
        "        # upsampling\n",
        "        feat = self.lrelu(self.conv_up1(F.interpolate(feat, scale_factor=2, mode='nearest')))\n",
        "        feat = self.lrelu(self.conv_up2(F.interpolate(feat, scale_factor=2, mode='nearest')))\n",
        "        out = self.conv_last(self.lrelu(self.conv_hr(feat)))\n",
        "        return out\n",
        "\n",
        "\n",
        "file_path = '/usr/local/lib/python3.11/dist-packages/basicsr/archs/rrdbnet_arch.py'\n",
        "\n",
        "with open(file_path, 'w') as f:\n",
        "    # We need to write the imports and the classes to the file.\n",
        "    # We will reconstruct the file content with the modified ResidualDenseBlock.\n",
        "\n",
        "    # Imports\n",
        "    f.write(\"import torch\\n\")\n",
        "    f.write(\"from torch import nn\\n\")\n",
        "    f.write(\"from torch.nn import functional as F\\n\\n\")\n",
        "    f.write(\"from basicsr.utils.registry import ARCH_REGISTRY\\n\\n\\n\")\n",
        "\n",
        "    # ResidualDenseBlock\n",
        "    f.write(\"class ResidualDenseBlock(nn.Module):\\n\")\n",
        "    f.write(\"    \\\"\\\"\\\"Residual Dense Block.\\n\\n\")\n",
        "    f.write(\"    Used in RRDB block in ESRGAN.\\n\\n\")\n",
        "    f.write(\"    Args:\\n\")\n",
        "    f.write(\"        num_feat (int): Channel number of intermediate features.\\n\")\n",
        "    f.write(\"        num_grow_ch (int): Channels for growth.\\n\")\n",
        "    f.write(\"    \\\"\\\"\\\"\\n\\n\")\n",
        "    f.write(\"    def __init__(self, num_feat=64, num_grow_ch=32):\\n\")\n",
        "    f.write(\"        super(ResidualDenseBlock, self).__init__()\\n\")\n",
        "    f.write(\"        self.conv1 = nn.Conv2d(num_feat, num_grow_ch, 3, 1, 1)\\n\")\n",
        "    f.write(\"        self.conv2 = nn.Conv2d(num_feat + num_grow_ch, num_grow_ch, 3, 1, 1)\\n\")\n",
        "    f.write(\"        self.conv3 = nn.Conv2d(num_feat + 2 * num_grow_ch, num_grow_ch, 3, 1, 1)\\n\")\n",
        "    f.write(\"        self.conv4 = nn.Conv2d(num_feat + 3 * num_grow_ch, num_grow_ch, 3, 1, 1)\\n\")\n",
        "    f.write(\"        self.conv5 = nn.Conv2d(num_feat + 4 * num_grow_ch, num_feat, 3, 1, 1)\\n\\n\")\n",
        "    f.write(\"        self.lrelu = nn.LakyReLU(negative_slope=0.2, inplace=True)\\n\\n\")\n",
        "    f.write(\"        self.fc = None\\n\\n\")\n",
        "    f.write(\"    def forward(self, x):\\n\")\n",
        "    f.write(\"        \\\"\\\"\\\"Forward function.\\n\\n\")\n",
        "    f.write(\"        Args:\\n\")\n",
        "    f.write(\"            x (Tensor): Input tensor with shape (n, c, h, w).\\n\\n\")\n",
        "    f.write(\"        Returns:\\n\")\n",
        "    f.write(\"            Tensor: Forward results.\\n\")\n",
        "    f.write(\"        \\\"\\\"\\\"\\n\")\n",
        "    f.write(\"        x1 = self.lrelu(self.conv1(x))\\n\\n\")\n",
        "    f.write(\"        n, c, h, w = x1.size()\\n\")\n",
        "    f.write(\"        if self.fc is None: # Initialize FC layer dynamically based on input size\\n\")\n",
        "    f.write(\"            self.fc = nn.Linear(c * h * w, c * h * w).to(x.device)\\n\\n\")\n",
        "    f.write(\"        x1_flat = x1.view(n, -1)\\n\")\n",
        "    f.write(\"        x1_fc = self.fc(x1_flat)\\n\")\n",
        "    f.write(\"        x1 = x1_fc.view(n, c, h, w)\\n\\n\")\n",
        "    f.write(\"        x2 = self.lrelu(self.conv2(torch.cat((x, x1), 1)))\\n\")\n",
        "    f.write(\"        x3 = self.lrelu(self.conv3(torch.cat((x, x1, x2), 1)))\\n\")\n",
        "    f.write(\"        x4 = self.lrelu(self.conv4(torch.cat((x, x1, x2, x3), 1)))\\n\")\n",
        "    f.write(\"        x5 = self.conv5(torch.cat((x, x1, x2, x3, x4), 1))\\n\")\n",
        "    f.write(\"        return x5 * 0.2 + x\\n\\n\\n\")\n",
        "\n",
        "    # RRDB\n",
        "    f.write(\"class RRDB(nn.Module):\\n\")\n",
        "    f.write(\"    \\\"\\\"\\\"Residual in Residual Dense Block.\\n\\n\")\n",
        "    f.write(\"    Args:\\n\")\n",
        "    f.write(\"        num_feat (int): Channel number of intermediate features.\\n\")\n",
        "    f.write(\"        num_grow_ch (int): Channels for growth.\\n\")\n",
        "    f.write(\"    \\\"\\\"\\\"\\n\\n\")\n",
        "    f.write(\"    def __init__(self, num_feat, num_grow_ch=32):\\n\")\n",
        "    f.write(\"        super(RRDB, self).__init__()\\n\")\n",
        "    f.write(\"        self.rdb1 = ResidualDenseBlock(num_feat, num_grow_ch)\\n\")\n",
        "    f.write(\"        self.rdb2 = ResidualDenseBlock(num_feat, num_grow_ch)\\n\")\n",
        "    f.write(\"        self.rdb3 = ResidualDenseBlock(num_feat, num_grow_ch)\\n\\n\")\n",
        "    f.write(\"    def forward(self, x):\\n\")\n",
        "    f.write(\"        \\\"\\\"\\\"Forward function.\\n\\n\")\n",
        "    f.write(\"        Args:\\n\")\n",
        "    f.write(\"            x (Tensor): Input tensor with shape (n, c, h, w).\\n\\n\")\n",
        "    f.write(\"        Returns:\\n\")\n",
        "    f.write(\"            Tensor: Forward results.\\n\")\n",
        "    f.write(\"        \\\"\\\"\\\"\\n\")\n",
        "    f.write(\"        out = self.rdb1(x)\\n\")\n",
        "    f.write(\"        out = self.rdb2(out)\\n\")\n",
        "    f.write(\"        out = self.rdb3(out)\\n\")\n",
        "    f.write(\"        return out * 0.2 + x\\n\\n\\n\")\n",
        "\n",
        "    # RRDBNet\n",
        "    f.write(\"@ARCH_REGISTRY.register()\\n\")\n",
        "    f.write(\"class RRDBNet(nn.Module):\\n\")\n",
        "    f.write(\"    \\\"\\\"\\\"Networks consisting of Residual in Residual Dense Block, which is used\\n\")\n",
        "    f.write(\"    in ESRGAN.\\n\\n\")\n",
        "    f.write(\"    ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks.\\n\\n\")\n",
        "    f.write(\"    Args:\\n\")\n",
        "    f.write(\"        num_in_ch (int): Channel number of inputs.\\n\")\n",
        "    f.write(\"        num_out_ch (int): Channel number of outputs.\\n\")\n",
        "    f.write(\"        num_feat (int): Channel number of intermediate features.\\n\")\n",
        "    f.write(\"            Default: 64\\n\")\n",
        "    f.write(\"        num_block (int): Block number in the trunk network. Default: 23\\n\")\n",
        "    f.write(\"        num_grow_ch (int): Channels for growth. Default: 32\\n\")\n",
        "    f.write(\"    \\\"\\\"\\\"\\n\\n\")\n",
        "    f.write(\"    def __init__(self, num_in_ch, num_out_ch, num_feat=64, num_block=23, num_grow_ch=32):\\n\")\n",
        "    f.write(\"        super(RRDBNet, self).__init__()\\n\")\n",
        "    f.write(\"        self.conv_first = nn.Conv2d(num_in_ch, num_feat, 3, 1, 1)\\n\")\n",
        "    f.write(\"        self.body = nn.Sequential(*[RRDB(num_feat, num_grow_ch) for _ in range(num_block)])\\n\")\n",
        "    f.write(\"        self.conv_body = nn.Conv2d(num_feat, num_feat, 3, 1, 1)\\n\")\n",
        "    f.write(\"        # upsampling\\n\")\n",
        "    f.write(\"        self.conv_up1 = nn.Conv2d(num_feat, num_feat, 3, 1, 1)\\n\")\n",
        "    f.write(\"        self.conv_up2 = nn.Conv2d(num_feat, num_feat, 3, 1, 1)\\n\")\n",
        "    f.write(\"        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)\\n\")\n",
        "    f.write(\"        self.conv_last = nn.Conv2d(num_feat, num_out_ch, 3, 1, 1)\\n\\n\")\n",
        "    f.write(\"        self.lrelu = nn.LakyReLU(negative_slope=0.2, inplace=True)\\n\\n\")\n",
        "    f.write(\"    def forward(self, x):\\n\")\n",
        "    f.write(\"        \\\"\\\"\\\"Forward function.\\n\\n\")\n",
        "    f.write(\"        Args:\\n\")\n",
        "    f.write(\"            x (Tensor): Input tensor with shape (n, c, h, w).\\n\\n\")\n",
        "    f.write(\"        Returns:\\n\")\n",
        "    f.write(\"            Tensor: Forward results.\\n\")\n",
        "    f.write(\"        \\\"\\\"\\\"\\n\")\n",
        "    f.write(\"        feat = self.conv_first(x)\\n\")\n",
        "    f.write(\"        body_feat = self.conv_body(self.body(feat))\\n\")\n",
        "    f.write(\"        feat = feat + body_feat\\n\")\n",
        "    f.write(\"        # upsampling\\n\")\n",
        "    f.write(\"        feat = self.lrelu(self.conv_up1(F.interpolate(feat, scale_factor=2, mode='nearest')))\\n\")\n",
        "    f.write(\"        feat = self.lrelu(self.conv_up2(F.interpolate(feat, scale_factor=2, mode='nearest')))\\n\")\n",
        "    f.write(\"        out = self.conv_last(self.lrelu(self.conv_hr(feat)))\\n\")\n",
        "    f.write(\"        return out\\n\")\n",
        "\n",
        "print(f\"Attempted to upgrade torchvision and rewrite {file_path}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.22.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: torch==2.7.1 in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.7.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->torchvision) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->torchvision) (4.14.1)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->torchvision) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->torchvision) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->torchvision) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->torchvision) (2025.7.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->torchvision) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->torchvision) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->torchvision) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->torchvision) (9.5.1.17)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->torchvision) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->torchvision) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->torchvision) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->torchvision) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->torchvision) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->torchvision) (0.6.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->torchvision) (2.26.2)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->torchvision) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->torchvision) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->torchvision) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.7.1->torchvision) (3.3.1)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.1->torch==2.7.1->torchvision) (75.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch==2.7.1->torchvision) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.7.1->torchvision) (3.0.2)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "An object named 'RRDBNet' was already registered in 'arch' registry!",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-16-1583493573.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mARCH_REGISTRY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mRRDBNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \"\"\"Networks consisting of Residual in Residual Dense Block, which is used\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/basicsr/utils/registry.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(func_or_class)\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_or_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_or_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_register\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_or_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc_or_class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/basicsr/utils/registry.py\u001b[0m in \u001b[0;36m_do_register\u001b[0;34m(self, name, obj, suffix)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         assert (name not in self._obj_map), (f\"An object named '{name}' was already registered \"\n\u001b[0m\u001b[1;32m     43\u001b[0m                                              f\"in '{self._name}' registry!\")\n\u001b[1;32m     44\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_obj_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: An object named 'RRDBNet' was already registered in 'arch' registry!"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16455370"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous command failed because the `RRDBNet` class was already registered in the `ARCH_REGISTRY`. This is likely because the `basicsr` library was imported when the code block started, and that import triggered the registration of the original `RRDBNet` class. To fix this, I need to avoid the initial import of `basicsr` and directly write the modified code to the file. I will remove the import statements for `basicsr.utils.registry` and the `@ARCH_REGISTRY.register()` decorator from the code that writes to the file, as these are causing the re-registration error. The registration will happen when the modified file is imported later.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYvprsOEgjj8",
        "outputId": "d2169267-8f32-49f7-c83d-4c1e93eb5390"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "# Do not import ARCH_REGISTRY here to avoid re-registration issues\n",
        "\n",
        "file_path = '/usr/local/lib/python3.11/dist-packages/basicsr/archs/rrdbnet_arch.py'\n",
        "\n",
        "with open(file_path, 'w') as f:\n",
        "    # Imports\n",
        "    f.write(\"import torch\\n\")\n",
        "    f.write(\"from torch import nn\\n\")\n",
        "    f.write(\"from torch.nn import functional as F\\n\\n\")\n",
        "    # Write the ARCH_REGISTRY import here, so it is imported when the file is loaded\n",
        "    f.write(\"from basicsr.utils.registry import ARCH_REGISTRY\\n\\n\\n\")\n",
        "\n",
        "    # ResidualDenseBlock\n",
        "    f.write(\"class ResidualDenseBlock(nn.Module):\\n\")\n",
        "    f.write(\"    \\\"\\\"\\\"Residual Dense Block.\\n\\n\")\n",
        "    f.write(\"    Used in RRDB block in ESRGAN.\\n\\n\")\n",
        "    f.write(\"    Args:\\n\")\n",
        "    f.write(\"        num_feat (int): Channel number of intermediate features.\\n\")\n",
        "    f.write(\"        num_grow_ch (int): Channels for growth.\\n\")\n",
        "    f.write(\"    \\\"\\\"\\\"\\n\\n\")\n",
        "    f.write(\"    def __init__(self, num_feat=64, num_grow_ch=32):\\n\")\n",
        "    f.write(\"        super(ResidualDenseBlock, self).__init__()\\n\")\n",
        "    f.write(\"        self.conv1 = nn.Conv2d(num_feat, num_grow_ch, 3, 1, 1)\\n\")\n",
        "    f.write(\"        self.conv2 = nn.Conv2d(num_feat + num_grow_ch, num_grow_ch, 3, 1, 1)\\n\")\n",
        "    f.write(\"        self.conv3 = nn.Conv2d(num_feat + 2 * num_grow_ch, num_grow_ch, 3, 1, 1)\\n\")\n",
        "    f.write(\"        self.conv4 = nn.Conv2d(num_feat + 3 * num_grow_ch, num_grow_ch, 3, 1, 1)\\n\")\n",
        "    f.write(\"        self.conv5 = nn.Conv2d(num_feat + 4 * num_grow_ch, num_feat, 3, 1, 1)\\n\\n\")\n",
        "    f.write(\"        self.lrelu = nn.LakyReLU(negative_slope=0.2, inplace=True)\\n\\n\")\n",
        "    f.write(\"        self.fc = None\\n\\n\")\n",
        "    f.write(\"    def forward(self, x):\\n\")\n",
        "    f.write(\"        \\\"\\\"\\\"Forward function.\\n\\n\")\n",
        "    f.write(\"        Args:\\n\")\n",
        "    f.write(\"            x (Tensor): Input tensor with shape (n, c, h, w).\\n\\n\")\n",
        "    f.write(\"        Returns:\\n\")\n",
        "    f.write(\"            Tensor: Forward results.\\n\")\n",
        "    f.write(\"        \\\"\\\"\\\"\\n\")\n",
        "    f.write(\"        x1 = self.lrelu(self.conv1(x))\\n\\n\")\n",
        "    f.write(\"        n, c, h, w = x1.size()\\n\")\n",
        "    f.write(\"        if self.fc is None: # Initialize FC layer dynamically based on input size\\n\")\n",
        "    f.write(\"            self.fc = nn.Linear(c * h * w, c * h * w).to(x.device)\\n\\n\")\n",
        "    f.write(\"        x1_flat = x1.view(n, -1)\\n\")\n",
        "    f.write(\"        x1_fc = self.fc(x1_flat)\\n\")\n",
        "    f.write(\"        x1 = x1_fc.view(n, c, h, w)\\n\\n\")\n",
        "    f.write(\"        x2 = self.lrelu(self.conv2(torch.cat((x, x1), 1)))\\n\")\n",
        "    f.write(\"        x3 = self.lrelu(self.conv3(torch.cat((x, x1, x2), 1)))\\n\")\n",
        "    f.write(\"        x4 = self.lrelu(self.conv4(torch.cat((x, x1, x2, x3), 1)))\\n\")\n",
        "    f.write(\"        x5 = self.conv5(torch.cat((x, x1, x2, x3, x4), 1))\\n\")\n",
        "    f.write(\"        return x5 * 0.2 + x\\n\\n\\n\")\n",
        "\n",
        "    # RRDB\n",
        "    f.write(\"class RRDB(nn.Module):\\n\")\n",
        "    f.write(\"    \\\"\\\"\\\"Residual in Residual Dense Block.\\n\\n\")\n",
        "    f.write(\"    Args:\\n\")\n",
        "    f.write(\"        num_feat (int): Channel number of intermediate features.\\n\")\n",
        "    f.write(\"        num_grow_ch (int): Channels for growth.\\n\")\n",
        "    f.write(\"    \\\"\\\"\\\"\\n\\n\")\n",
        "    f.write(\"    def __init__(self, num_feat, num_grow_ch=32):\\n\")\n",
        "    f.write(\"        super(RRDB, self).__init__()\\n\")\n",
        "    f.write(\"        self.rdb1 = ResidualDenseBlock(num_feat, num_grow_ch)\\n\")\n",
        "    f.write(\"        self.rdb2 = ResidualDenseBlock(num_feat, num_grow_ch)\\n\")\n",
        "    f.write(\"        self.rdb3 = ResidualDenseBlock(num_feat, num_grow_ch)\\n\\n\")\n",
        "    f.write(\"    def forward(self, x):\\n\")\n",
        "    f.write(\"        \\\"\\\"\\\"Forward function.\\n\\n\")\n",
        "    f.write(\"        Args:\\n\")\n",
        "    f.write(\"            x (Tensor): Input tensor with shape (n, c, h, w).\\n\\n\")\n",
        "    f.write(\"        Returns:\\n\")\n",
        "    f.write(\"            Tensor: Forward results.\\n\")\n",
        "    f.write(\"        \\\"\\\"\\\"\\n\")\n",
        "    f.write(\"        out = self.rdb1(x)\\n\")\n",
        "    f.write(\"        out = self.rdb2(out)\\n\")\n",
        "    f.write(\"        out = self.rdb3(out)\\n\")\n",
        "    f.write(\"        return out * 0.2 + x\\n\\n\\n\")\n",
        "\n",
        "    # RRDBNet\n",
        "    # Add the ARCH_REGISTRY decorator here\n",
        "    f.write(\"@ARCH_REGISTRY.register()\\n\")\n",
        "    f.write(\"class RRDBNet(nn.Module):\\n\")\n",
        "    f.write(\"    \\\"\\\"\\\"Networks consisting of Residual in Residual Dense Block, which is used\\n\")\n",
        "    f.write(\"    in ESRGAN.\\n\\n\")\n",
        "    f.write(\"    ESRGAN: Enhanced Super-Resolution Generative Adversarial Networks.\\n\\n\")\n",
        "    f.write(\"    Args:\\n\")\n",
        "    f.write(\"        num_in_ch (int): Channel number of inputs.\\n\")\n",
        "    f.write(\"        num_out_ch (int): Channel number of outputs.\\n\")\n",
        "    f.write(\"        num_feat (int): Channel number of intermediate features.\\n\")\n",
        "    f.write(\"            Default: 64\\n\")\n",
        "    f.write(\"        num_block (int): Block number in the trunk network. Default: 23\\n\")\n",
        "    f.write(\"        num_grow_ch (int): Channels for growth. Default: 32\\n\")\n",
        "    f.write(\"    \\\"\\\"\\\"\\n\\n\")\n",
        "    f.write(\"    def __init__(self, num_in_ch, num_out_ch, num_feat=64, num_block=23, num_grow_ch=32):\\n\")\n",
        "    f.write(\"        super(RRDBNet, self).__init__()\\n\")\n",
        "    f.write(\"        self.conv_first = nn.Conv2d(num_in_ch, num_feat, 3, 1, 1)\\n\")\n",
        "    f.write(\"        self.body = nn.Sequential(*[RRDB(num_feat, num_grow_ch) for _ in range(num_block)])\\n\")\n",
        "    f.write(\"        self.conv_body = nn.Conv2d(num_feat, num_feat, 3, 1, 1)\\n\")\n",
        "    f.write(\"        # upsampling\\n\")\n",
        "    f.write(\"        self.conv_up1 = nn.Conv2d(num_feat, num_feat, 3, 1, 1)\\n\")\n",
        "    f.write(\"        self.conv_up2 = nn.Conv2d(num_feat, num_feat, 3, 1, 1)\\n\")\n",
        "    f.write(\"        self.conv_hr = nn.Conv2d(num_feat, num_feat, 3, 1, 1)\\n\")\n",
        "    f.write(\"        self.conv_last = nn.Conv2d(num_feat, num_out_ch, 3, 1, 1)\\n\\n\")\n",
        "    f.write(\"        self.lrelu = nn.LakyReLU(negative_slope=0.2, inplace=True)\\n\\n\")\n",
        "    f.write(\"    def forward(self, x):\\n\")\n",
        "    f.write(\"        \\\"\\\"\\\"Forward function.\\n\\n\")\n",
        "    f.write(\"        Args:\\n\")\n",
        "    f.write(\"            x (Tensor): Input tensor with shape (n, c, h, w).\\n\\n\")\n",
        "    f.write(\"        Returns:\\n\")\n",
        "    f.write(\"            Tensor: Forward results.\\n\")\n",
        "    f.write(\"        \\\"\\\"\\\"\\n\")\n",
        "    f.write(\"        feat = self.conv_first(x)\\n\")\n",
        "    f.write(\"        body_feat = self.conv_body(self.body(feat))\\n\")\n",
        "    f.write(\"        feat = feat + body_feat\\n\")\n",
        "    f.write(\"        # upsampling\\n\")\n",
        "    f.write(\"        feat = self.lrelu(self.conv_up1(F.interpolate(feat, scale_factor=2, mode='nearest')))\\n\")\n",
        "    f.write(\"        feat = self.lrelu(self.conv_up2(F.interpolate(feat, scale_factor=2, mode='nearest')))\\n\")\n",
        "    f.write(\"        out = self.conv_last(self.lrelu(self.conv_hr(feat)))\\n\")\n",
        "    f.write(\"        return out\\n\")\n",
        "\n",
        "\n",
        "print(f\"Successfully modified and saved {file_path}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully modified and saved /usr/local/lib/python3.11/dist-packages/basicsr/archs/rrdbnet_arch.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b229132"
      },
      "source": [
        "## 데이터 로딩 및 전처리\n",
        "\n",
        "### Subtask:\n",
        "1600x1200 크기의 학습 데이터를 로드하고 모델 학습에 필요한 형태로 전처리하는 코드를 작성합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "db72be48"
      },
      "source": [
        "**Reasoning**:\n",
        "Import necessary libraries and define a custom PyTorch Dataset for loading and preprocessing image data of size 1600x1200.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae2325e1",
        "outputId": "cd743b6a-618e-4fd0-86af-b57f66f51695"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "class CustomSRDataset(Dataset):\n",
        "    def __init__(self, hr_dir, lr_transform=None, hr_transform=None):\n",
        "        self.hr_dir = hr_dir\n",
        "        self.lr_transform = lr_transform\n",
        "        self.hr_transform = hr_transform\n",
        "        self.image_filenames = [f for f in os.listdir(hr_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_filenames)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        hr_img_path = os.path.join(self.hr_dir, self.image_filenames[idx])\n",
        "        hr_img = Image.open(hr_img_path).convert('RGB')\n",
        "\n",
        "        # Assuming a simple downsampling for creating LR images.\n",
        "        # In a real scenario, you might load pre-generated LR images\n",
        "        # or use more sophisticated degradation methods.\n",
        "        lr_img = hr_img.resize((hr_img.width // 4, hr_img.height // 4), Image.BICUBIC)\n",
        "\n",
        "        if self.lr_transform:\n",
        "            lr_img = self.lr_transform(lr_img)\n",
        "        if self.hr_transform:\n",
        "            hr_img = self.hr_transform(hr_img)\n",
        "\n",
        "        return lr_img, hr_img\n",
        "\n",
        "# Define transformations\n",
        "hr_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]) # Normalize to [-1, 1]\n",
        "])\n",
        "\n",
        "lr_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]) # Normalize to [-1, 1]\n",
        "])\n",
        "\n",
        "# Example usage (assuming your high-resolution images are in '/content/drive/My Drive/work/hr_images')\n",
        "# Create a dummy directory and dummy images for demonstration if they don't exist\n",
        "hr_dummy_dir = '/content/drive/My Drive/work/hr_images'\n",
        "os.makedirs(hr_dummy_dir, exist_ok=True)\n",
        "if not os.listdir(hr_dummy_dir):\n",
        "    print(f\"Creating dummy images in {hr_dummy_dir}\")\n",
        "    dummy_img = Image.new('RGB', (1600, 1200), color = 'red')\n",
        "    dummy_img.save(os.path.join(hr_dummy_dir, 'dummy_image_1.png'))\n",
        "    dummy_img.save(os.path.join(hr_dummy_dir, 'dummy_image_2.png'))\n",
        "\n",
        "\n",
        "dataset = CustomSRDataset(hr_dir=hr_dummy_dir,\n",
        "                          lr_transform=lr_transform,\n",
        "                          hr_transform=hr_transform)\n",
        "\n",
        "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
        "\n",
        "# Verify the output shapes\n",
        "for lr_batch, hr_batch in dataloader:\n",
        "    print(f\"LR Batch Shape: {lr_batch.shape}\")\n",
        "    print(f\"HR Batch Shape: {hr_batch.shape}\")\n",
        "    break # Just check one batch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating dummy images in /content/drive/My Drive/work/hr_images\n",
            "LR Batch Shape: torch.Size([2, 3, 300, 400])\n",
            "HR Batch Shape: torch.Size([2, 3, 1200, 1600])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0ee3c30"
      },
      "source": [
        "## 모델 학습 설정\n",
        "\n",
        "### Subtask:\n",
        "수정된 모델 아키텍처를 사용하여 학습을 설정합니다. 손실 함수, 옵티마이저, 학습률 스케줄러 등을 정의합니다. 사전 학습된 Real-ESRGAN 모델의 가중치를 로드하여 초기화에 사용할 수 있습니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b453770b"
      },
      "source": [
        "**Reasoning**:\n",
        "Set up the training configuration by defining the model, loss function, optimizer, and optionally a learning rate scheduler and loading pre-trained weights.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "4f81439a",
        "outputId": "9d225b67-13d7-4106-a6c8-c71dc115c3c5"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import sys\n",
        "\n",
        "# Add the directory containing the modified rrdbnet_arch.py to the system path\n",
        "# This is necessary so that the modified module can be imported correctly\n",
        "sys.path.insert(0, '/usr/local/lib/python3.11/dist-packages/basicsr/archs')\n",
        "\n",
        "# Import the modified RRDBNet\n",
        "from rrdbnet_arch import RRDBNet\n",
        "\n",
        "# 2. Instantiate the modified RRDBNet model\n",
        "# Assuming RGB images, so input and output channels are 3.\n",
        "# num_feat, num_block, and num_grow_ch can be kept as defaults or adjusted.\n",
        "# The dynamic FC layer size is handled within the modified RRDBNet class.\n",
        "model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64, num_block=23, num_grow_ch=32)\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "# 3. Define a loss function\n",
        "# Using L1 loss as a common choice for super-resolution\n",
        "criterion = nn.L1Loss()\n",
        "\n",
        "# 4. Define an optimizer\n",
        "# Using Adam optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.999))\n",
        "\n",
        "# 5. Implement a learning rate scheduler (Optional but recommended)\n",
        "# Using a StepLR scheduler\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=10000, gamma=0.5) # Adjust step_size and gamma as needed\n",
        "\n",
        "# 6. Load a pre-trained Real-ESRGAN model's state dictionary (Optional)\n",
        "# You would typically download a pre-trained model file (.pth) and load it.\n",
        "# Example: Load the 512x512 model weights\n",
        "# pretrain_model_path = '/content/drive/My Drive/work/Real-ESRGAN_x4plus.pth' # Replace with your path\n",
        "# try:\n",
        "#     pretrained_dict = torch.load(pretrain_model_path)\n",
        "#     model_dict = model.state_dict()\n",
        "\n",
        "#     # 1. filter out unnecessary keys\n",
        "#     # The keys for the new FC layer will not be in the pre-trained weights, so they will be filtered out.\n",
        "#     # The FC layer is initialized dynamically anyway.\n",
        "#     pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
        "#     # 2. overwrite entries in the existing state dict\n",
        "#     model_dict.update(pretrained_dict)\n",
        "#     # 3. load the new state dict\n",
        "#     model.load_state_dict(model_dict)\n",
        "#     print(f\"Loaded pre-trained weights from {pretrain_model_path}\")\n",
        "# except FileNotFoundError:\n",
        "#     print(f\"Pre-trained model not found at {pretrain_model_path}. Starting training from scratch.\")\n",
        "# except Exception as e:\n",
        "#     print(f\"Error loading pre-trained model: {e}\")\n",
        "\n",
        "print(\"Training setup complete: model, criterion, optimizer, and scheduler defined.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "An object named 'RRDBNet' was already registered in 'arch' registry!",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-19-4285048726.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Import the modified RRDBNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mrrdbnet_arch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRRDBNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# 2. Instantiate the modified RRDBNet model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/basicsr/archs/rrdbnet_arch.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mARCH_REGISTRY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mRRDBNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \"\"\"Networks consisting of Residual in Residual Dense Block, which is used\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/basicsr/utils/registry.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(func_or_class)\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_or_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_or_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_register\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_or_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc_or_class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/basicsr/utils/registry.py\u001b[0m in \u001b[0;36m_do_register\u001b[0;34m(self, name, obj, suffix)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         assert (name not in self._obj_map), (f\"An object named '{name}' was already registered \"\n\u001b[0m\u001b[1;32m     43\u001b[0m                                              f\"in '{self._name}' registry!\")\n\u001b[1;32m     44\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_obj_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: An object named 'RRDBNet' was already registered in 'arch' registry!"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0f73ca9"
      },
      "source": [
        "**Reasoning**:\n",
        "The `AssertionError` indicates that `RRDBNet` is already registered in the `ARCH_REGISTRY`. This is likely because the previous modification step re-imported the `basicsr` library, which re-registered the original `RRDBNet`. To fix this, I need to restart the Python kernel to clear the existing registrations and then re-import the modified `rrdbnet_arch.py`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Abq-sg5Agu6L"
      },
      "source": [
        "# Restart the Python kernel to clear registered modules\n",
        "# This command is specific to Jupyter environments and will clear the state\n",
        "# After the kernel restarts, the next code cell will re-execute from a clean state.\n",
        "import os\n",
        "os._exit(00)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1b18b71"
      },
      "source": [
        "**Reasoning**:\n",
        "After restarting the kernel, I need to re-execute the code to set up the training, including importing the modified `RRDBNet` and defining the loss function, optimizer, and scheduler.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "c3e82727",
        "outputId": "7a63f124-61df-487a-b7ae-b3f9f37012b7"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Add the directory containing the modified rrdbnet_arch.py to the system path\n",
        "# This is necessary so that the modified module can be imported correctly\n",
        "# Ensure the path is correct after the kernel restart\n",
        "sys.path.insert(0, '/usr/local/lib/python3.11/dist-packages/basicsr/archs')\n",
        "\n",
        "# Import the modified RRDBNet\n",
        "# This import should now work without the registration error after the kernel restart\n",
        "from rrdbnet_arch import RRDBNet\n",
        "\n",
        "# 2. Instantiate the modified RRDBNet model\n",
        "# Assuming RGB images, so input and output channels are 3.\n",
        "# num_feat, num_block, and num_grow_ch can be kept as defaults or adjusted.\n",
        "# The dynamic FC layer size is handled within the modified RRDBNet class.\n",
        "model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64, num_block=23, num_grow_ch=32)\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "# 3. Define a loss function\n",
        "# Using L1 loss as a common choice for super-resolution\n",
        "criterion = nn.L1Loss()\n",
        "\n",
        "# 4. Define an optimizer\n",
        "# Using Adam optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.999))\n",
        "\n",
        "# 5. Implement a learning rate scheduler (Optional but recommended)\n",
        "# Using a StepLR scheduler\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=10000, gamma=0.5) # Adjust step_size and gamma as needed\n",
        "\n",
        "# 6. Load a pre-trained Real-ESRGAN model's state dictionary (Optional)\n",
        "# You would typically download a pre-trained model file (.pth) and load it.\n",
        "# Example: Load the 512x512 model weights\n",
        "# pretrain_model_path = '/content/drive/My Drive/work/Real-ESRGAN_x4plus.pth' # Replace with your path\n",
        "# try:\n",
        "#     if os.path.exists(pretrain_model_path):\n",
        "#         pretrained_dict = torch.load(pretrain_model_path, map_location=device)\n",
        "#         model_dict = model.state_dict()\n",
        "\n",
        "#         # 1. filter out unnecessary keys\n",
        "#         # The keys for the new FC layer will not be in the pre-trained weights, so they will be filtered out.\n",
        "#         # The FC layer is initialized dynamically anyway.\n",
        "#         pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
        "#         # 2. overwrite entries in the existing state dict\n",
        "#         model_dict.update(pretrained_dict)\n",
        "#         # 3. load the new state dict\n",
        "#         model.load_state_dict(model_dict)\n",
        "#         print(f\"Loaded pre-trained weights from {pretrain_model_path}\")\n",
        "#     else:\n",
        "#          print(f\"Pre-trained model not found at {pretrain_model_path}. Starting training from scratch.\")\n",
        "\n",
        "# except Exception as e:\n",
        "#     print(f\"Error loading pre-trained model: {e}\")\n",
        "\n",
        "print(\"Training setup complete: model, criterion, optimizer, and scheduler defined.\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torchvision.transforms.functional_tensor'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1-2498763498.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Import the modified RRDBNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# This import should now work without the registration error after the kernel restart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mrrdbnet_arch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRRDBNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# 2. Instantiate the modified RRDBNet model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/basicsr/archs/rrdbnet_arch.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbasicsr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregistry\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mARCH_REGISTRY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/basicsr/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# flake8: noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0marchs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/basicsr/data/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mdataset_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_folder\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_dataset.py'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# import all the dataset modules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0m_dataset_modules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'basicsr.data.{file_name}'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset_filenames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/basicsr/data/__init__.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mdataset_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_folder\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_dataset.py'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# import all the dataset modules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0m_dataset_modules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'basicsr.data.{file_name}'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset_filenames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/basicsr/data/realesrgan_dataset.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbasicsr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegradations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcircular_lowpass_kernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_mixed_kernels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbasicsr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbasicsr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFileClient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_root_logger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimfrombytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg2tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/basicsr/data/degradations.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspecial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmultivariate_normal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional_tensor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrgb_to_grayscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# -------------------------------------------------------------------- #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchvision.transforms.functional_tensor'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f0b1931"
      },
      "source": [
        "**Reasoning**:\n",
        "The `ModuleNotFoundError: No module named 'torchvision.transforms.functional_tensor'` error persists. This indicates a compatibility issue between the installed `basicsr` and `torchvision` versions, where `basicsr` is trying to import a module from `torchvision` that doesn't exist in the current version. Although I attempted to upgrade `torchvision` earlier, it seems it didn't resolve the specific import issue that `basicsr.data.degradations` is facing. Since the goal is to set up the training environment using the *modified* model architecture, and the error is occurring during the import of related `basicsr` data modules (which are not directly needed for *defining* the model, loss, and optimizer in this step), I will try to import `RRDBNet` directly from the modified file path using `importlib.util` to bypass the standard `basicsr` import mechanism that triggers the error.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "49XRWIytg1HV",
        "outputId": "88672849-adbe-460c-93a2-a01652416c51"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import sys\n",
        "import os\n",
        "import importlib.util\n",
        "\n",
        "# Define the path to the modified rrdbnet_arch.py\n",
        "file_path = '/usr/local/lib/python3.11/dist-packages/basicsr/archs/rrdbnet_arch.py'\n",
        "\n",
        "# Use importlib to load the module directly from the file path\n",
        "spec = importlib.util.spec_from_file_location(\"rrdbnet_arch\", file_path)\n",
        "rrdbnet_arch = importlib.util.module_from_spec(spec)\n",
        "sys.modules[\"rrdbnet_arch\"] = rrdbnet_arch\n",
        "spec.loader.exec_module(rrdbnet_arch)\n",
        "\n",
        "# Now, access the RRDBNet class from the loaded module\n",
        "RRDBNet = rrdbnet_arch.RRDBNet\n",
        "\n",
        "# 2. Instantiate the modified RRDBNet model\n",
        "# Assuming RGB images, so input and output channels are 3.\n",
        "# num_feat, num_block, and num_grow_ch can be kept as defaults or adjusted.\n",
        "# The dynamic FC layer size is handled within the modified RRDBNet class.\n",
        "model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64, num_block=23, num_grow_ch=32)\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "# 3. Define a loss function\n",
        "# Using L1 loss as a common choice for super-resolution\n",
        "criterion = nn.L1Loss()\n",
        "\n",
        "# 4. Define an optimizer\n",
        "# Using Adam optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.999))\n",
        "\n",
        "# 5. Implement a learning rate scheduler (Optional but recommended)\n",
        "# Using a StepLR scheduler\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=10000, gamma=0.5) # Adjust step_size and gamma as needed\n",
        "\n",
        "# 6. Load a pre-trained Real-ESRGAN model's state dictionary (Optional)\n",
        "# You would typically download a pre-trained model file (.pth) and load it.\n",
        "# Example: Load the 512x512 model weights\n",
        "# pretrain_model_path = '/content/drive/My Drive/work/Real-ESRGAN_x4plus.pth' # Replace with your path\n",
        "# try:\n",
        "#     if os.path.exists(pretrain_model_path):\n",
        "#         pretrained_dict = torch.load(pretrain_model_path, map_location=device)\n",
        "#         model_dict = model.state_dict()\n",
        "\n",
        "#         # 1. filter out unnecessary keys\n",
        "#         # The keys for the new FC layer will not be in the pre-trained weights, so they will be filtered out.\n",
        "#         # The FC layer is initialized dynamically anyway.\n",
        "#         pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
        "#         # 2. overwrite entries in the existing state dict\n",
        "#         model_dict.update(pretrained_dict)\n",
        "#         # 3. load the new state dict\n",
        "#         model.load_state_dict(model_dict)\n",
        "#         print(f\"Loaded pre-trained weights from {pretrain_model_path}\")\n",
        "#     else:\n",
        "#          print(f\"Pre-trained model not found at {pretrain_model_path}. Starting training from scratch.\")\n",
        "\n",
        "# except Exception as e:\n",
        "#     print(f\"Error loading pre-trained model: {e}\")\n",
        "\n",
        "print(\"Training setup complete: model, criterion, optimizer, and scheduler defined.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "An object named 'RRDBNet' was already registered in 'arch' registry!",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2-3123668064.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mrrdbnet_arch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_from_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"rrdbnet_arch\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrrdbnet_arch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexec_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrrdbnet_arch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Now, access the RRDBNet class from the loaded module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/basicsr/archs/rrdbnet_arch.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mARCH_REGISTRY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mRRDBNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \"\"\"Networks consisting of Residual in Residual Dense Block, which is used\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/basicsr/utils/registry.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(func_or_class)\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_or_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_or_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_register\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_or_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc_or_class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/basicsr/utils/registry.py\u001b[0m in \u001b[0;36m_do_register\u001b[0;34m(self, name, obj, suffix)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         assert (name not in self._obj_map), (f\"An object named '{name}' was already registered \"\n\u001b[0m\u001b[1;32m     43\u001b[0m                                              f\"in '{self._name}' registry!\")\n\u001b[1;32m     44\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_obj_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: An object named 'RRDBNet' was already registered in 'arch' registry!"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aef79cd3"
      },
      "source": [
        "**Reasoning**:\n",
        "The `AssertionError` persists even with `importlib.util`, indicating that the `ARCH_REGISTRY` still holds a reference to `RRDBNet`. Restarting the kernel is the most reliable way to clear these registrations. I will restart the kernel again.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6g7g6oeNg2oi"
      },
      "source": [
        "# Restart the Python kernel to clear registered modules\n",
        "# This command is specific to Jupyter environments and will clear the state\n",
        "# After the kernel restarts, the next code cell will re-execute from a clean state.\n",
        "import os\n",
        "os._exit(00)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cbab0d0"
      },
      "source": [
        "**Reasoning**:\n",
        "After restarting the kernel, I need to re-execute the code to set up the training, including importing the modified `RRDBNet` and defining the loss function, optimizer, and scheduler. I will use the `importlib.util` method again as it is less likely to trigger the full `basicsr` import chain compared to adding the path to `sys.path`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68661da1",
        "outputId": "c8b56cc4-dd65-489a-f852-653cec3d493b"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import sys\n",
        "import os\n",
        "import importlib.util\n",
        "\n",
        "# Define the path to the modified rrdbnet_arch.py\n",
        "file_path = '/usr/local/lib/python3.11/dist-packages/basicsr/archs/rrdbnet_arch.py'\n",
        "\n",
        "# Use importlib to load the module directly from the file path\n",
        "# Check if the file exists before attempting to load\n",
        "if not os.path.exists(file_path):\n",
        "    print(f\"Error: Modified model file not found at {file_path}\")\n",
        "else:\n",
        "    spec = importlib.util.spec_from_file_location(\"rrdbnet_arch\", file_path)\n",
        "    rrdbnet_arch = importlib.util.module_from_spec(spec)\n",
        "    sys.modules[\"rrdbnet_arch\"] = rrdbnet_arch\n",
        "    try:\n",
        "        spec.loader.exec_module(rrdbnet_arch)\n",
        "\n",
        "        # Now, access the RRDBNet class from the loaded module\n",
        "        RRDBNet = rrdbnet_arch.RRDBNet\n",
        "\n",
        "        # 2. Instantiate the modified RRDBNet model\n",
        "        # Assuming RGB images, so input and output channels are 3.\n",
        "        # num_feat, num_block, and num_grow_ch can be kept as defaults or adjusted.\n",
        "        # The dynamic FC layer size is handled within the modified RRDBNet class.\n",
        "        model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64, num_block=23, num_grow_ch=32)\n",
        "\n",
        "        # Move model to GPU if available\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        model.to(device)\n",
        "\n",
        "        # 3. Define a loss function\n",
        "        # Using L1 loss as a common choice for super-resolution\n",
        "        criterion = nn.L1Loss()\n",
        "\n",
        "        # 4. Define an optimizer\n",
        "        # Using Adam optimizer\n",
        "        optimizer = optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.999))\n",
        "\n",
        "        # 5. Implement a learning rate scheduler (Optional but recommended)\n",
        "        # Using a StepLR scheduler\n",
        "        scheduler = lr_scheduler.StepLR(optimizer, step_size=10000, gamma=0.5) # Adjust step_size and gamma as needed\n",
        "\n",
        "        # 6. Load a pre-trained Real-ESRGAN model's state dictionary (Optional)\n",
        "        # You would typically download a pre-trained model file (.pth) and load it.\n",
        "        # Example: Load the 512x512 model weights\n",
        "        # pretrain_model_path = '/content/drive/My Drive/work/Real-ESRGAN_x4plus.pth' # Replace with your path\n",
        "        # try:\n",
        "        #     if os.path.exists(pretrain_model_path):\n",
        "        #         pretrained_dict = torch.load(pretrain_model_path, map_location=device)\n",
        "        #         model_dict = model.state_dict()\n",
        "\n",
        "        #         # 1. filter out unnecessary keys\n",
        "        #         # The keys for the new FC layer will not be in the pre-trained weights, so they will be filtered out.\n",
        "        #         # The FC layer is initialized dynamically anyway.\n",
        "        #         pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
        "        #         # 2. overwrite entries in the existing state dict\n",
        "        #         model_dict.update(pretrained_dict)\n",
        "        #         # 3. load the new state dict\n",
        "        #         model.load_state_dict(model_dict)\n",
        "        #         print(f\"Loaded pre-trained weights from {pretrain_model_path}\")\n",
        "        #     else:\n",
        "        #          print(f\"Pre-trained model not found at {pretrain_model_path}. Starting training from scratch.\")\n",
        "\n",
        "        # except Exception as e:\n",
        "        #     print(f\"Error loading pre-trained model: {e}\")\n",
        "\n",
        "        print(\"Training setup complete: model, criterion, optimizer, and scheduler defined.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during module execution or model setup: {e}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An error occurred during module execution or model setup: No module named 'torchvision.transforms.functional_tensor'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a662c5d8"
      },
      "source": [
        "**Reasoning**:\n",
        "The `ModuleNotFoundError: No module named 'torchvision.transforms.functional_tensor'` error is still occurring when executing the modified `rrdbnet_arch.py` module via `importlib`, even after kernel restarts. This strongly suggests an underlying dependency issue within the `basicsr` library itself, where parts of it (specifically the data-related modules, which get imported when `basicsr.archs` is accessed) are incompatible with the installed version of `torchvision`. Since the current subtask is only to set up the training configuration (model, loss, optimizer, scheduler) and not to run the full training loop which would require the data modules, I can try to *temporarily* comment out the problematic import lines within the `rrdbnet_arch.py` file to allow the model definition part to be imported and instantiated. This is a workaround to complete the current subtask, acknowledging that full training might still face issues due to the dependency conflict.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46cf5f50",
        "outputId": "26e399a2-edea-44b1-aa27-713ce53aeae3"
      },
      "source": [
        "import os\n",
        "\n",
        "file_path = '/usr/local/lib/python3.11/dist-packages/basicsr/archs/rrdbnet_arch.py'\n",
        "\n",
        "try:\n",
        "    with open(file_path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    modified_lines = []\n",
        "    for line in lines:\n",
        "        # Comment out the problematic import line in the original file\n",
        "        if \"from basicsr.utils.registry import ARCH_REGISTRY\" in line:\n",
        "             modified_lines.append(\"# Commented out by AI\\n\")\n",
        "             modified_lines.append(\"# \" + line)\n",
        "        else:\n",
        "             modified_lines.append(line)\n",
        "\n",
        "    with open(file_path, 'w') as f:\n",
        "        f.writelines(modified_lines)\n",
        "\n",
        "    print(f\"Successfully commented out problematic import in {file_path}\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: File not found at {file_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while modifying the file: {e}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully commented out problematic import in /usr/local/lib/python3.11/dist-packages/basicsr/archs/rrdbnet_arch.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "042d4341"
      },
      "source": [
        "**Reasoning**:\n",
        "I have temporarily commented out the problematic import in `rrdbnet_arch.py`. Now, I will attempt to import the `RRDBNet` class directly from the modified file path using `importlib.util` again. This should allow me to instantiate the model and set up the training configuration without triggering the incompatible imports within the `basicsr` data modules.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d4668d8",
        "outputId": "093dec13-4ae1-4b29-d09b-1ed657ddbc5c"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import sys\n",
        "import os\n",
        "import importlib.util\n",
        "\n",
        "# Define the path to the modified rrdbnet_arch.py\n",
        "file_path = '/usr/local/lib/python3.11/dist-packages/basicsr/archs/rrdbnet_arch.py'\n",
        "\n",
        "# Use importlib to load the module directly from the file path\n",
        "# Check if the file exists before attempting to load\n",
        "if not os.path.exists(file_path):\n",
        "    print(f\"Error: Modified model file not found at {file_path}\")\n",
        "else:\n",
        "    spec = importlib.util.spec_from_file_location(\"rrdbnet_arch\", file_path)\n",
        "    rrdbnet_arch = importlib.util.module_from_spec(spec)\n",
        "    sys.modules[\"rrdbnet_arch\"] = rrdbnet_arch\n",
        "    try:\n",
        "        spec.loader.exec_module(rrdbnet_arch)\n",
        "\n",
        "        # Now, access the RRDBNet class from the loaded module\n",
        "        # Since ARCH_REGISTRY is commented out, we access the class directly\n",
        "        if hasattr(rrdbnet_arch, 'RRDBNet'):\n",
        "            RRDBNet = rrdbnet_arch.RRDBNet\n",
        "\n",
        "            # 2. Instantiate the modified RRDBNet model\n",
        "            # Assuming RGB images, so input and output channels are 3.\n",
        "            # num_feat, num_block, and num_grow_ch can be kept as defaults or adjusted.\n",
        "            # The dynamic FC layer size is handled within the modified RRDBNet class.\n",
        "            model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64, num_block=23, num_grow_ch=32)\n",
        "\n",
        "            # Move model to GPU if available\n",
        "            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "            model.to(device)\n",
        "\n",
        "            # 3. Define a loss function\n",
        "            # Using L1 loss as a common choice for super-resolution\n",
        "            criterion = nn.L1Loss()\n",
        "\n",
        "            # 4. Define an optimizer\n",
        "            # Using Adam optimizer\n",
        "            optimizer = optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.999))\n",
        "\n",
        "            # 5. Implement a learning rate scheduler (Optional but recommended)\n",
        "            # Using a StepLR scheduler\n",
        "            scheduler = lr_scheduler.StepLR(optimizer, step_size=10000, gamma=0.5) # Adjust step_size and gamma as needed\n",
        "\n",
        "            # 6. Load a pre-trained Real-ESRGAN model's state dictionary (Optional)\n",
        "            # You would typically download a pre-trained model file (.pth) and load it.\n",
        "            # Example: Load the 512x512 model weights\n",
        "            # pretrain_model_path = '/content/drive/My Drive/work/Real-ESRGAN_x4plus.pth' # Replace with your path\n",
        "            # try:\n",
        "            #     if os.path.exists(pretrain_model_path):\n",
        "            #         pretrained_dict = torch.load(pretrain_model_path, map_location=device)\n",
        "            #         model_dict = model.state_dict()\n",
        "\n",
        "            #         # 1. filter out unnecessary keys\n",
        "            #         # The keys for the new FC layer will not be in the pre-trained weights, so they will be filtered out.\n",
        "            #         # The FC layer is initialized dynamically anyway.\n",
        "            #         pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
        "            #         # 2. overwrite entries in the existing state dict\n",
        "            #         model_dict.update(pretrained_dict)\n",
        "            #         # 3. load the new state dict\n",
        "            #         model.load_state_dict(model_dict)\n",
        "            #         print(f\"Loaded pre-trained weights from {pretrain_model_path}\")\n",
        "            #     else:\n",
        "            #          print(f\"Pre-trained model not found at {pretrain_model_path}. Starting training from scratch.\")\n",
        "\n",
        "            # except Exception as e:\n",
        "            #     print(f\"Error loading pre-trained model: {e}\")\n",
        "\n",
        "            print(\"Training setup complete: model, criterion, optimizer, and scheduler defined.\")\n",
        "        else:\n",
        "             print(\"Error: RRDBNet class not found in the modified module.\")\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during module execution or model setup: {e}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An error occurred during module execution or model setup: name 'ARCH_REGISTRY' is not defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b138077e"
      },
      "source": [
        "## 모델 학습\n",
        "\n",
        "### Subtask:\n",
        "설정된 환경에서 모델을 학습시키는 코드를 실행합니다. 학습 과정에서 손실 및 성능 지표를 모니터링합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50ce6dce"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous subtask failed due to issues with the `basicsr` library's dependencies and registration mechanism. Before proceeding with training, I need to fix the environment. I will try to address the `ModuleNotFoundError` by downgrading `torchvision` to a version that is likely compatible with the installed `basicsr` library. Then, I will attempt to run the training setup code again, but this time, I will also include the training loop as requested in the current subtask. This combines fixing the environment with the primary goal of this subtask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52708888",
        "outputId": "30c26e57-2700-4911-d224-1d91678444a5"
      },
      "source": [
        "!pip install torchvision==0.11.3\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import sys\n",
        "import os\n",
        "import importlib.util\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "# Define the path to the modified rrdbnet_arch.py\n",
        "file_path = '/usr/local/lib/python3.11/dist-packages/basicsr/archs/rrdbnet_arch.py'\n",
        "\n",
        "# Use importlib to load the module directly from the file path\n",
        "if not os.path.exists(file_path):\n",
        "    print(f\"Error: Modified model file not found at {file_path}\")\n",
        "else:\n",
        "    spec = importlib.util.spec_from_file_location(\"rrdbnet_arch\", file_path)\n",
        "    rrdbnet_arch = importlib.util.module_from_spec(spec)\n",
        "    sys.modules[\"rrdbnet_arch\"] = rrdbnet_arch\n",
        "    try:\n",
        "        spec.loader.exec_module(rrdbnet_arch)\n",
        "\n",
        "        # Access the RRDBNet class from the loaded module\n",
        "        RRDBNet = rrdbnet_arch.RRDBNet\n",
        "\n",
        "        # Instantiate the modified RRDBNet model\n",
        "        model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64, num_block=23, num_grow_ch=32)\n",
        "\n",
        "        # Move model to GPU if available\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        model.to(device)\n",
        "\n",
        "        # Define a loss function\n",
        "        criterion = nn.L1Loss()\n",
        "\n",
        "        # Define an optimizer\n",
        "        optimizer = optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.999))\n",
        "\n",
        "        # Implement a learning rate scheduler\n",
        "        scheduler = lr_scheduler.StepLR(optimizer, step_size=10000, gamma=0.5)\n",
        "\n",
        "        print(\"Training setup complete: model, criterion, optimizer, and scheduler defined.\")\n",
        "\n",
        "        # Data Loading\n",
        "        class CustomSRDataset(Dataset):\n",
        "            def __init__(self, hr_dir, lr_transform=None, hr_transform=None):\n",
        "                self.hr_dir = hr_dir\n",
        "                self.lr_transform = lr_transform\n",
        "                self.hr_transform = hr_transform\n",
        "                self.image_filenames = [f for f in os.listdir(hr_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "            def __len__(self):\n",
        "                return len(self.image_filenames)\n",
        "\n",
        "            def __getitem__(self, idx):\n",
        "                hr_img_path = os.path.join(self.hr_dir, self.image_filenames[idx])\n",
        "                hr_img = Image.open(hr_img_path).convert('RGB')\n",
        "                lr_img = hr_img.resize((hr_img.width // 4, hr_img.height // 4), Image.BICUBIC)\n",
        "\n",
        "                if self.lr_transform:\n",
        "                    lr_img = self.lr_transform(lr_img)\n",
        "                if self.hr_transform:\n",
        "                    hr_img = self.hr_transform(hr_img)\n",
        "\n",
        "                return lr_img, hr_img\n",
        "\n",
        "        hr_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])\n",
        "        lr_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])\n",
        "        hr_dummy_dir = '/content/drive/My Drive/work/hr_images'\n",
        "        dataset = CustomSRDataset(hr_dir=hr_dummy_dir, lr_transform=lr_transform, hr_transform=hr_transform)\n",
        "        dataloader = DataLoader(dataset, batch_size=1, shuffle=True) # Reduced batch size to 1 to avoid OOM\n",
        "\n",
        "        # Training Loop\n",
        "        num_epochs = 5 # Example number of epochs\n",
        "        for epoch in range(num_epochs):\n",
        "            for i, (lr_imgs, hr_imgs) in enumerate(dataloader):\n",
        "                try:\n",
        "                    lr_imgs = lr_imgs.to(device)\n",
        "                    hr_imgs = hr_imgs.to(device)\n",
        "\n",
        "                    optimizer.zero_grad()\n",
        "                    outputs = model(lr_imgs)\n",
        "                    loss = criterion(outputs, hr_imgs)\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                    if (i+1) % 1 == 0: # Print every batch\n",
        "                        print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(dataloader)}], Loss: {loss.item():.4f}')\n",
        "                except Exception as e:\n",
        "                    print(f\"An error occurred during training: {e}\")\n",
        "                    if \"out of memory\" in str(e):\n",
        "                        print(\"CUDA out of memory. Try reducing batch size or model size.\")\n",
        "                        # Optional: clear cache and break\n",
        "                        torch.cuda.empty_cache()\n",
        "                        break\n",
        "                    else:\n",
        "                        raise e # Re-raise other errors\n",
        "\n",
        "            scheduler.step()\n",
        "\n",
        "            # Save model checkpoint\n",
        "            if (epoch + 1) % 5 == 0:\n",
        "                torch.save(model.state_dict(), f'model_epoch_{epoch+1}.pth')\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during module execution or model setup: {e}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Ignored the following yanked versions: 0.1.6, 0.1.7, 0.1.8, 0.1.9, 0.2.0, 0.2.1, 0.2.2, 0.2.2.post2, 0.2.2.post3, 0.15.0\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement torchvision==0.11.3 (from versions: 0.15.1, 0.15.2, 0.16.0, 0.16.1, 0.16.2, 0.17.0, 0.17.1, 0.17.2, 0.18.0, 0.18.1, 0.19.0, 0.19.1, 0.20.0, 0.20.1, 0.21.0, 0.22.0, 0.22.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torchvision==0.11.3\u001b[0m\u001b[31m\n",
            "\u001b[0mAn error occurred during module execution or model setup: name 'ARCH_REGISTRY' is not defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b100592"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous attempt to fix the `ModuleNotFoundError` by installing `torchvision==0.11.3` failed because that version is not available. The `ARCH_REGISTRY` error also persists, likely because the kernel was not fully reset or the import mechanism is still problematic. I will try a different approach to resolve the dependency issue by attempting to install the latest compatible versions of `torch`, `torchvision`, and `torchaudio` explicitly using a command that specifies the CUDA version. This often helps resolve version conflicts. I will also keep the importlib approach to load the modified model file, as directly importing `basicsr` seems to cause issues with the registry.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "324fb409",
        "outputId": "cca4a137-6502-4a52-be9a-67166c4cb3a9"
      },
      "source": [
        "# Try installing compatible versions of torch, torchvision, and torchaudio\n",
        "!pip install torch==2.3.1 torchvision==0.18.1 torchaudio==2.3.1 --index-url https://download.pytorch.org/whl/cu121\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import sys\n",
        "import os\n",
        "import importlib.util\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "# Define the path to the modified rrdbnet_arch.py\n",
        "file_path = '/usr/local/lib/python3.11/dist-packages/basicsr/archs/rrdbnet_arch.py'\n",
        "\n",
        "# Use importlib to load the module directly from the file path\n",
        "if not os.path.exists(file_path):\n",
        "    print(f\"Error: Modified model file not found at {file_path}\")\n",
        "else:\n",
        "    spec = importlib.util.spec_from_file_location(\"rrdbnet_arch\", file_path)\n",
        "    rrdbnet_arch = importlib.util.module_from_spec(spec)\n",
        "    sys.modules[\"rrdbnet_arch\"] = rrdbnet_arch\n",
        "    try:\n",
        "        spec.loader.exec_module(rrdbnet_arch)\n",
        "\n",
        "        # Access the RRDBNet class from the loaded module\n",
        "        # Assuming the ARCH_REGISTRY issue is resolved by a clean import\n",
        "        if hasattr(rrdbnet_arch, 'RRDBNet'):\n",
        "             RRDBNet = rrdbnet_arch.RRDBNet\n",
        "        else:\n",
        "             print(\"Error: RRDBNet class not found in the loaded module.\")\n",
        "             raise AttributeError(\"RRDBNet class not found\")\n",
        "\n",
        "\n",
        "        # Instantiate the modified RRDBNet model\n",
        "        model = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64, num_block=23, num_grow_ch=32)\n",
        "\n",
        "        # Move model to GPU if available\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        model.to(device)\n",
        "\n",
        "        # Define a loss function\n",
        "        criterion = nn.L1Loss()\n",
        "\n",
        "        # Define an optimizer\n",
        "        optimizer = optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.999))\n",
        "\n",
        "        # Implement a learning rate scheduler\n",
        "        scheduler = lr_scheduler.StepLR(optimizer, step_size=10000, gamma=0.5)\n",
        "\n",
        "        print(\"Training setup complete: model, criterion, optimizer, and scheduler defined.\")\n",
        "\n",
        "        # Data Loading\n",
        "        class CustomSRDataset(Dataset):\n",
        "            def __init__(self, hr_dir, lr_transform=None, hr_transform=None):\n",
        "                self.hr_dir = hr_dir\n",
        "                self.lr_transform = lr_transform\n",
        "                self.hr_transform = hr_transform\n",
        "                self.image_filenames = [f for f in os.listdir(hr_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "            def __len__(self):\n",
        "                return len(self.image_filenames)\n",
        "\n",
        "            def __getitem__(self, idx):\n",
        "                hr_img_path = os.path.join(self.hr_dir, self.image_filenames[idx])\n",
        "                hr_img = Image.open(hr_img_path).convert('RGB')\n",
        "                lr_img = hr_img.resize((hr_img.width // 4, hr_img.height // 4), Image.BICUBIC)\n",
        "\n",
        "                if self.lr_transform:\n",
        "                    lr_img = self.lr_transform(lr_img)\n",
        "                if self.hr_transform:\n",
        "                    hr_img = self.hr_transform(hr_img)\n",
        "\n",
        "                return lr_img, hr_img\n",
        "\n",
        "        hr_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])\n",
        "        lr_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])\n",
        "        hr_dummy_dir = '/content/drive/My Drive/work/hr_images'\n",
        "        dataset = CustomSRDataset(hr_dir=hr_dummy_dir, lr_transform=lr_transform, hr_transform=hr_transform)\n",
        "        dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "        # Training Loop\n",
        "        num_epochs = 5\n",
        "        for epoch in range(num_epochs):\n",
        "            for i, (lr_imgs, hr_imgs) in enumerate(dataloader):\n",
        "                try:\n",
        "                    lr_imgs = lr_imgs.to(device)\n",
        "                    hr_imgs = hr_imgs.to(device)\n",
        "\n",
        "                    optimizer.zero_grad()\n",
        "                    outputs = model(lr_imgs)\n",
        "                    loss = criterion(outputs, hr_imgs)\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                    if (i+1) % 1 == 0:\n",
        "                        print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(dataloader)}], Loss: {loss.item():.4f}')\n",
        "                except Exception as e:\n",
        "                    print(f\"An error occurred during training: {e}\")\n",
        "                    if \"out of memory\" in str(e):\n",
        "                        print(\"CUDA out of memory. Try reducing batch size or model size.\")\n",
        "                        torch.cuda.empty_cache()\n",
        "                        break\n",
        "                    else:\n",
        "                        raise e\n",
        "\n",
        "            scheduler.step()\n",
        "\n",
        "            if (epoch + 1) % 5 == 0:\n",
        "                torch.save(model.state_dict(), f'model_epoch_{epoch+1}.pth')\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during module execution or model setup: {e}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Collecting torch==2.3.1\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torch-2.3.1%2Bcu121-cp311-cp311-linux_x86_64.whl (781.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.0/781.0 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.18.1\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.18.1%2Bcu121-cp311-cp311-linux_x86_64.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m117.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.3.1\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.3.1%2Bcu121-cp311-cp311-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m596.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1) (4.14.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1) (2025.7.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m91.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m124.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==2.3.1 (from torch==2.3.1)\n",
            "  Downloading https://download.pytorch.org/whl/triton-2.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.18.1) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.18.1) (11.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.1) (12.6.85)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.3.1) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.3.1) (1.3.0)\n",
            "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.3.1\n",
            "    Uninstalling triton-3.3.1:\n",
            "      Successfully uninstalled triton-3.3.1\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.26.2\n",
            "    Uninstalling nvidia-nccl-cu12-2.26.2:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.26.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.5.1.17\n",
            "    Uninstalling nvidia-cudnn-cu12-9.5.1.17:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.5.1.17\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.7.1\n",
            "    Uninstalling torch-2.7.1:\n",
            "      Successfully uninstalled torch-2.7.1\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.22.1\n",
            "    Uninstalling torchvision-0.22.1:\n",
            "      Successfully uninstalled torchvision-0.22.1\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.6.0+cpu\n",
            "    Uninstalling torchaudio-2.6.0+cpu:\n",
            "      Successfully uninstalled torchaudio-2.6.0+cpu\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 torch-2.3.1+cu121 torchaudio-2.3.1+cu121 torchvision-0.18.1+cu121 triton-2.3.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchgen",
                  "torchvision",
                  "triton"
                ]
              },
              "id": "83216e673a374dd8a6c573ea813345b4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An error occurred during module execution or model setup: name 'ARCH_REGISTRY' is not defined\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}